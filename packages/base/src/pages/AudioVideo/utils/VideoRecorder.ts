/**
 * @ Author: willysliang
 * @ CreateTime: 2025-05-15 22:51:28
 * @ Modifier: willysliang
 * @ ModifierTime: 2025-05-26 14:35:56
 * @ Description: è§†é¢‘å½•åˆ¶
 */

declare global {
  interface Window {
    webkitAudioContext?: typeof AudioContext
  }
}

/** å½•åˆ¶æºæ¥å£ */
interface IRecordingSources {
  screen?: MediaStream
  camera?: MediaStream
}

/**
 * @class VideoRecorder è§†é¢‘å½•åˆ¶
 * @description
    1. å½•åˆ¶å±å¹•å’Œæ‘„åƒå¤´å†…å®¹ï¼Œå¹¶åˆæˆè§†é¢‘
      - å¦‚æœæœ‰æŠŠæ‘„åƒå¤´è§†å›¾æ¸²æŸ“åˆ°é¡µé¢ä¸Šï¼Œå½•åˆ¶çš„è§†é¢‘åˆ™å¿½ç•¥æ‘„åƒå¤´åª’ä½“æµçš„åˆæˆï¼ŒåªæŠŠæ‘„åƒå¤´éŸ³é¢‘æµåˆæˆåˆ°è§†é¢‘æµä¸­
    2. åœ¨å½•åˆ¶çš„è§†é¢‘ä¸­æ·»åŠ æ—¶é—´æˆ³æ°´å°
    3. å½•åˆ¶è¿‡ç¨‹ä¸­çš„éŸ³é¢‘å¯è§†åŒ–ç»˜åˆ¶ä¸ºé¢‘è°±å›¾
    3. æŠŠå½•åˆ¶çš„è§†é¢‘ä¿å­˜åˆ°æœ¬åœ°

 * @memberof #startRecording å¼€å§‹å½•åˆ¶è§†é¢‘
 * @memberof #stopRecording åœæ­¢å½•åˆ¶è§†é¢‘
 * @memberof #saveAsFile ä¿å­˜å½•åˆ¶çš„è§†é¢‘æ–‡ä»¶
 *
 * ç§æœ‰æ–¹æ³•
 * @memberof #getSources è·å–å±å¹•å…±äº«å’Œæ‘„åƒå¤´åª’ä½“æµ
 * @memberof #compositeStream åˆ›å»ºåˆæˆè§†é¢‘æµ
 * @memberof #drawCompositeView åˆå¹¶è§†å›¾ç”»é¢ï¼Œå¯è‡ªå®šä¹‰ç”»é¢å¸ƒå±€æ ·å¼
 * @memberof #drawAudioVisualization å¯è§†åŒ–æ¸²æŸ“éŸ³é¢‘-ç»˜åˆ¶é¢‘è°±å›¾
 * @memberof #stopTracks å…³é—­æ‰€æœ‰åª’ä½“è½¨é“ï¼Œå¹¶æ¸…ç†é¢„è§ˆæ˜¾ç¤º
 *
 * è¾…åŠ©æ–¹æ³•
 * @memberof #getMimeType è‡ªåŠ¨å…¼å®¹ä¸åŒæµè§ˆå™¨çš„è§†é¢‘ç¼–ç æ ¼å¼
 * @memberof #getBitrate æ ¹æ®åˆ†è¾¨ç‡è®¡ç®—æ¯”ç‰¹ç‡
 *
 * @example
    const videoRef = ref<HTMLVideoElement>()
    const canvasRef = ref<HTMLCanvasElement>()
    const recorder = new VideoRecorder()
    const showPreview = ref<boolean>(true) // æ˜¯å¦å±•ç¤ºé•œå¤´è§†å›¾

    // æ‘„åƒå¤´åˆ—è¡¨
    const cameraList = ref<MediaDeviceInfo[]>([])
    const currentCamera = ref<MediaDeviceInfo['deviceId']>('')
    getCameraList().then((list) => {
      cameraList.value = list
      currentCamera.value = list[0]?.deviceId
    })

    // å¼€å§‹å½•åˆ¶
    const handleStartRecord = async () => {
      await recorder.startRecording(
        currentCamera.value,
        canvasRef.value!,
        showPreview.value ? videoRef.value! : undefined,
      )
    }

    // ç»“æŸå½•åˆ¶
    const handleStopRecord = async () => {
      recorder.stopRecording()
    }

    // ä¿å­˜è§†é¢‘
    const handleSaveVideo = async () => {
      recorder.saveAsFile()
    }
 */
export class VideoRecorder {
  /** åª’ä½“æµçš„æº */
  private sources: IRecordingSources = {}
  /** åª’ä½“å½•åˆ¶å™¨ */
  private mediaRecorder?: MediaRecorder
  /** å½•åˆ¶çš„æ•°æ®å— */
  private recordedChunks: Blob[] = []

  /** å±å¹•å…±äº«å’Œæ‘„åƒå¤´æµæ’­æ”¾çš„DOM */
  private videoElements: HTMLVideoElement[] = []
  /** é¢„è§ˆè§†é¢‘å…ƒç´  */
  private previewVideo?: HTMLVideoElement

  /** è§†é¢‘åˆæˆç”»å¸ƒ */
  private canvas!: HTMLCanvasElement
  private ctx!: CanvasRenderingContext2D
  private animationFrameId?: number

  /** é¢‘è°±å›¾ */
  private audioContext?: AudioContext
  private audioRAFId?: number

  constructor() {
    this.canvas = document.createElement('canvas')
    this.ctx = this.canvas.getContext('2d')!
  }

  /**
   * @method è·å–å±å¹•å…±äº«å’Œæ‘„åƒå¤´åª’ä½“æµ
   */
  private async getSources(
    cameraDeviceId: MediaDeviceInfo['deviceId'],
  ): Promise<IRecordingSources> {
    try {
      const promises = [
        navigator.mediaDevices.getDisplayMedia({
          video: { frameRate: 24, deviceId: cameraDeviceId },
          audio: {
            echoCancellation: true, // å›å£°æ¶ˆé™¤
            noiseSuppression: true, // å¼€å¯é™å™ª å™ªéŸ³æŠ‘åˆ¶
            autoGainControl: false, // è‡ªåŠ¨å¢ç›Šæ§åˆ¶(åœ¨åŸæœ‰å½•éŸ³åŸºç¡€ä¸Šæ˜¯å¦å¢åŠ éŸ³é‡)
          },
        }),
        navigator.mediaDevices.getUserMedia({
          video: { width: 640, height: 480 },
          audio: true,
        }),
      ]
      const [screenStream, cameraStream] = await Promise.all(promises)
      const sources = { screen: screenStream, camera: cameraStream }

      // å¼ºåˆ¶æ£€æŸ¥æ˜¯å¦å­˜åœ¨æœ‰æ•ˆè½¨é“
      if (
        !screenStream.getVideoTracks().length ||
        !cameraStream.getVideoTracks().length
      ) {
        this.stopTracks(sources)
        throw new Error('å¿…é¡»æä¾›æœ‰æ•ˆçš„è§†é¢‘è½¨é“')
      }

      return sources
    } catch (error) {
      const ERROR_MAP = {
        NotAllowedError: 'è¯·å…è®¸è®¿é—®å±å¹•å’Œæ‘„åƒå¤´æƒé™ â”',
        NotFoundError: 'æœªæ‰¾åˆ°è§†é¢‘è®¾å¤‡ï¼Œè¯·æ£€æŸ¥æ‘„åƒå¤´è¿æ¥ ğŸ”',
        NotReadableError: 'è®¾å¤‡å·²è¢«å…¶ä»–ç¨‹åºå ç”¨ ğŸ”’',
        OverconstrainedError: 'æ— æ³•æ»¡è¶³åˆ†è¾¨ç‡è¦æ±‚',
        default: `åª’ä½“è·å–å¤±è´¥: ${error instanceof Error ? error.message : String(error)}`,
      }
      throw new Error(
        error instanceof DOMException
          ? ERROR_MAP[error.name] || ERROR_MAP.default
          : ERROR_MAP.default,
      )
    }
  }

  /**
   * @method åˆå¹¶è§†å›¾ç”»é¢ï¼Œç»˜åˆ¶è§†é¢‘å¸§ï¼ˆå«å¸ƒå±€å’Œæ°´å°ï¼‰
   * @description å¯è‡ªå®šä¹‰ç”»é¢å¸ƒå±€æ ·å¼(å¦‚æ·»åŠ æ—¶é—´æˆ³ã€ç»˜åˆ¶è¾¹æ¡†ç­‰)
   *  - ä¸»ç”»é¢ä¸ºå±å¹•å…±äº«å†…å®¹
   *  - å³ä¸‹è§’ä¸ºæ‘„åƒå¤´ç”»é¢
   *  - å·¦ä¸‹è§’ä¸ºæ°´å°æ—¶é—´æˆ³
   *  - ç”»é¢å°ºå¯¸ä¸å±å¹•æµä¸€è‡´ï¼Œå¹¶æ ¹æ®è®¾å¤‡æ€§èƒ½è°ƒæ•´ç”»è´¨
   *  - åŒæ­¥çš„éŸ³é¢‘å½•åˆ¶
   */
  private async drawCompositeView() {
    if (!this.sources.screen || !this.sources.camera) return

    /**
     * åˆå§‹åŒ–è§†é¢‘å…ƒç´ 
     */
    this.videoElements = await Promise.all(
      [this.sources.screen, this.sources.camera].map(async (stream) => {
        const video = document.createElement('video')
        video.srcObject = stream
        video.muted = true
        video.play()
        await new Promise((resolve) => (video.onloadedmetadata = resolve))
        return video
      }),
    )
    const [screenVideo, cameraVideo] = this.videoElements

    // åˆå§‹åŒ–ç”»å¸ƒå°ºå¯¸
    const setupCanvas = () => {
      // è®¾ç½®ç”»å¸ƒå°ºå¯¸ä¸å±å¹•æµä¸€è‡´ï¼Œå¹¶æ ¹æ®è®¾å¤‡æ€§èƒ½è°ƒæ•´ç”»è´¨
      const isMobile = /Android|webOS|iPhone|iPad/i.test(navigator.userAgent)
      const quality = isMobile ? 0.7 : 1
      this.canvas.width = screenVideo.videoWidth * quality
      this.canvas.height = screenVideo.videoHeight * quality

      // ä¼˜åŒ–ç»˜åˆ¶æ€§èƒ½
      this.ctx.imageSmoothingEnabled = true
      this.ctx.imageSmoothingQuality = 'high'
    }
    setupCanvas()

    /**
     * åŠ¨æ€æ—¶é—´æˆ³æ°´å°ç»˜åˆ¶
     */
    const drawTimestampWatermark = () => {
      const watermarkStyle = {
        fontSize: 32,
        fontColor: 'rgba(255,255,255,0.8)',
        position: 'bottom-left',
      }
      const { fontColor, fontSize, position } = watermarkStyle
      this.ctx.font = `bold ${fontSize || 24}px Arial`
      this.ctx.fillStyle = fontColor || 'rgba(255, 0, 0, 0.7)'
      this.ctx.textBaseline = 'top'
      const timestamp = new Date().toLocaleTimeString()

      const padding = 20
      const x = position?.includes('right') ? this.canvas.width - 200 : padding
      const y = position?.includes('bottom') ? this.canvas.height - 50 : padding

      // æ–‡å­—é˜´å½±æ•ˆæœ
      this.ctx.shadowColor = 'rgba(0, 0, 0, 0.5)'
      this.ctx.shadowBlur = 4
      this.ctx.shadowOffsetX = 2
      this.ctx.shadowOffsetY = 2
      this.ctx.fillText(timestamp, x, y)
      this.ctx.restore()
    }

    /**
     * ç”»ä¸­ç”»å¸ƒå±€
     */
    const drawFrame = () => {
      const { width, height } = this.canvas
      this.ctx.clearRect(0, 0, width, height)

      // ç»˜åˆ¶ä¸»å±å¹•
      if (screenVideo.readyState >= 2) {
        this.ctx.drawImage(screenVideo, 0, 0, width, height)
      }

      // å¦‚æœæ²¡æœ‰æ‘„åƒå¤´æ²¡æœ‰å±•ç¤ºåˆ°é¡µé¢ï¼Œåœ¨å³ä¸‹è§’ç»˜åˆ¶æ‘„åƒå¤´ç”»ä¸­ç”»
      if (!this.previewVideo && cameraVideo.readyState >= 2) {
        const previewWidth = width / 4
        const previewHeight =
          (previewWidth * cameraVideo.videoHeight) / cameraVideo.videoWidth

        this.ctx.drawImage(
          cameraVideo,
          width - previewWidth - 10,
          height - previewHeight - 10,
          previewWidth,
          previewHeight,
        )
      }

      // ç»˜åˆ¶æ—¶é—´æˆ³æ°´å°
      drawTimestampWatermark()

      this.animationFrameId = requestAnimationFrame(drawFrame)
    }

    drawFrame()
  }

  /**
   * @method å¯è§†åŒ–æ¸²æŸ“éŸ³é¢‘-ç»˜åˆ¶é¢‘è°±å›¾
   * @description éŸ³è§†é¢‘å¯è§†åŒ–-éŸ³é¢‘å£°æ³¢å›¾ï¼ˆé€šè¿‡ canvas å¯¹è§†é¢‘æˆ–éŸ³é¢‘ç»˜åˆ¶å£°æ³¢å›¾ï¼‰
   */
  private drawAudioVisualization(
    stream: MediaStream,
    canvasElement: HTMLCanvasElement,
  ) {
    this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
      latencyHint: 'interactive', // è¶…ä½å»¶è¿Ÿæ¨¡å¼
      sampleRate: 48000, // ä¸“ä¸šéŸ³é¢‘é‡‡æ ·ç‡
    })
    const source = this.audioContext.createMediaStreamSource(stream)

    // åˆ›å»ºåˆ†æå™¨èŠ‚ç‚¹
    const analyser = this.audioContext.createAnalyser()
    analyser.fftSize = 256
    source.connect(analyser)

    const canvas = canvasElement
    const ctx = canvas.getContext('2d')!

    const dataArray = new Uint8Array(analyser.frequencyBinCount)
    const dataArrayLength = dataArray.length

    /**
     * è½®è¯¢ç»˜åˆ¶é¢‘è°±
     */
    const draw = () => {
      // analyser.getByteTimeDomainData(dataArray) // æ”¹ç”¨æ—¶åŸŸæ•°æ®ç»˜åˆ¶æ³¢å½¢
      analyser.getByteFrequencyData(dataArray) // ä½¿ç”¨é¢‘åŸŸæ•°æ®ç»˜åˆ¶é¢‘è°±

      const WIDTH = canvas.width
      const HEIGHT = canvas.height - 2
      const meterWidth = 2 // é¢‘è°±æ¡å®½åº¦
      const gap = 2 // é¢‘è°±æ¡é—´è·
      const capHeight = 100 // é¢‘è°±æ¡é«˜åº¦
      const capStyle = 'rgb(6, 247, 8)' // #2196f3 é¢‘è°±æ¡é¢œè‰²
      const meterNum = 20 / (gap + 2) // é¢‘è°±æ¡æ•°é‡
      const capYPositionArray: number[] = [] // é¢‘è°±æ¡é¡¶ç‚¹ä½ç½®æ•°ç»„

      ctx.clearRect(0, 0, WIDTH, HEIGHT) // æ¸…ç©ºç”»å¸ƒ
      ctx.fillStyle = capStyle // è®¾ç½®é¢‘è°±æ¡é¢œè‰²

      const step = Math.round(dataArrayLength / meterNum) // é‡‡æ ·æ­¥é•¿

      for (let i = 0; i < meterNum; i++) {
        const value = dataArray[i * step] // è·å–å½“å‰èƒ½é‡å€¼

        if (capYPositionArray.length < Math.round(meterNum)) {
          capYPositionArray.push(value) // åˆå§‹åŒ–é¡¶ç‚¹ä½ç½®æ•°ç»„ï¼Œå¹¶å°†ç¬¬ä¸€ä¸ªç”»é¢æ•°æ®å‹å…¥
        }
        if (value < capYPositionArray[i]) {
          ctx.fillRect(
            i * 4,
            HEIGHT - --capYPositionArray[i],
            meterWidth,
            capHeight,
          )
        } else {
          ctx.fillRect(i * 4, HEIGHT - value, meterWidth, capHeight)
          capYPositionArray[i] = value
        }
        ctx.fillRect(i * 4, HEIGHT - value + capHeight, meterWidth, capHeight)
      }

      this.audioRAFId = requestAnimationFrame(draw)
    }

    draw()
  }

  /**
   * @method åˆ›å»ºåˆæˆè§†é¢‘æµ
   * @param {boolean} needVideoComposite æ˜¯å¦éœ€è¦åˆæˆ
   *    - needVideoComposite=trueï¼Œéœ€è¦åˆæˆï¼ˆæŠŠæ‘„åƒå¤´è§†å›¾åˆæˆåˆ°è§†é¢‘æµä¸­ï¼‰
   *    - needVideoComposite=falseï¼Œç›´æ¥è¿”å›æ‰€æœ‰åª’ä½“è½¨é“ï¼ˆåœ¨é¡µé¢æœ‰è®¾ç½®é¢„è§ˆè§†é¢‘å…ƒç´ æ—¶ï¼Œç›´æ¥è¿”å›åˆæˆåçš„è§†é¢‘æµï¼‰
   */
  private async compositeStream(): Promise<MediaStream> {
    // è§†é¢‘åˆæˆ
    await this.drawCompositeView()

    // åˆ›å»ºåˆæˆè§†é¢‘æµ
    const stream = this.canvas.captureStream(25) // 25fps

    // åˆå¹¶æ‰€æœ‰éŸ³é¢‘è½¨é“åˆ°è§†é¢‘ä¸­
    ;[this.sources.screen!, this.sources.camera!].forEach((source) => {
      source.getAudioTracks().forEach((track) => stream.addTrack(track))
    })
    return stream
  }

  /**
   * @method å…³é—­æ‰€æœ‰åª’ä½“è½¨é“ï¼Œå¹¶æ¸…ç†é¢„è§ˆæ˜¾ç¤º
   * @description æ¸…é™¤ä¸Šæ¬¡å½•åˆ¶çš„å‰¯ä½œç”¨
   */
  private stopTracks(sources: IRecordingSources = this.sources) {
    Object.values(sources).forEach((stream) =>
      stream?.getTracks().forEach((t) => t.stop()),
    )
    sources = { screen: undefined, camera: undefined }

    // åœæ­¢åª’ä½“æµ
    this.mediaRecorder?.stream.getTracks().forEach((track) => track.stop())
    this.mediaRecorder = undefined

    // æ¸…é™¤è§†é¢‘å…ƒç´ 
    this.videoElements.forEach((video) => {
      video.pause()
      video.srcObject = null
      video.remove()
    })
    this.videoElements = []

    // æ¸…é™¤é¢„è§ˆæ˜¾ç¤º
    if (this.previewVideo) {
      this.previewVideo.pause()
      this.previewVideo.srcObject = null
      this.previewVideo = undefined
    }

    // å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡
    if (this.audioContext) {
      this.audioContext.close()
      this.audioContext = undefined
    }
    // åœæ­¢éŸ³é¢‘ç»˜åˆ¶
    this.audioRAFId && cancelAnimationFrame(this.audioRAFId)

    // åœæ­¢åŠ¨ç”»ç»˜åˆ¶ & æ¸…é™¤ç”»å¸ƒ
    this.animationFrameId && cancelAnimationFrame(this.animationFrameId)
    this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height)
  }

  // ================== æš´éœ²ç»™å¤–éƒ¨ç”¨çš„è°ƒç”¨æ–¹æ³• ==================
  /**
   * @method å¼€å§‹å½•åˆ¶è§†é¢‘
   */
  public async startRecording(
    cameraDeviceId: MediaDeviceInfo['deviceId'],
    canvasElement: HTMLCanvasElement,
    previewElement?: HTMLVideoElement,
  ) {
    this.stopTracks() // å‰ç½®å¤„ç†-å¼€å§‹å‰å…ˆå…³é—­å·²æœ‰æµ

    this.previewVideo = previewElement
    this.sources = await this.getSources(cameraDeviceId) // è·å–åª’ä½“æµ
    const stream = await this.compositeStream() // è·å–åˆæˆåçš„è§†é¢‘æµ

    // ç»˜åˆ¶é¢‘è°±å›¾
    this.drawAudioVisualization(stream, canvasElement)

    // æ˜¾ç¤ºæ‘„åƒå¤´é¢„è§ˆ
    if (this.previewVideo && this.sources.camera) {
      this.previewVideo.srcObject = this.sources.camera
      // this.previewVideo.srcObject = stream
      await this.previewVideo.play()
    }

    // å‡†å¤‡å½•åˆ¶
    this.mediaRecorder = new MediaRecorder(stream, {
      mimeType: this.getMimeType(),
      videoBitsPerSecond: this.getBitrate(),
      audioBitsPerSecond: 128_000, // æ¯ç§’éŸ³é¢‘æ¯”ç‰¹ç‡
    })

    this.recordedChunks = []
    this.mediaRecorder.ondataavailable = (e) => {
      e.data.size && this.recordedChunks.push(e.data)
    }

    this.mediaRecorder.start(100)
  }

  /**
   * @method åœæ­¢å½•åˆ¶è§†é¢‘
   */
  public stopRecording() {
    if (!this.mediaRecorder) throw new Error('å½•åˆ¶æœªå¼€å§‹')

    // æ·»åŠ å½•åˆ¶ç»“æŸç›‘å¬
    return new Promise<void>((resolve) => {
      this.mediaRecorder!.onstop = () => resolve()
      this.mediaRecorder?.stop()
      this.stopTracks()
    })
  }

  /**
   * @method ä¿å­˜å½•åˆ¶çš„è§†é¢‘æ–‡ä»¶
   */
  public saveAsFile(filename: string = 'recording') {
    if (this.recordedChunks.length === 0) return

    const mimeType = this.mediaRecorder?.mimeType || 'video/webm'
    const extension = mimeType.includes('mp4') ? 'mp4' : 'webm'
    const blob = new Blob(this.recordedChunks, { type: mimeType })

    const link = document.createElement('a')
    link.href = URL.createObjectURL(blob)
    link.download = `${filename}.${extension}`
    link.click()

    setTimeout(() => {
      URL.revokeObjectURL(link.href)
      link.remove()
    }, 100)
  }

  // ================== è¾…åŠ©å·¥å…·æ–¹æ³• ==================
  /**
   * @method è‡ªåŠ¨å…¼å®¹ä¸åŒæµè§ˆå™¨çš„è§†é¢‘ç¼–ç æ ¼å¼
   * @returns {string} æ£€æŸ¥ MediaRecorder æ ¼å¼æ”¯æŒå¹¶è¿”å›
   */
  private getMimeType(): string {
    const MIME_TYPES = [
      'video/mp4;codecs=avc1', // h264
      'video/webm;codecs=vp9', // vp9
      'video/webm;codecs=vp8', // vp8
    ] as const

    return MIME_TYPES.find(MediaRecorder.isTypeSupported) || 'video/webm'
  }

  /**
   * @method æ ¹æ®åˆ†è¾¨ç‡è®¡ç®—æ¯”ç‰¹ç‡
   * @returns {number} æ¯”ç‰¹ç‡
   */
  private getBitrate(): number {
    // const isHD = this.canvas.width >= 1280 || this.canvas.height >= 720
    // return isHD ? 5_000_000 : 2_500_000

    return this.canvas.width * this.canvas.height * 24 * 0.15 // åŸºäºåˆ†è¾¨ç‡å’Œå¸§ç‡çš„åŠ¨æ€æ¯”ç‰¹ç‡
  }
}

/**
 * @method è·å–æ‘„åƒå¤´è®¾å¤‡åˆ—è¡¨
 * @return {Promise<MediaDeviceInfo[]>} æ‘„åƒå¤´è®¾å¤‡åˆ—è¡¨
 */
export const getCameraList = async (): Promise<MediaDeviceInfo[]> => {
  const devices = await navigator.mediaDevices.enumerateDevices()
  return devices.filter((d) => d.kind === 'videoinput')
}
