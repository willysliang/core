---
Author: willysliang
CreateTime: 2022-10-24 10:15:15
Modifier: willysliang
ModifiedTime: 2025-05-21 09:17:27
Description: 功能记录本
---

## 功能记录本

## 初级 HTML/CSS

### 使用焦点样式丰富用户体验

> 焦点指示器常用于输入元素时显示特殊样式。
>
> ### 使用`outline:none`改变默认焦点样式
>
> 使用 `outline: none` 删除默认的蓝色轮廓，同时更改背景颜色和接收焦点时元素的颜色。通过这种方式，用户仍然可以很容易地识别出元素当前的焦点
>
> 注意：当改变颜色时，应该检查[颜色对比度](https://contrast-ratio.com/)是否足够。这对于视力低下的人来说尤其重要，但是颜色对比度差会影响到每个人。如果你曾经坐在阳光下上网，拥有一个好的颜色对比度是多么重要，这样你才能看到屏幕上的内容
>
> ```css
>a:focus {
>   outline: none;
>   background-color: #651787;
>   color: #fff;
> }
> ```
> 
> ### 使用 `:focus-within` 设置可聚焦元素的父元素的样式
>
> 默认情况下，使用 `:before` 为表单创建背景，并使用 `transform: translateY(-100%)` 隐藏它。
>
> 一旦用户点击其中一个 `input` 元素，背景将从顶部移入。这是通过使用 `form:focus-within::before` 并将 `translateY` 设置为 `0` 来完成的。此外还使用 `transition` 使其成为平滑效果。
>
> ```html
><form>
>   <label for="username">Username:</label>
>   <input id="username" type="text" />
> 
>   <label for="password">Password:</label>
>   <input id="password" type="password" />
> 
>   <input type="submit" value="Login" />
> </form>
> ```
> 
> ```css
>form {
>    padding: 10px;
>    position: relative;
>      overflow: hidden;
>    }
>    form:before {
>    content: '';
>    background: #ddd;
>      position: absolute;
>      left: 0;
>      right: 0;
>      top: 0;
>      bottom: 0;
>      z-index: -1;
>      transform: translateY(-100%);
>      transition: transform 260ms ease-out;
>    }
>    form:focus-within::before {
>    transform: translateY(0);
> }
>    ```
> 
> ### 使用 `:focus-visible` 与鼠标/指针交互时不显示焦点样式   
>
> 有时，使用 `:focus` 样式也会对鼠标/指针用户的用户体验产生副作用。以具有上一个/下一个控件的图像库为例。如果用户单击其中一个按钮，它们将聚焦，因此将显示聚焦样式。虽然这对键盘用户来说很好，但对鼠标/指针用户来说可能太多了。
>
> 在这里，如果用户使用鼠标或指针聚焦元素，我们将使用伪类显式删除焦点样式。这样，键盘用户仍然可以看到焦点指示器，而鼠标用户则看不到。
>
> 在之前，你可能会使用以下错误的方法来修复这样的问题。但这样会删除键盘用户的焦点指示器，使您几乎无法使用图像库。
>
> ```css
>button:focus {
> 	outline: none;
> }
> ```
> 
> 可以使用 [`:focus-visible`](https://developer.mozilla.org/en-US/docs/Web/CSS/:focus-visible) 伪类，仅当用户使用键盘对焦元素时，才会显示对焦样式。
>在这里使用 `:not` 伪类来明确删除对焦样式，如果用户使用鼠标或指头对焦元素。这样，键盘用户仍将看到对焦指示器，而鼠标用户看不到。
> 
> ```css
>/* 提供基本的焦点样式 */
> button:focus {
> 	/* ...; */
> }
> /* 删除鼠标用户的焦点样式 */
> button:focus:not(:focus-visible) {
> 	outline: none;
> }
> ```

### 垂直水平居中的方式

> 基本结构如下：
>
> ```html
> <div class="container">
> 	<div class="box"></div>
> </div>
> ```
>
> 基本样式如下：
>
> ```css
> .container {
>   width: 200px;
>   height: 200px;
>   background-color: pink;
> }
> 
> .box {
>   width: 50px;
>   height: 50px;
>   background-color: plum;
> }
> ```

#### table-cell 表格

> ```css
> .container {
>   display: table-cell;
>   vertical-align: middle;
> }
> 
> .box {
>   margin: auto;
> }
> ```
>
> 或者
>
> ```css
> .container {
>   display: table-cell;
>   text-align: center;
>   vertical-align: middle;
> }
> 
> .box {
>   display: inline-block;
> }
> ```

#### position 定位

> **未知宽度和高度的元素**，可以使用绝对定位和 `transform` 属性的 `translate`。
>
> ```css
> .container {
>   position: relative;
> }
> 
> .box {
>   position: absolute;
>   top: 50%;
>   left: 50%;
>   transform: translate(-50%, -50%);
> }
> ```
>
> `transform` 还可以使用 `margin` 代替，需要注意的是 `margin` 的值是宽和高值的负一半：
>
> ```css
> .container {
>   position: relative;
> }
> 
> .box {
>   position: absolute;
>   top: 50%;
>   left: 50%;
>   margin: -25px 0 0 -25px; // width 和 height 的负一半
> }
> ```
>
> 另一种方式，设置 `absolute` 的偏移值（`top`、`left`、`right` 和 `bottom`）为 `0`，并使用 `margin: auto`，好处是不需要提前知道元素的尺寸兼容性好。
>
> ```css
> .container {
> position: relative;
> }
> 
> .box {
> position: absolute;
> top: 0;
> right: 0;
> bottom: 0;
> left: 0;
> margin: auto;
> }
> ```

#### Flex 布局

> 使用 `justify-content` 和 `align-item`：
>
> ```css
> .container {
> display: flex;
> justify-content: center;
> align-items: center;
> }
> ```
>
> 使用 `justify-content` 和 `align-self`：
>
> ```css
> .container {
> display: flex;
> justify-content: center;
> }
> 
> .box {
> align-self: center;
> }
> ```
>
> 使用 `margin：auto`：
>
> ```css
> .container {
> display: flex;
> }
> 
> .box {
> margin: auto;
> }
> ```

#### Grid 布局

> `grid` 用于二维布局，但当只有一个子元素时，一维布局与二维布局都一样。
>
> ```css
> .container {
> display: grid;
> justify-content: center;
> align-content: center;
> }
> /* or */
> .container {
> display: grid;
> justify-items: center;
> align-items: center;
> }
> ```
>
> 上面属性的简写形式：
>
> ```css
> .container {
> display: grid;
> place-items: center;
> }
> /* or */
> .container {
> display: grid;
> place-content: center;
> }
> ```
>
> 更简便的技巧：
>
> ```css
> .container {
> display: grid;
> }
> 
> .box {
> margin: auto;
> }
> ```
>
> 另一种方式，我们可以单独控制子元素的对齐方式：
>
> ```css
> .container {
> display: grid;
> }
> 
> .box {
> align-self: center;
> justify-self: center;
> /* 简写形式 */
> /* place-self: center; */
> }
> ```
>

### CSS创建三角形

#### 盒模型的border实现

> - 三角形指向的另一侧（即，如果三角形指向下方，则为顶部）应具有所需的 `border-color`。相邻边框（即左侧和右侧）的 `border-color` 应为 `transparent`
> - 更改 `border-width` 值将更改三角形的比例。
>
> ```css
> .triangle {
>   width: 0;
>   height: 0;
>   border-top: 20px solid #9c27b0;
>   border-left: 20px solid transparent;
>   border-right: 20px solid transparent;
> 
>   /* 简写形式 */
>   /* border: 20px solid transparent;
>   border-top-color: 20px solid plum; */
> }
> ```

#### `clip-path` 属性裁剪

> - [`clip-path`](https://developer.mozilla.org/zh-CN/docs/Web/CSS/clip-path) 属性使用裁剪方式创建元素的可显示区域。区域内的部分显示，区域外的隐藏。
> - 可使用`polygon` 函数实现一个三角形
>
> ```css
> .triangle {
>   clip-path: polygon(0 0, 100% 0, 50% 100%);
>   height: 20px;
>   width: 40px;
>   background-color: plum;
> }
> ```

#### `linear-gradient` 函数

> - [`linear-gradient()`](https://developer.mozilla.org/zh-CN/docs/Web/CSS/gradient/linear-gradient) 函数用于创建一个表示两种或多种颜色线性渐变的图片。
>
> ```css
> .triangle {
>   width: 100px;
>   height: 100px;
>   background: linear-gradient(
>     to bottom right,
>     #fff 0%,
>     #fff 50%,
>     plum 50%,
>     plum 100%
>   );
> }
> ```

### 瀑布流布局

> - [css瀑布流参考](https://blog.csdn.net/qq_53008257/article/details/124638563)
>
> **瀑布流布局**是一种新型的布局方式，可以将大小不一的图片完整的显示在页面上，并且在杂乱的布局中保持着一定的美感。
>
> ![image-20221122164839262](./image/image-20221122164839262.png)
>
> ```html
> <div class="container" id="con">
>   <div class="item">
>     <img src="../img/1.jpeg" alt="">
>   </div>
>   <div class="item">
>     <img src="../img/2.jpeg" alt="">
>   </div>
>   <div class="item">
>     <img src="../img/3.jpeg" alt="">
>   </div>
>   <div class="item">
>     <img src="../img/4.jpeg" alt="">
>   </div>
>   <div class="item">
>     <img src="../img/5.jpeg" alt="">
>   </div>
>   <div class="item">
>     <img src="../img/6.jpeg" alt="">
>   </div>
> </div>
> ```

#### 使用column-count属性实现

> - 使用column-count属性将一个盒子分为多列展示数据 ，使用column-gap：0px将列间间距设置未0，方便我们自定义间距。
>
> **优点**：
>
> 1. 简单，只需给父盒子两行代码
> 2. 列数不会随着浏览器的宽度而改变，例如：指定列数为4就只能显示4列
>
> **缺点**：图片的位置是按照从上往下排序，如果我们需要一些动态加载图片的业务，那么新加入的图片将不会加入页面的最低端，不符合我们的业务需求
>
> ```css
> .container{
>   column-count: 4;//想要排成的列数
>   column-gap: 0;
> }
> .item img{
>   width: 100%;
> }
> ```

#### 使用 flex 布局

> 使用弹性盒子，给弹性元素指定列排列，然后给每个元素指定宽度(宽度设置为（1/列数）如果想要排成4列就设置成25%,如果想要排成5列就设置成25%以此类推)。
>
> **由于设置为列排列，当元素的累计高度没有超过指定的高度时，首先会在第一个列上堆叠元素**
>
> 由于设置了flex-wrap:wrap导致如果超出了设置的高度，元素将会换行，由于我们设置的排列方向是按列排列，因此超出的元素将会展示在第二列
>
> 注意：若父容器高度设置过高（或子内容数量过少），就会导致存在有些列为空白情况
>
> ```css
> .container{
>     display: flex;
>     flex-direction: column;
>     flex-wrap: wrap;
>     /* 需要指定高度 */
>     height: 800px;
> }
> .item{
>     width: 25%;
> }
> 
> .item img{
>     width: 100%;
> }
> 
> ```
>
> ### 优化
>
> ```css
> .container{
>     display: flex;
>     flex-direction: column;
>     flex-wrap: wrap;
>     /* 需要指定高度 */
>     height: 1600px
> }
> /**新加入的代码*/
> .item:nth-child(4n+1){
>     order: 1;
> }
> .item:nth-child(4n+2){
>     order:2;
> }
> .item:nth-child(4n+3){
>     order: 3;
> }
> .item:nth-child(4n){
>     order: 4;
> }
> /**新加入的代码*/
> .item{
>     width: 25%;
>     position: relative;
>     counter-increment: item-counter;
> }
> 
> .item img{
>     width: 100%;
> }
> .item::after{
>     position:absolute;
>     background-color: red;
>     color: white;
>     left: 0;
>     top: 0;
>     content: counter(item-counter);
> }
> ```
>
> **由于图片大小差距过大，导致每一行显示图片的数量不一样，导致order失效**。
> 但当每一列图片数量相等的时候，可以达成想要的效果
>
> **优点**：如果每列数量差图片数量相同，则可以实现新的图片显示在最下方的业务
>
> **缺点**:
>
> - 列数不会随着浏览器的宽度而改变
> - 需要指定高度，并且在每一列放置合适数量的图片。
> - 如果没有给容器设置固定宽度，则当容器宽度缩小时，图片的宽度相应的缩小，由于图片的高度是auto，即按图片原比例展示，因此图片高度会相应减少，由于高度指定，图片数量固定，则可能会出现图片占不满列数的情况
>
> ![image-20221122180605976](./image/image-20221122180605976.png)

#### JS 方法实现

> 原理:通过JS，根据每个图片的宽度计算出需要放置多少行，将所有图片设置绝对定位，逐一计算出该图片所在的top和left进行定位。
>
> **优点**:
>
> 1. 列数随浏览器窗口大小动态改变
> 2. 可以实现新图片在最下方展示
>
> **缺点**:
>
> 1. 代码较为复杂
> 2. 由于使用js，会消耗一些浏览器性能，当图片多了的时候可能导致卡顿。
>
> ```css
> .container{
>   position: relative;
> }
> .item{
>   width: 200px;
>   height: auto;
>   position: absolute;
> }
> 
> .item img{
>   width: 100%;
> }
> ```
>
> ```js
> //当页面加载的时候调用
> window.onload = function(){
>   //页面初始化调用
>   waterFall()
>   //每次页面改变大小调用
>   window.onresize = waterFall
> }
> function waterFall(){
>   // 1. 设置container盒子的宽度
>   //      注意：浏览器的可视区域的宽度 / 一个item元素的宽度 = 一行的排列的元素的个数
>   let container = document.getElementById("con")
>   let item = document.getElementsByClassName("item")
>   //获取元素的宽度(含border，padding)
>   let width = item[0].offsetWidth 
>   //计算出浏览器窗口的宽度
>   let clientWidth = document.documentElement.clientWidth;
>   //计算出应该放几列（向下取整）
>   let columnCount = Math.floor(clientWidth / width)
>   //设置容器（父盒子）的宽度
>   container.style.width = columnCount*width+"px"
> 
>   // 2.设置每一个item元素的排列位置
>   //  第一行整体的top值都是0 后面的依次找上一行高度最小的容器，在它下面进行排列
>   let hrr = []
>   for(let i= 0 ;i<item.length;i++){
>     //定位第一行的图片
>     if(i<columnCount){
>       item[i].style.top = "0px"
>       item[i].style.left = i* width+"px" 
>       hrr.push(item[i].offsetHeight)
>     }else{
>       //第一行之后的 选择总高度最小的列
>       let min = Math.min(...hrr)
>       let index = hrr.indexOf(min)
>       //将每个元素定位到当前总高度最小的列下
>       item[i].style.top = min+"px"
>       item[i].style.left = index * width+"px" 
>       //当前定位的元素加入该列
>       hrr[index] += item[i].offsetHeight
>     }
>   }
> }
> ```
>
> 为什么每次都要将图片放置在高度最小的列上呢?
> 因为图片高度不一的情况，**如果按下标顺序一个一个排列，最终虽然每一列上图片的数量是一样的，但是显示的高度可能相差甚远**,因此选择将每个图片放在高度最小的列上让每一列的总高度不会相差太大。实现效果图如下：
>
> ![image-20221122181314569](./image/image-20221122181314569.png)
>
> 当浏览器宽度改变时，图片列数自动匹配。
>
> ![image-20221122181421527](./image/image-20221122181421527.png)

#### 总结

> ![image-20221122181823720](./image/image-20221122181823720.png)

## 中级 JS

### 计算textarea的字符数

> - 需要使用 `maxlength` 属性设置用户可以在 `textarea` 中限制用户输入的最大字符数
> - 通过监听`textarea`的`input`事件来计算长度
> - 注意：若是通过捕获`keyup`事件来计算，其会在某些情况下不起作用，例如
>   1. 用户将文本拖动到文本区域
>   2. 用户在文本区域中单击鼠标右键，然后从关联菜单中选择粘贴
>
> ```html
> <div>
>   <textarea rows="5" maxlength="200" id="message"></textarea>
>   <div id="counter">0</div>
> </div>
> ```
>
> ```js
> const messageEle = document.getElementById('message')
> const counterEle = document.getElementById('counter')
> // 获取 `maxlength` 属性
> const maxLength = messageEle.getAttribute('maxlength')
> 
> counterEle.innerHTML = `0/${maxLength}`
> 
> messageEle.addEventListener('input', function (e) {
>   const target = e.target
>   // 计算当前字符数
>   const currentLength = target.value.length
>   counterEle.innerHTML = `${currentLength}/${maxLength}`
> })
> ```

### 判断对象是否为空

> ### 无法使用等号直接比较
>
> 因为对象是引用类型，所以无法像基本数据类型那样使用`===`或`==`比较（等号是比较内存地址）
>
> ```js
> const obj = {}
> console.log(obj === {}) // false
> ```
>
> ### `for...in`遍历比较
>
> `for...in`可以任意顺序遍历一个对象的除Symbol以外的可枚举属性。
> 根据`for...in`遍历对象，如果进入遍历则为非空对象
>
> ```js
> const obj = {}
> const user = { name: 'willy' }
> const isEmptyObj = (obj) => {
>   for(let key in obj) {
>      return '非空对象'
>   }
>   return '空对象'
> }
> 
> console.log(isEmptyObj(obj))	// 空对象
> console.log(isEmptyObj(user))	// 非空对象
> ```
>
> ### `JSON.stringify()`
>
> 利用JSON的`JSON.stringify()`转换为JSON字符串来进行判断
>
> ```js
> const isEmptyObj = (obj) => JSON.stringify(obj) === '{}' ? '空对象' ： '非空对象'
> ```
>
> ### `Object.keys()`
>
> `Object.keys()`方法会返回一个由一个给定对象的自身可枚举属性组成的数组。如果对象为空，将返回一个空数组。
>
> ```js
> const isEmptyObj = (obj) => Object.keys(obj).length === 0 ? '空对象' : '非空对象'
> ```

### API身份认证

> ```js
> fetch('https://example.com/token', {
>   headers: {
>      Authorization: `Bearer ${token}`
>   }
> })
>   .then((response) => {
>    if (response.ok) return response.json()
>    throw response
> })
>   .then((data) => console.log(data))
>   .catch((error) => console.warn(error))
> ```

### ES JSON 模块提案

> JSON 模块已经存在于 Chrome 91，它看起来就像一个 ES Modules 风格的导入，只是你在最后设置了类型。
>
> ```js
> import configData from './config-data.json' assert { type: 'json' }
> ```
>
> **好处**：一行代码获取 JSON 数据

### 侦听手机浏览器的方法

#### navigator.userAgent设备信息

> - JS 通过`navigator.userAgent`属性拿到一个字符串，只要里面包含`mobi`、`android`、`iphone`等关键字，就可以认定是移动设备
> - 这种方法的优点是简单方便，缺点是不可靠，因为用户可以修改这个字符串，让手机浏览器伪装成桌面浏览器
>
> ```js
> if (/Mobi|Android|iPhone/i.test(navigator.userAgent)) {
>   // 当前设备是移动设备
> }
> 
> // 另一种写法
> if (
>   navigator.userAgent.match(/Mobi/i) ||
>   navigator.userAgent.match(/Android/i) ||
>   navigator.userAgent.match(/iPhone/i)
> ) {
>   // 当前设备是移动设备
> }
> ```
>
> Chromium 系的浏览器，还有一个`navigator.userAgentData`属性，也有类似作用。不同之处是它将 user agent 字符串解析为一个对象，该对象的`mobile`属性，返回一个布尔值，表示用户是否使用移动设备。
>
> ```js
> const isMobile = navigator.userAgentData.mobile; 
> ```

#### window.screen，window.innerWidth

> 另一种方法是通过屏幕宽度，判断是否为手机。
>
> `window.screen`对象返回用户设备的屏幕信息，该对象的`width`属性是屏幕宽度（单位为像素）。
>
> 如果屏幕宽度`window.screen.width`小于500像素，就认为是手机。
>
> 但是这个方法的缺点在于，如果手机横屏使用，就识别不了。
>
> ```js
> if (window.screen.width < 500) {
>   // 当前设备是移动设备 
> }
> ```
>
> 另一个属性`window.innerWidth`返回浏览器窗口里面的网页可见部分的宽度，比较适合指定网页在不同宽度下的样式。
>
> ```js
> const getBrowserWidth = function() {
>     if (window.innerWidth < 768) {
>        return "xs";
>     } else if (window.innerWidth < 991) {
>        return "sm";
>     } else if (window.innerWidth < 1199) {
>        return "md";
>     } else {
>        return "lg";
>     }
> };
> ```

#### window.orientation

> 第三种方法是侦测屏幕方向，手机屏幕可以随时改变方向（横屏或竖屏），桌面设备做不到。
>
> `window.orientation`属性用于获取屏幕的当前方向，只有移动设备才有这个属性，桌面设备会返回`undefined`。
>
> ```js
> if (typeof window.orientation !== 'undefined') {
>   // 当前设备是移动设备 
> }
> ```
>
> 注意，iPhone 的 Safari 浏览器不支持该属性 

#### touch 事件

> 第四种方法是，手机浏览器的 DOM 元素可以通过`ontouchstart`属性，为`touch`事件指定监听函数。桌面设备没有这个属性。
>
> ```js
> function isMobile() { 
>     return ('ontouchstart' in document.documentElement); 
> }
> 
> // 另一种写法
> function isMobile() {
>     try {
>        document.createEvent("TouchEvent"); return true;
>     } catch(e) {
>        return false; 
>     }
> }
> ```

#### window.matchMedia()

> **通过屏幕宽度判断**
>
> CSS 通过 media query（媒介查询）为网页指定响应式样式。如果某个针对手机的 media query 语句生效了，就可以认为当前设备是移动设备。
>
> `window.matchMedia()`方法接受一个 CSS 的 media query 语句作为参数，判断这个语句是否生效。
>
> ```js
> let isMobile = window.matchMedia("only screen and (max-width: 760px)").matches;
> ```
>
> 上面示例中，`window.matchMedia()`的参数是一个 CSS 查询语句，表示只对屏幕宽度不超过 700 像素的设备生效。它返回一个对象，该对象的`matches`属性是一个布尔值。如果是`true`，就表示查询生效，当前设备是手机。
>
> **通过指针精确性判断**
>
> CSS 语句`pointer:coarse`表示当前设备的指针是不精确的。由于手机不支持鼠标，只支持触摸，所以符合这个条件。
>
> ```js
> let isMobile = window.matchMedia("(pointer:coarse)").matches;
> ```
>
> 有些设备支持多种指针，比如同时支持鼠标和触摸。
>
> `pointer:coarse`只用来判断主指针，此外还有一个`any-pointer`命令判断所有指针。
>
> `any-pointer:coarse`表示所有指针里面，只要有一个指针是不精确的，就符合查询条件。
>
> ```js
> let isMobile = window.matchMedia("(any-pointer:coarse)").matches; 
> ```

### 图片懒加载(延迟加载)

> -  当访问一个页面时，先把img元素或者其他元素的背景图片替换成一张大小1*1px图片的路径（只需要请求一次的占位图），只有当图片出现在浏览器的可视区域内时，才设置图片真正的路径，让图片显示出来，这就是图片的懒加载
> -  懒加载的原理是先在页面中把所有的图片统一使用一张占位图进行占位，把真正的路径存在元素的‘data-url’属性中，要使用的时候再设置。
>
> ```js
> // html
>  <div>
>     <img src="./imgloading.jpg" alt="loading..." data-src="./img/1.jpg">
>     <img src="./img/loading.jpg" alt="loading..." data-src="../../willy/二次备份/冰墨/收藏/2.jpg">
>     <img src="./img/loading.jpg" alt="loading..." data-src="./img/3.jpg">
> </div>
>       
> // js
> // onload是等所有的资源文件加载完毕以后再绑定事件
> window.onload = function () {
>   // 获取图片列表，即img标签列表
>   var imgs = document.querySelectorAll('img');
> 
>   // 获取到浏览器顶部的距离
>   function getTop(e) {
>     return e.offsetTop;
>   }
> 
>   // 懒加载实现
>   function lazyload(imgs) {
>     // 可视区域高度
>     var h = window.innerHeight;
>     //滚动区域高度
>     var s = document.documentElement.scrollTop || document.body.scrollTop;
>     for (var i = 0; i < imgs.length; i++) {
>       //图片距离顶部的距离大于可视区域和滚动区域之和时懒加载
>       if ((h + s) > getTop(imgs[i])) {
>         // 真实情况是页面开始有2秒空白，所以使用setTimeout定时2s
>         (function (i) {
>           setTimeout(function () {
>             // 不加立即执行函数i会等于9
>             // 隐形加载图片或其他资源，
>             //创建一个临时图片，这个图片在内存中不会到页面上去。实现隐形加载
>             var temp = new Image();
>             temp.src = imgs[i].getAttribute('data-src');//只会请求一次
>             // onload判断图片加载完毕，真是图片加载完毕，再赋值给dom节点
>             temp.onload = function () {
>               // 获取自定义属性data-src，用真图片替换假图片
>               imgs[i].src = imgs[i].getAttribute('data-src')
>             }
>           }, 2000)
>         })(i)
>       }
>     }
>   }
>   lazyload(imgs);
> 
>   // 滚屏函数
>   window.onscroll = function () {
>     lazyload(imgs);
>   }
> }
> ```
>

### 页面倒计时

#### 倒计时用 setInterval 实现

> ```js
> const totalDuration = 100; // 100s
> let duration = totalDuration;
> let countDownInterval = null;
> let startTime = new Date().getTime();
> let endTime = startTime;
> let prevEndTime = startTime
> let timeDifferance = 0; // 每1s倒计时偏差值，单位ms
> let totalTimeDifferance = 0; // 总共倒计时偏差值，单位ms
> 
> function countDown() {
>   countDownInterval = setInterval(() => {
>     duration = duration - 1;
>     prevEndTime = endTime
>     endTime = new Date().getTime();
>     console.log(`当前执行时间：${endTime}, 首次执行时间：${startTime}`);
>     console.log(`当前和首次执行的时间间隔差：${endTime - startTime}`)
>     timeDifferance = endTime - prevEndTime
>     document.getElementById("app").innerText = duration;
>     document.getElementById("differance").innerText = timeDifferance;
>     if (duration <= 0) {
>       totalTimeDifferance = endTime - startTime - totalDuration * 1000;
>       console.log(`累计时间差: ${totalTimeDifferance}`)
>       clearInterval(countDownInterval);
>     }
>   }, 1000);
> }
> 
> countDown();
> ```
>
> #### 使用 setInterval 实现的缺点
>
> 使用 setInterval 实现，可以看到每次变更倒计时都会出现 `-2ms ~ 7ms` 的偏差值不等。这是因为浏览器可能存在同步或异步任务代码的执行阻塞，导致 setInterval 的回调函数会产生延迟。
>
> ![image-20230423125105265](./image/image-20230423125105265.png)

#### 倒计时用 setTimeout 实现

> ```js
> const totalDuration = 100; // 100s
> let duration = totalDuration;
> let countDownInterval = null;
> let startTime = new Date().getTime();
> let endTime = startTime;
> let prevEndTime = startTime;
> let timeDifferance = 0; // 每1s倒计时偏差值，单位ms
> let totalTimeDifferance = 0; // 总共倒计时偏差值，单位ms
> let interval = 1000; // 1s
> 
> function countDown() {
> duration = duration - 1;
> endTime = new Date().getTime();
> timeDifferance = endTime - prevEndTime;
> console.log(`当前倒计时：${duration}, 每秒执行的偏差值：${timeDifferance}`)
> let nextTime = interval - timeDifferance
> // 如果下一次执行时间超过当前周期，需要特俗处理一下
> if (nextTime < 0) {
>  nextTime = 0
> }
> document.getElementById("nextTime").innerText = nextTime;
> if (duration <= 0) {
>  totalTimeDifferance = endTime - startTime - totalDuration * 1000;
>  console.log(`累计执行的偏差值：${totalTimeDifferance}`)
>  clearTimeout(countDownInterval);
> } else {
>  countDownInterval = setTimeout(() => countDown(), nextTime);
> }
> }
> 
> countDownInterval = setTimeout(() => countDown(), interval);
> ```
>
> #### 使用 setTimeout 实现的缺点
>
> **注意：如果下次执行的时间间隔小于0，则需要特殊处理**
>
> 同样加了线程阻塞代码倒计时10s，误差值可降低到 2.5s，说明优化效果还是很显著的，当然实际过程编程过程中阻塞时间这么严重是很极端的情况，此时重点不再是去降低延迟，而是关注重构导致阻塞的代码。
>
> ![image-20230423125158020](./image/image-20230423125158020.png)

#### 倒计时用 requestAnimationFrame 实现

> ```js
> const totalDuration = 10 * 1000;
> let requestRef = null;
> let startTime;
> let prevEndTime;
> let prevTime;
> let currentCount = totalDuration;
> let endTime;
> let timeDifferance = 0; // 每1s倒计时偏差值，单位ms
> let interval = 1000;
> let nextTime = interval;
> 
> setInterval(() => {
>   let n = 0;
>   while (n++ < 1000000000);
> }, 0);
> 
> const animate = (timestamp) => {
>   if (prevTime !== undefined) {
>     const deltaTime = timestamp - prevTime;
>     if (deltaTime >= nextTime) {
>       prevTime = timestamp;
>       prevEndTime = endTime;
>       endTime = new Date().getTime();
>       currentCount = currentCount - 1000;
>       console.log("currentCount: ", currentCount / 1000);
>       timeDifferance = endTime - startTime - (totalDuration - currentCount);
>       console.log(timeDifferance);
>       nextTime = interval - timeDifferance;
>       // 慢太多了，就立刻执行下一个循环
>       if (nextTime < 0) {
>         nextTime = 0;
>       }
>       console.log(`执行下一次渲染的时间是：${nextTime}ms`);
>       if (currentCount <= 0) {
>         currentCount = 0;
>         cancelAnimationFrame(requestRef);
>         console.log(`累计偏差值： ${endTime - startTime - totalDuration}ms`);
>         return;
>       }
>     }
>   } else {
>     startTime = new Date().getTime();
>     prevTime = timestamp;
>     endTime = new Date().getTime();
>   }
>   requestRef = requestAnimationFrame(animate);
> };
> 
> requestRef = requestAnimationFrame(animate);
> ```
>
> ![image-20230423170418774](./image/image-20230423170418774.png)

#### react + requestAnimationFrame 实现倒计时

> ```jsx
> import React, { useState, useEffect, useRef } from "react";
> const [count, setCount] = useState<number>(0)
> const [duration, setTotalDuration] = useState<number>(0)
> const requestRef = useRef(null);
> const previousTimeRef = useRef(null);
> const currentCountRef = useRef<number>(0);
> 
> const animate = time => {
>   if (previousTimeRef.current !== undefined) {
>     const deltaTime = time - previousTimeRef.current;
>     if (deltaTime > 1000) {
>       if (currentCountRef.current > 0) {
>         previousTimeRef.current = time;
>         setCount(prevCount => {
>           currentCountRef.current = prevCount - 1000
>           return prevCount - 1000
>         });
>       } else {
>         setCount(0)
>         cancelAnimationFrame(requestRef.current);
>         return
>       }
>     }
>   } else {
>     previousTimeRef.current = time;
>   }
>   requestRef.current = requestAnimationFrame(animate);
> }
> 
> useEffect(() => {
>   const totalDuration = 60 * 1000
>   setCount(totalDuration)
>   setTotalDuration(totalDuration)
> }, [])
> 
> useEffect(() => {
>   if (duration <= 0) {
>     return
>   }
>   currentCountRef.current = duration
>   previousTimeRef.current = undefined
>   if (requestRef.current) {
>     cancelAnimationFrame(requestRef.current)
>   }
>   requestRef.current = requestAnimationFrame(animate);
>   return () => cancelAnimationFrame(requestRef.current)
> }, [duration])
> ```



## 前端逻辑 ES6

### 数组

#### 判断一个值是否是数组

> ```bash
> ## 判断一个值是否是数组
> const str = 'abc'
> const arr = [1, 2, 3]
> 
> 1. Array.prototype.isArray()
>       Array.isArray(arr)	// true
>       Array.isArray(str)	// false
> 
> 
> 2. Object.prototype.toString.call()
> 		const isArray = (arr) => Object.prototype.toString.call(arr) == '[object Array]'
> 
> 
> 3. instanceof
> 	使用 instanceof 检验构造函数的 prototype 属性是否出现在对象的原型链中，返回一个 Boolean。
>     arr instanceof Array // true
>     str instanceof Array // false
> 	
> 
> 4. constructor
> 	使用 constructor 判断该变量的构造函数是否为 Array
> 		arr.constructor === Array // true
> 		
> 
> 5. 封装
> 		const isArray = Array.isArray || ((list) => ({}.toString.call(list) === '[object Array]'))
> 		cosole.log(isArray([1, 2, 3])) // true
> 		console.log(isArray({}))	// false
> ```

#### 判断数组是否包含某值

> ```bash
> ## 判断数组是否包含某值
> const arr = ['red', 'yellow', 'black', 'white', 'yellow']
> 
> ### 1. Array.prototype.indexOf()：判断数组是否存在某个值，如果存在则返回数组元素下标，否则返回 -1。
>  arr.indexOf('plum')	// -1
>  arr.indexOf('yellow')	// 1
>  arr.indexOf('yellow', 2)	// 4
>  arr.indexOf('red') !== -1	// true
> 
> 
> ### 2. Array.prototype.includes()：判断数组中是否存在某个值，如果存在返回 true，否则返回 false。
>  arr.includes('red')	// true
>  arr.includes('plum')	// false
> 
> 
> ### 3. Array.prototype.find()：返回数组中满足条件的第一个元素的值，如果没有则返回 undefined。
> 		arr.find((item) => item && item === 'black')	// 'black'
> 
> 
> ### 4. Array.prototype.findIndex()：返回数组中满足条件的第一个元素的下标，如果没有找到则返回 -1。
> 		arr.findIndex((item) => item === 'white')	// 3
> 
> 
> ### 5. 常规循环：递减循环通常效率更高。
>  const contains = function (array, str) {
>    let i = a.length
>    while (i--) {
>      if (array[i] === str) return true
>      return false
>    }
>  }
>  contains(arr, 'yellow')	// true
>  contains(arr, 'plum')	// false
> ```

#### 数组扁平化

```bash
## 数组扁平化
const arr = [1, [2, [3, [4, 5]]], 6]    // --> [1, 2, 3, 4, 5, 6]

1. Array.prototype.flat()
		flat 可以指定展开多少层，也可使用 Infinity 作为参数展开无限嵌套数组
      	arr.flat(1) // [1, 2, [3, [4, 5]], 6]
        arr.flat(2) // [1, 2, 3, [4, 5], 6]
        arr.flat(Infinity) // [1, 2, 3, 4, 5, 6]


2. Array.prototype.toString() 或 Array.prototype.join()
		如果数组的元素都是数字，可考虑使用。
        const flatten1 = (arr) => arr.toString().split(',').map((item) => +item)
        flatten1(arr) // [1, 2, 3, 4, 5, 6]
        const flatten2 = (arr) => arr.join(',').split(',').map((item) => +item)
        flatten2(arr) // [1, 2, 3, 4, 5, 6]


3. 扩展运算符（注：仅适用于一层）
		[].concat(...arr) // [1, 2, [3, [4, 5]], 6]
		[].concat.apply([], arr) // [1, 2, [3, [4, 5]], 6]


4. 序列化 + 正则replace
		const str = `[${JSON.stringify(arr).replace(/(\[|\])/g, '')}]`
		JSON.parse(str) // [1, 2, 3, 4, 5, 6]
		
		
5. 递归 Array.prototype.reduce() + concat()
    const flatten = (arr) => {
      return arr.reduce(
        (acc, val) => Array.isArray(val) ? acc.concat(flatten(val)) : acc.concat(val),
        [],
      )
    }
    flatten(arr) // [1, 2, 3, 4, 5, 6]
```



#### 从数组中删除重复的对象

```bash
## 从数组中删除重复的对象

检查两个对象是否具有相同的属性和值的唯一方法是实际检查每个对象的属性和值。
	- 仅检索数组中每一项与其后的每一项，以避免多次比较同一对象。
	- 仅检查未发现与任何其他项重复的项。
	- 先检查两个对象是否具有相同的键，再检查每个属性的值是否相同。
	
```

```ts
/**
 * @function deepEqual 深度对比两个值是否相等
 * @param {any} value1 要对比的值
 * @param {any} value2 要对比的值
 * @returns {boolean} 是否相等
 * @example deepEqual([], [])
 */
export const deepEqual = (value1: any, value2: any): boolean => {
  // 两边类型是否一致
  const valueType = (v) => Object.prototype.toString.call(v)
  if (valueType(value1) !== valueType(value2)) return false

  /** 类型判断仅需要判断一边就行 */
  if (value1 && typeof value1 === 'object') {
    // 数组的对比
    if (Array.isArray(value1)) {
      // 是否等长
      if (value1.length !== value2.length) return false

      // 是否存在不同的值
      for (let i = 0; i < value1.length; i++) {
        if (!deepEqual(value1[i], value2[i])) return false
      }

      // 排除了上述所有检查，则必为相同
      return true
    }

    // Map 的对比
    if (value1 instanceof Map) {
      if (value1.size !== value2.size) return false
      for (const [key, value] of value1) {
        if (!value2.has(key) || value2.get(key) !== value) return false
      }

      return true
    }

    // Set 的对比
    if (value1 instanceof Set) {
      if (value1.size !== value2.size) return false
      for (const item of value1) {
        if (!value2.has(item)) return false
      }

      return true
    }

    // 其他情况的对比
    const valueKeys1 = Object.keys(value1)
    const valueKeys2 = Object.keys(value2)
    if (valueKeys1.length !== valueKeys2.length) return false
    for (const key of valueKeys1) {
      if (!(key in value2) || !deepEqual(value1[key], value2[key])) return false
    }
    return true
  }

  // 是否直接相等
  return value1 === value2
}


/**
 * @function removeDuplicates 删除数组的重复项对象
 * @param {Record<string, unknown>[]} arr 可能具有重复项的数组
 * @returns {Record<string, unknown>[]} 去重后的对象数组
 */
export function removeDuplicates(arr: Record<string, unknown>[]) {
  /** 已经去重的数组 */
  const result: Record<string | number, unknown>[] = []

  /** 重复索引 */
  const duplicatesIndices = new Map<number, boolean>()

  for (let index = 0; index < arr.length; index++) {
    // 如果已经重复，则无需检查
    if (duplicatesIndices.has(index)) continue

    const current = arr[index]

    // 此时必然是不重复的，直接加入该对象
    result.push(current)

    // 遍历数组当前项之后的其他项
    for (
      let comparisonIndex = index + 1;
      comparisonIndex < arr.length;
      comparisonIndex++
    ) {
      // 如果之前就已经计算到这里重复，则无需检查
      if (duplicatesIndices.has(comparisonIndex)) continue

      const valuesEqual = deepEqual(current, arr[comparisonIndex])

      // 检查值是否全部相等，以此来加入重复对象
      if (valuesEqual) duplicatesIndices.set(comparisonIndex, true)
    }
  }

  return result
}


/** 测试用例 */
const test1 = [
  { id: 1, name: 'Alice' },
  { id: 2, name: 'Bob' },
]
console.log(removeDuplicates(test1))
// 期望： [{ id: 1, name: 'Alice' }, { id: 2, name: 'Bob' }]

const test2 = [
  { id: 1, name: 'Alice' },
  { id: 1, name: 'Alice' },
  { id: 2, name: 'Bob' },
]
console.log(removeDuplicates(test2))
// 期望：[{ id: 1, name: 'Alice' }, { id: 2, name: 'Bob' }]

const test3 = [
  { id: 1, name: 'Alice' },
  { id: 1, name: 'Alice' },
  { id: 1, name: 'Alice' },
]
console.log(removeDuplicates(test3))
// 期望：[{ id: 1, name: 'Alice' }]

const test4 = [
  { id: 1, name: 'Alice', age: 30 },
  { id: 1, name: 'Alice' },
  { id: 1, name: 'Alice', gender: 'female' },
]
console.log(removeDuplicates(test4))
// 期望：[{ id: 1, name: 'Alice', age: 30 }, { id: 1, name: 'Alice' }, { id: 1, name: 'Alice', gender: 'female' }]

const test5 = [
  { id: 1, data: { score: 10, passed: true } },
  { id: 1, data: { score: 10, passed: true } },
  { id: 1, data: { passed: true, score: 10 } },
  { id: 2, data: { score: 8, passed: false } },
]
console.log(removeDuplicates(test5))
// 期望：[{ id: 1, data: { score: 10, passed: true } }, { id: 2, data: { score: 8, passed: false } }]

const test6 = [
  { id: 1, tags: ['science', 'math'] },
  { id: 1, tags: ['science', 'math'] },
  { id: 2, tags: ['science'] },
]
console.log(removeDuplicates(test6))
// 期望：[{ id: 1, tags: ['science', 'math'] }, { id: 2, tags: ['science'] }]

```



### 对象

#### 判断对象是否为空

```bash
## 判断对象是否为空
### 1. JSON.stringify()：
使用 `JSON.stringify()` 将对象转化为字符串 '{}' 来进行判断。
  const isEmpty = (obj) => JSON.stringify(obj) === '{}'
  isEmpty({})	// true
  isEmpty({ name: 'willy' }) // false


### 2. Object.keys()
		`Object.keys()` 方法会返回一个由一个给定对象的自身可枚举属性组成的数组。如果对象为空，将返回一个空数组。
    - 所以检查对象是否为空的最简单方法是检查它是否有键。
    - Object.keys() 传入非对象参数将强制转换为对象。
    		const isEmpty = (obj) => Object.keys(obj).length === 0
    		isEmpty({})	// true
        isEmpty({ name: 'willy' }) // false


### 3. for...in
		`for...in` 语句以任意顺序遍历一个对象的除 Symbol 以外的可枚举属性。
		根据 for...in 遍历对象，如果存在则返回 false，否则返回 true。
        const isEmpty = (obj) => {
          for (let prop in obj) {
            // 判断是否自身属性
            if (Object.prototype.hasOwnProperty.call(obj, prop)) {
              return false
            }
          }
          return JSON.stringify(obj) === '{}'
        }
        isEmpty({})	// true
        isEmpty({ name: 'willy' }) // false

```



### 函数

#### 管道运算符

```bash
### 管道运算符
管道是将一个函数的输出直接发送到另一个函数。

例：
伪代码表示：`output = input -> func1 -> func2 -> func3`。
在这种情况下，将 `input` 通过管道输送到 `func1`，将 `func1` 通过管道输送到 `func2` 的输出，在将 `func2` 通过管道输送到 `func3`，然后再汇算结果进行输出。
在不支持管道的情况下，实现方式为：`const output = func3(func2(func1(input)))`。

手动实现：
- 使用扩展运算符（`...`）允许将任意数量的参数传递到创建 `pipe` 函数中，传入的参数都存放在 `args` 数组中。
- 使用 `Array.prototype.reduce()` 方法遍历数组 `args`。执行 `reduce` 时，累加器会将前一个累加器传递给当前元素的结果。

```

```js
/** 管道函数 */
const pipe = (...args) => args.reduce((acc, el) => el(acc))

const title = 'Front End Interview'

const toLowerCase = (str) => str.toLowerCase()
const addHyphens = (str) => str.replace(/\s/g, '-')

// 案例：对标题转化为小写，并且通过 `-` 来进行单词的连接
pipe(title, toLowerCase, addHyphens) // "front-end-interview"

```



### 网络

#### WEB应用从服务器主动推送数据到客户端的方式

> ```bash
> ## WEB应用从服务器主动推送数据到客户端的方式
> 1. html5 的 websocket
> 2. websocket 通过 Flash
> 3. XHR 长时间连接
> 4. 不可见的 iframe
> 5. <script> 标签的长时间连接(可跨域)
> 6. ajax 轮询调用请求
> 
> 
> 
> ### Ajax 轮询
> Ajax 轮询是定时通过 Ajax 查询服务端，客户端按规定定时向服务端发送 ajax 请求，服务器接到请求后马上返回响应信息并关闭连接。
> 优点： 逻辑简单容易实现。
> 缺点：
>     * 需要不断向服务器发送消息询问，请求中有大半是无用，浪费带宽和服务器资源。
>     * 通过模拟服务器发起的通信，不是实时通信，不顾及应用的状态改变并且盲目检查更新，导致服务器资源浪费，且会加重网络负载，拖累服务器。
>     * 前端长时间处于轮询占用CPU，并且由于JS是单线程，轮询间隔无法保证。
> 实例：适于小型应用。
> 
> 
> ### WebSocket 通过 Flash
> Flash Socket：在页面中内嵌入一个使用了Socket类的 `Flash` 程序，`JavaScript`通过调用此`Flash`程序提供的Socket接口与服务器端的Socket接口进行通信，JavaScript在收到服务器端传送的信息后控制页面的显示。
>  * 优点：实现真正的即时通信，而不是伪即时。
>  * 缺点：客户端必须安装Flash插件；非HTTP协议，无法自动穿越防火墙。
>  * 实例：网络互动游戏。
> 
> 
> ### XHR 长时间连接（长轮询）
> 客户端打开一个到服务器端的 `AJAX` 请求然后等待响应；服务器端需要一些特定的功能来允许请求被挂起，只要一有事件发生，服务器端就会在挂起的请求中送回响应并关闭该请求。
> 客户端 JavaScript 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接；如此循环。
> 优点： 
>  		 * 对于前端来说实现简单，与普通的网络请求没有太大区别。
>  		 * 在无消息的情况下不会频繁的请求。
> 缺点： 
>  		 * 需要服务器端有特殊的功能来临时挂起连接，服务器hold连接会消耗资源。
>  		 * 客户端发起的连接较多时，服务器端会长期保持多个连接，具有一定的风险。
> 实例：WebQQ、Hi网页版、Facebook IM。
> 
> 
> ### 不可见的iframe（长连接）
> 在页面中嵌入一个隐藏的`iframe`，将这个隐藏的`iframe`的`src`属性设置为对一个长连接的请求或者采用XRH请求，服务器端就能源源不断地往客户端输入数据。
>  * 优点：消息即时到达，不发无用的请求；管理起来也相对方便。
>  * 缺点：服务器维护一个长连接会增加开销。
>  * 实例：Gmail聊天
> 
> 
> ### `<script>` 标签
> 把 script 标签附加到页面上以让脚本执行。服务器会挂起连接直到有事件发生，接着把脚本内容发送回浏览器，然后重新打开另一个 script 标签来获取下一个事件，从而实现长轮询的模型。
> 	 * 缺点：前后端实现都很麻烦
> 	 
> 	 
> ### html5 websocket
> `WebSocket`是HTML5开始提供的一种在单个 `TCP` 连接上进行全双工通讯的协议。
> 在WebSocket API中，浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送。
>  * 优点： 实现简单、可靠。
>  * 缺点： 部分低版本浏览器可能不支持。
> ```

### TypeScript

#### add函数，要求参数类型相同，否则报错

> ```bash
> ## add函数，要求参数类型相同，否则报错
> const func = (a, b) => a + b; 要求编写Typescript，要求a，b参数类型一致，都为number或者都为string
> 
> 
> ### 1. 使用 扩展运算符 + 数组设定类型
> const add = (...values: Array<string> | Array<number>) => values.reduce((total, num) => total + num, 0)
> add(1, 2, 3)
> add('a', 'b', 'c')
> add('a', 1, 2)
> 
> 
> ### 2. 函数重载
> interface Add {
>  (a: string, b: string): string
>  (a: number, b: number): number
> }
> const add: Add = (a, b) => values.reduce((total, num) => total + num, 0)
> 
> 
> ### 3. 泛型（答案错误的，仅供参考，在传递字符串的时候会报错）
> type IFun<T extends number | string> = (...values: Array<T>) => T extends number ? number : string
> const add: IFun<number> = (...values) => values.reduce((total, num) => total + num, 0)
> add(1, 2)
> add('a', 'b') // 报错
> add('a', 1) // 报错
> ```



### 设计模式

#### 工厂模式

> **工厂模式：同样的形式参数返回不同的实例**
>
> ```js
> /** 工厂构造函数 */
> function Superman () { this.name = '超级管理员' }
> function CommonMan () { this.name = '普通用户' }
> 
> /** 简单工厂 */
> function Factory () {}
> Factory.prototype.getInstance = function (className) {
>  try {
>     return eval('new' + className + '()')
>  } catch {
>     throw new Error('参数错误，不存在该工厂构造函数')
>  }
> }
> 
> const factory = new Factory()
> const obj1 = factory.getInstance('Superman')
> const obj2 = factory.getInstance('CommonMan')
> console.log(obj1.name, obj2.name)	// 超级管理员， 普通用户
> ```

#### 代理模式

> **代理模式：新建个类包装老类，对被包装的类进行管控及分发**
>
> ```js
> function Person () { }
> Person.prototype.sayName = function () { console.log('willysliang') }
> Person.prototype.sayAge = function () { console.log(30) }
> 
> /** 代理类 */
> function PersonProxy () {
>  const that = this
>  this.person = new Person()
>  // 代理调用 Person 的方法
>  this.callMethod = function (functionName) {
>     try {
>       that.person[functionName]()	// 代理
>     } catch {
>       throw new Error('参数错误，原对象不存在该方法')
>     }
>  }
> }
> 
> const person1 = new PersonProxy()
> person1.callMethod('sayName')
> person1.callMethod('sayAge') // 代理调用Person的方法 sayAge()
> ```

#### 单例模式

> **单例模式：任意对象都是单例，无须特别处理**
>
> ```js
> // demo1
> const obj = { name: 'willysliang', age: 24 }
> 
> 
> // demo2
> let box = null
> const createBox = (_a, _b) => {
>  if (!box) { box = Object.create(null) }
>  box.a = _a
>  box.b = _b
>  return box
> }
> 
> const obj1 = createBox(3, 6)
> console.log(obj1) // {a: 3, b: 6}
> 
> const obj2 = createBox(10, 20)
> console.log(obj1) // {a: 10, b: 20}
> console.log(obj2) // {a: 10, b: 20}
> ```

#### 发布订阅模式

> ```js
> // 发布者
> function Publisher () {
>  this.listeners = []
> }
> Publisher.prototype.addListener = function (listener) {
>  this.listeners.push(listener)
> }
> Publisher.prototype.removeListener = function (listener) {
>  delete this.listeners[listener]
> },
>  Publisher.prototype.notify = function (obj) {
>  for(let i = 0; i < this.listeners.length; i++) {
>     const listener = this.listeners[i]
>     if (typeof listener !== 'undefined') {
>       listener.process(obj)
>     }
>  }
> }
> }
> 
> // 订阅者
> function Subscriber () {  }
> Subscriber.prototype.process = function (obj) {
>  console.log(obj)
> }
> 
> const publisher = new Publisher()
> publisher.addListener(new Subscriber())
> publisher.addListener(new Subscriber())
> publisher.notify({ name: 'willy', age: 24 }) // 发布一个对象到所有订阅者
> publisher.notify('this is string value') // 发布一个字符串到所有订阅者
> ```



## 数据处理

### 树形菜单

#### 根据子节点ID找父节点

> ```js
> let arr = [  //数组树型结构
> {
>   children: '',
>   id: '11111'
> },
> {
>   children: [
>       {
>         children: '',
>         id: '22221'
>       },
>       {
>         name: [
>           {
>             children: '',
>             id: '33332'
>           }
>         ],
>         id: '22222'
>       }
>   ],
>   id: '11112'
> },
> {
>   children: [
>       {
>         children: [
>           {
>             children: [
>               {
>                 children: [],
>                 id: '44444'
>               }
>             ],
>             id: '33334'
>           }
>         ],
>         id: '22224'
>       }
>   ],
>   id: '11114'
> },
> ]
> ```

##### 逆向递归--多维数组根据子节点ID查找所有相关联父节点ID

> 1. 判断数组是否为空，以此来跳出循环
> 2. 对数组进行遍历，查找子节点的id的位置
>     - 若该层数组没有找到，则通过递归往深一层找
> 3. 找到父节点后，则把父节点Id取出，并根据父节点id继续递归查找
>
> ```js
> let result = [];  //用来接收相关联父级id的集合
> getParentNode = (arr, id) => {
>   if (!arr.length) return;
>   arr.forEach(item => {
>     // 数组不存在子节点 或 子节点长度为0，则不执行
>     if (!item.children || !item.children.length) return;
>     // 利用some筛选子级有没有符合条件的，有就重新递归，没有就继续递归
>     if (item.children.some(row => row.id == id)) {
>       result.unshift(item.id)
>       //重新递归
>       getParentNode(a, item.id)
>     } else {
>       //继续递归
>       getParentNode(item.children, id)
>     }
>   });
> }
> getParentNode(arr, '44444');	// 要查找的子节点id
> ```
>
> ```js
> // 知晓子节点寻找父节点
> treeFindPath(tree, func, path = []) {
>   if (!tree) return []
>   for (const data of tree) {
>     path.push(data.code)
>     if (func(data)) return path
>     if (data.children) {
>       const findChildren = treeFindPath(data.children, func, path)
>       if (findChildren.length) return findChildren
>     }
>     path.pop()
>   }
>   return []
> };
> let ssfj = treeFindPath(treeData,data=> data.code==rows[0].werks && data.type == 30);
> ```

#### 数组转树形结构

> ```js
> const json = require("./json")
> let data = json.data.rows.qmQmsRalUserareaList;
> toTree = (arr) => {
> let werks = {};
> let list = [];
> arr.forEach((item, i) => {
>  werks[item.werksShortname] 
>    ? werks[item.werksShortname] = [...werks[item.werksShortname], i]  
>  	: werks[item.werksShortname] = [i]
> });
> Object.keys(werks).forEach((item, i) => {
>  item.forEach((val, j) => {
>    // list[i].push({})
>  })
> })
> console.log( werks)
> }
> toTree(data)
> ```



## 文件

### 下载文件

#### 使用  download 属性

> - 将 `download` 属性添加到链接将强制浏览器下载文件，而不是导航到链接。并且可以向 `download` 属性传递一个字符串值作为可下载文件的名称。
> - 注意：IE11 不支持 download 属性，但有`polyfill`来支持这些不支持的环境中运行该属性
> - 下载限制：只有当文件与当前网站同域时，download属性才会起作用。如果 `href` 属性与站点的来源不同，则该属性无效。
>
> ```html
> <a href="/path/to/file" download>下载</a>
> <a href="/logo.png" download="logo">home</a>
> ```

#### 触发  click  事件

> - 这个想法来自于创建一个链接，并触发它的 `click` 事件。
>
>
> ```js
> // 创建一个新链接
> const link = document.createElement('a')
> link.download = 'file name'
> link.href = '/path/to/file'
> 
> // 添加到文档中
> document.body.appendChild(link)
> 
> // 触发点击事件
> link.click()
> 
> // 移除元素
> document.body.removeChild(link)
> ```

#### 下载生成数据的文件

> - 下载带有动态数据的文件是很常见的，例如一个JSON、一段文字或一个图像
> - 从数据中，我们可以将其转换为 `blob`，然后触发上述提到的 `click` 事件。以下示例代码创建一个 JSON blob 并下载它：
>
> ```js
> const data = JSON.stringify({ message: 'Hello world' })
> const blob = new Blob([data], { type: 'application/json' })
> 
> // 创建新的 URL
> const url = window.URL.createObjectURL(blob)
> 
> // 创建链接并触发下载
> // ...
> 
> // 释放上面创建的 URL
> window.URL.revokeObjectURL(url)
> ```

### 文件上传

#### 上传文件多选、限制文件类型、获取文件元数据

> - 文件上传的传统形式是使用`input`定义`type`为`file`类型接收上传的文件数据；通过监听`change`事件来获取上传的文件，并获取其文件的元数据
> - 使用`multiple`属性来设置是否可选上传多个文件（Boolean类型）
> - 使用`accpet`属性来限制上传文件的类型（不是所设置的类型会不显示出来）
> - 有一个非标准属性 `webkitdirectory`，使我们能够上传整个目录（虽然最初仅针对基于 WebKit 的浏览器实施，但 WebkitDirectory 在微软 Edge 以及 Firefox 50 及以后也可用。然而，即使它有相对广泛的支持，它仍然不是标准的，不应该使用，除非你别无选择）
>
> ```html
> <!-- html -->
> <!-- 单个文件上传 -->
> <input type="file" class="file-uploader" />
> <!-- 多个文件上传 -->
> <input type="file" class="file-uploader" multiple /> 
> <!-- 文件上传限制 -->
> <input type="file" class="file-uploader" accept=".jpg, .png" />
> <!-- 上传目录 -->
> <input type="file" id="file-uploader" webkitdirectory />
> 
> <!-- js -->
> <script>
>   const fileUploader = document.querySelectorAll(".file-uploader");
> 
>   fileUploader.forEach((item, i) => {
>     // 添加 change 事件监听器读取 event.target.files 文件对象
>     fileUploader[i].addEventListener("change", (event) => {
>       // 获取文件列表数组
>       const files = event.target.files;
> 
>       // 循环浏览文件并获取元数据
>       for (const file of files) {
>         const name = file.name
>         const type = file.type ? file.type : 'NA'
>         const size = file.size
>         const lastModified = file.lastModified
>         console.log({ file, name, type, size, lastModified })
>       }
>     });
>   })
> </script>
> ```

#### 上传文件前预览文件

##### window.URL.createObjectURL()

> **`URL.createObjectURL()`** 方法包含一个表示参数中给出的对象的 URL。这个新的 URL 对象表示指定的 [`File`](https://developer.mozilla.org/zh-CN/docs/Web/API/File) 对象或 [`Blob`](https://developer.mozilla.org/zh-CN/docs/Web/API/Blob) 对象。
>
> ```html
> <!-- html -->
> <input type="file" class="file-uploader" multiple />
> <img id="preview" />
> 
> <!-- js -->
> <script>
>   const fileUploader = document.querySelectorAll(".file-uploader");
>   const previewEle = document.getElementById('preview');
> 
>   fileUploader.forEach((item, i) => {
>     fileUploader[i].addEventListener("change", (event) => {
>       // 获取所选文件
>       const file = event.target.files[0];
> 
>       // 创建引用该文件的新 URL
>       const url = URL.createObjectURL(file);
> 
>       // 设置预览元素的源
>       previewEle.src = url;
>     });
>   })
> </script>
> ```

##### FileReader.readAsDataURL()

> - 使用 [`FileReader`](http://www.w3.org/TR/FileAPI/#FileReader-interface) 对象将文件转换为二进制字符串。然后添加 `load` 事件侦听器，以获得成功文件上传的二进制字符串。
> - `FileReader.readAsDataURL()` 方法用于读取指定的 `Blob` 或 `File`对象。
>
> ```html
> <!-- html -->
> <input type="file" class="file-uploader" multiple />
> <img id="preview" />
> 
> <!-- js -->
> <script>
>   const fileUploader = document.querySelectorAll(".file-uploader");
>   const previewEle = document.getElementById('preview');
> 
>   fileUploader.forEach((item, i) => {
>     // 获取 FileReader 的实例
>     const reader = new FileReader()
> 
>     fileUploader[i].addEventListener("change", (event) => {
>       const file = event.target.files[0];
> 
>       // 上传后获取文件对象，以 URL 二进制字符串的形式读取数据
>       reader.readAsDataURL(file)
> 
>       // 加载后，对字符串进行处理
>       reader.addEventListener('load', (e) => {
>         // 设置预览元素的源
>         previewEle.src = reader.result;
>       })
>     });
>   })
> </script>
> ```

#### 限制上传文件的大小

> 在读取了文件的大小元数据，可以使用它进行文件大小验证。可以允许用户上传高达 1MB 的图像文件
>
> ```html
> <input type="file" id="file-uploader" />
> ```
>
> ```js
> const fileUploader = document.getElementById("file-uploader");
> 
> fileUploader.addEventListener("change", (event) => {
>   // 读取文件大小
>   const file = event.target.files[0];
>   const size = file.size;
> 
>   // 检查文件大小是否大于 1MB，提示对应消息。
>   let msg = "";
>   if (size > 1024 * 1024) {
>      msg = `允许的文件大小为 1MB。您尝试上载的文件大小为${size}`;
>   } else {
>      msg = `${size}文件已成功上载。`;
>   }
>   console.log(msg);
> });
> ```

#### 显示上传进度条

> 先在页面中放置一个 `progress` 标签
>
> ```html
> <label id="progress-label" for="progress"></label>
> <progress id="progress" value="0" max="100" value="0">0</progress>
> ```
>
> 定义 `progress` 事件的回调函数
>
> ```js
> const reader = new FileReader()
> 
> reader.addEventListener('progress', (e) => {
>   if (e.loaded && e.total) {
>      // 计算完成百分比
>      const percent = (e.loaded / e.total) * 100
>      // 将值设置为进度组件
>      progress.value = percent
>   }
> })
> ```

#### 拖拽上传文件

> ```html
> <!-- css -->
> <style>
>   .dashboard {
>     border-radius: 10px;
>     width: 400px;
>     height: 400px;
>     margin: 20px auto 0;
>     box-sizing: border-box;
>     padding: 12px;
>     border: 2px dashed #f8bbd0;
>     border-radius: 5px;
>     font-size: 20px;
>     color: #2c1612;
>     cursor: text;
>     white-space: pre-wrap;
>     /*word-break: break-all;*/
>     word-wrap: break-word;
>     overflow-y: auto;
>   }
> </style>
> 
> <!-- html -->
> <div id="dashboard" class="dashboard"></div>
> 
> <!-- js -->
> <script type="text/javascript">
>   var dashboard = document.getElementById("dashboard");
>   dashboard.addEventListener("dragover", function (e) {
>      e.preventDefault();
>      e.stopPropagation();
>   });
>   dashboard.addEventListener("dragenter", function (e) {
>      e.preventDefault();
>      e.stopPropagation();
>   });
>   dashboard.addEventListener("drop", function (e) {
>      // 必须要禁用浏览器默认事件
>      e.preventDefault();
>      e.stopPropagation();
>  
>      // 获取文件
>      var files = this.files || e.dataTransfer.files;
>      var reader = new FileReader();
>      reader.readAsText(files[0], "utf-8");
>      reader.onload = function (evt) {
>          var text = evt.target.result;
>          dashboard.innerText = text;
>      };
>   });
> </script>
> ```

#### 用对象处理文件

> 使用 `URL.createObjectURL()` 方法从文件创建一个唯一的 URL。使用 `URL.revokeObjectURL()` 方法释放它。
>
> DOM 和 `URL.createObjectURL()` 和 `URL.revokeObjectURL()` 方法允许您创建简单的 URL 字符串，可用于引用任何可以使用 DOM 文件对象引用的数据，包括用户计算机上的本地文件。
>
> ```html
> <div>
> <h1>使用 Object URL</h1>
> <input type="file" id="file-uploader" accept=".jpg, .jpeg, .png" />
> <div id="image-grid"></div>
> </div>
> ```
>
> ```js
> const fileUploader = document.getElementById('file-uploader')
> const reader = new FileReader()
> const imageGrid = document.getElementById('image-grid')
> 
> fileUploader.addEventListener('change', (event) => {
>   const files = event.target.files
>   const file = files[0]
> 
>   const img = document.createElement('img')
>   imageGrid.appendChild(img)
>   img.src = URL.createObjectURL(file)
>   img.alt = file.name
> })
> ```

### 图片路径转base64

> ```bash
> # 2022年8月19日17:14:00  图片上传转换为base64格式封装
> 	1. 通过创建一个canvas画布：document.createElement('canvas')
> 	2. 把图片路径传递到画布，然后让画布获取图片的信息（如图片宽高和路径内容）
> 	3. 通过 canvas.getContext('2d').drawImage() 绘画出图片信息
> 	4. 通过 canvas.toDataURL('image/jpeg') 绘画成图片 base64 信息
> ```

#### 将图像文件转换为base64

> ```js
> /* image转Base64 */
> imageToBase64(file) {
>   let reader = new FileReader()
>   reader.readAsDataURL(file)
>   reader.onload = () => {
>     console.log('file 转 base64结果：' + reader.result)
>     const imgBase64 = reader.result
>     }
>   reader.onerror = (error) => {
>     console.log('Error: ', error)
>   }
> }
> 
> 
> /* Base64图像直接显示在标签 */
> <img :src="imgBase64" />
> ```

#### 网络图片转base64（单张）

> ```js
> //异步执行
> const imageUrlToBase64 = (imageUrl) => {
>   let imageFile = new Image();
>   imageFile.setAttribute('crossOrigin', 'anonymous'); //解决跨域问题
>   imageFile.src = imageUrl
>   //image.onload为异步加载
>   imageFile.onload = () => {
>     const canvas = document.createElement('canvas');
>     canvas.width = imageFile.width;
>     canvas.height = imageFile.height;
> 
>     const context = canvas.getContext('2d');
>     context.drawImage(imageFile, 0, 0, canvas.width, canvas.height)
> 
>     //使用toDataUrl将图片转换成jpeg的格式,不要把图片压缩成png，因为压缩成png后base64的字符串可能比不转换前的长
>     return canvas.toDataURL('image/jpeg') // 返回值为就是base64类型
>   }
> }
> ```

#### 网络图片转base64（多张）

> ```js
> /***
>  * 采用递归同步执行
>  * 每次获取存储图片路径的数组的第一个图片地址进行计算，
>  * 然后存储到导出的数组中，并删除该第一位数组，然后携带所导出的数据进行递归
> */
> const resultImgData = [];
> 
> const imageUrlToBase64 = (imgUrlList, i) => {
>   let imageFile = new Image();
>   imageFile.setAttribute('crossOrigin', 'anonymous'); //解决跨域问题
>   imageFile.src = imgUrlList[i]
>   //image.onload为异步加载
>   imageFile.onload = () => {
>     const canvas = document.createElement('canvas');
>     canvas.width = imageFile.width;
>     canvas.height = imageFile.height;
> 
>     const context = canvas.getContext('2d');
>     context.drawImage(imageFile, 0, 0, canvas.width, canvas.height)
> 
>     resultImgData.push(canvas.toDataURL('image/jpeg'))
>     imgUrlList.shift();
>     if(++i <= len) {
>       imageUrlToBase64(imgUrlList, i)
>     }
>   }
> }
> 
> const imgUrlList = [
>   'blob:http://localhost:3000/7fa9ee7e-29c4-4f9e-9762-0a02ad00760a',
>   'blob:http://localhost:3000/7fa9ee7e-29c4-4f9e-9762-0a02ad00760a',
>   'blob:http://localhost:3000/7fa9ee7e-29c4-4f9e-9762-0a02ad00760a',
> ]
> 
> imageUrlToBase64(imgUrlList);
> console.log("导出的图片地址", resultImgData);
> ```

#### base64转换图片显示

> ```vue
> <template>
> <img 
>    style="width:200px; height:200px;" 
>    :src="'data:img/png;base64,' + imgData.imgBase64" 
>    alt="图片加载失败" 
>    :title="imgData.imgTitle"
>  />
> </template>
> 
> <script setup>
>   import { reactive } from 'vue'
>   const imgData = reactive({
>     imgBase64: " base64的编码 ",  // 照片base64数据是来自后端 或 根据图片来转换
>     imgTitle: "图片标题"
>   })
> </script>
> ```

### 下载/打印为文件流的pdf

> **注意：若使用Blod，则需要在请求中增加数据格式`responseTtpe: blod`**
>
> ```js
> // post请求
> axios({
>   method: 'post',
>   url: 'api/user/',
>    data: {
>        firstName: 'Fred',
>        lastName: 'Flintstone'
>     },
>     responseType: 'blob'
> }).then(response => {
>    this.download(response)
> }).catch((error) => {
>   this.$message.error(error)
> })
> 
> // get 请求
> axios({
>   methods: "get",
>   url: env['qm_assist'] + `q/printPDF?id=${this.id}&sapNum=${this.sapNum}`,
>    responseType: 'blod'
> }).then(res => {
>      let blob = new Blob([res.data], {
>        type: "application/pdf;charset=utf-8",
>      })
>      console.log(blob, res)
>      this.printpdf(blob) 
>   }).catch(err => {
>      this.$message.error(error)
>  })
> 
> 
> // 下载文件
> download(data) {
>   if (!data) { return; }
>   let url = window.URL.createObjectURL(new Blob([data]))
>    let link = document.createElement('a')
>    link.style.display = 'none'
>    link.href = url
>    link.setAttribute('download', 'excel.xlsx')
> 
>    document.body.appendChild(link)
>   link.click()
> }
> ```

#### 下载

> **思路：点击下载用了a标签来接收，由于a标签点击自动下载pdf，新创建一个a标签之后，下载完成之后要释放掉URL对象**
>
> 1. 先获取后台返回所保存的pdf的路径（pdf存在服务器中的url）
> 2. 创建一个a标签，并给该a标签赋予下载
> 3. 把该a标签追加到页面的body标签中
> 4. 给a标签触发点击事件
> 5. 移除该a标签
>
>   ```js
> //1. 下载功能，dataResult是后台返回的文件流
> const downloadFile = (dataResult) = > {
>   let pdfUrl = window.URL.createObjectURL(
>   	new Blob([dataResult.data], { type: `application/pdf` })
>   )
>   const fileName = item.name; // 下载文件的名字
>   const link = document.createElement('a');
>   link.href = pdfUrl;
>   link.setAttribute('download', fileName);
>   document.body.appendChild(link);
>   link.click();
>   document.body.removeChild(link)
> }
> 
> 
> //2. 下载功能，dataResult是后台返回的base64
> const downloadFileBase64 = () => {
>   let blob = this.dataURLtoBlob(dataResult);
>   const elink = document.createElement('a')
>   elink.download = item.name; // 下载文件的名字
>   elink.href = window.URL.createObjectURL(blob)
>   elink.click()
>   window.URL.revokeObjectURL(elink.href) // 释放URL 对象
> }
>   ```

#### 打印

> **思路：因为我的打印是打印的pdf，并不是当前页面，如果直接使用window.print()，则是打印的当前页面**
>
> **注意：{ type: 'application/pdf' }要加上，否则有可能无法进行打印**
>
> ```ts
> //1. 打印功能，dataResult是后台返回的base64
> let blob = this.dataURLtoBlob(dataResult);
> const date = (new Date()).getTime()
> let ifr = document.createElement('iframe')
> ifr.style.frameborder = 'no'
> ifr.style.display = 'none'
> ifr.style.pageBreakBefore = 'always'
> ifr.setAttribute('id', 'printPdf' + date)
> ifr.setAttribute('name', 'printPdf' + date)
> ifr.src = window.URL.createObjectURL(blob)
> document.body.appendChild(ifr)
> this.doPrint('printPdf' + date)
> window.URL.revokeObjectURL(ifr.src) // 释放 URL 对象
> 
> 
> // 2. 打印功能，res.data是后台返回的文件流
> const printFile = (res) => {
>      let blob = new Blob([res.data], { type: "application/pdf;charset=utf-8" })
>      let reader = new FileReader()
>      reader.readAsDataURL(blob)
>     reader.addEventListener('loadend', () => {
>        // 通知主进程打印
>        ipcRenderer.send("IPCR_PDF_PRINT", {
>          baseCode: Buffer.from(reader.result.split('base64,')[1], 'base64'),
>        })
>      }
>                           }
> ```

### 打印DOM内容

#### 打印dom图片

> ```html
> <img id="image" src="https://images.pexels.com/photos/753626/pexels-photo-753626.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500"/>
> <button id="print">打印</button>
> ```
>
> ```js
> // 添加打印事件
> const printBtn = document.getElementById("print");
> printBtn.addEventListener("click", function () {
>   // 创建一个虚拟的 iframe 标签，并将其隐藏
>   const iframe = document.createElement("iframe");
>   Object.assign(iframe.style, {
>      height: 0,
>      width: 0,
>      visibility: "hidden",
>   });
> 
>   // 设置 iframe 的源，并添加到 body 标签下
>   iframe.setAttribute("srcdoc", "<html><body>");
>   document.body.appendChild(iframe);
> 
>   // 尽管 iframe 源是一个简单的 HTML，而不是 src 属性定义的远程路径，但我们必须等待 iframe 完全加载再进行处理
>   iframe.addEventListener("load", function () {
>      // 克隆图像
>      const image = document.getElementById("image").cloneNode();
>      image.style.maxWidth = "100%";
> 
>      // 将图像附加到 iframe 的 body 上
>      const body = iframe.contentDocument.body;
>      body.style.textAlign = "center";
>      body.appendChild(image);
> 
>      // 当图像准备就绪时调用打印
>      image.addEventListener("load", function () {
>          iframe.contentWindow.print();
>      });
>   });
> });
> ```

#### 打印设定标签内容

```html
<div id="printCont">
  <h1>要打印的标签标题</h1>
  <p>要打印的标签内容</p>
  <img src="https://images.pexels.com/photos/753626/pexels-photo-753626.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500" />
</div>
<button class="print-btn" id="handlePrint">打印</button>
```

```js
// 添加打印事件
const printBtn = document.getElementById("handlePrint");
printBtn.addEventListener("click", function () {
  // 创建一个虚拟的 iframe 标签，并将其隐藏
  const iframe = document.createElement("iframe");
  Object.assign(iframe.style, {
    height: 0,
    width: 0,
    visibility: "hidden",
  });

  // 设置 iframe 的源，并添加到 body 标签下
  iframe.setAttribute("srcdoc", "<html><body>");
  document.body.appendChild(iframe);

  // 尽管 iframe 源是一个简单的 HTML，而不是 src 属性定义的远程路径，但我们必须等待 iframe 完全加载再进行处理
  iframe.addEventListener("load", function () {
    // 克隆图像
    const printEle = document.getElementById("printCont").cloneNode(true);

    printEle.style.maxWidth = "100%";

    // 将图像附加到 iframe 的 body 上
    const body = iframe.contentDocument.body;
    body.style.textAlign = "center";
    body.appendChild(printEle);

    iframe.contentWindow.print();
  });
});
```



### 将表格导出到 csv

```ts
/**
 * @function toCsv 将 `table` 的所有单元格导出为 CSV 格式
 * @param tableEle
 * @returns
 * @desc
 *  1. 选择所有行，在它们上面循环并将每一行导出到 CSV。
 *  2. 在每一行中，我们遍历所有单元格，并使用 `textContent` 检索它们的文本内容
 */
const toCsv = (table: HTMLElement) => {
  const rows = table.querySelectorAll('tr')

  return ([] as HTMLTableRowElement[]).slice
    .call(rows!)
    .map((row) => {
      const cells = row.querySelectorAll('th, td')
      return [].slice
        .call(cells)
        .map((cell: any) => {
          return cell.textContent
        })
        .join(',')
    })
    .join('\n')
}

const download = (text, fileName) => {
  const link = document.createElement('a')
  link.setAttribute(
    'href',
    `data:text/csv;charset=utf-8,${encodeURIComponent(text)}`,
  )
  link.setAttribute('download', fileName)

  link.style.display = 'none'
  document.body.appendChild(link)

  link.click()

  document.body.removeChild(link)
}

const table = document.getElementById('exportMe')
const exportBtn = document.getElementById('export')
exportBtn?.addEventListener('click', () => {
  // 导出到 csv
  const csv = toCsv(table!)
  // 下载
  download(csv, 'download.csv')
})

```



## 权限/主题

### 主题切换方案

#### 方案1：link标签动态引入

> ```bash
> ## 做法
> 其做法就是提前准备好几套`CSS`主题样式文件，在需要的时候，创建`link`标签动态加载到`head`标签中，或者是动态改变`link`标签的`href`属性
> 
> ## 优点：
> - 实现了按需加载，提高了首屏加载时的性能
> 
> ## 缺点：
> - 动态加载样式文件，如果文件过大网络情况不佳的情况下可能会有加载延迟，导致样式切换不流畅
> - 如果主题样式表内定义不当，会有优先级问题
> - 各个主题样式是写死的，后续针对某一主题样式表修改或者新增主题也很麻烦
> ```
>
> ![image-20220906160246298](./image/image-20220906160246298.png)
>
> ![主题切换方案一](./image/Theme_switching_plan_1.gif)

#### 方案2：提前引入所有主题样式，做类名切换

> 这种方案与第一种比较类似，为了解决反复加载样式文件问题提前将样式全部引入，在需要切换主题的时候将指定的根元素类名更换，相当于直接做了样式覆盖，在该类名下的各个样式就统一地更换了。其基本方法如下：
>
> ```css
> /* day样式主题 */
> body.day .box {
>   color: #f90;
>   background: #fff;
> }
> /* dark样式主题 */
> body.dark .box {
>   color: #eee;
>   background: #333;
> }
> 
> .box {
>   width: 100px;
>   height: 100px;
>   border: 1px solid #000;
> }
> ```
>
> ```vue
> <template>
> <button onclick="change('day')">day</button>
> <button onclick="change('dark')">dark</button>
> <p>hello</p>
> </template>
> 
> <script setup>
>   const change = (theme) => {
>     document.body.className = theme;
>   }
> </script>
> ```
>
> ![主题切换方案二](./image/Theme_switching_plan_2.gif)
>
> ```bash
> ## 优点：
> - 不用重新加载样式文件，在样式切换时不会有卡顿
> 
> ## 缺点：
> - 首屏加载时会牺牲一些时间加载样式资源
> - 如果主题样式表内定义不当，也会有优先级问题
> - 各个主题样式是写死的，后续针对某一主题样式表修改或者新增主题也很麻烦
> 
> ## 小结：
> 通过以上两个方案，我们可以看到对于样式的加载问题上的考量就类似于在纠结是做SPA单页应用还是MPA多页应用项目一样。两种其实都误伤大雅，但是最重要的是要保证在后续的持续开发迭代中怎样会更方便。因此我们还可以基于以上存在的问题和方案做进一步的增强。
> ```

#### 方案3：CSS变量+类名切换

> ```bash
> ## 实现
> 在`Vue3`官网有一个暗黑模式切换按钮，点击之后就会平滑地过渡，虽然`Vue3`中也有一个`v-bind`特性可以实现动态样式绑定，但经过观察以后`Vue`官网并没有采取这个方案。
> 大体思路跟方案2相似，依然是提前将样式文件载入，切换时将指定的根元素类名更换。不过这里相对灵活的是，默认在根作用域下定义好CSS变量，只需要在不同的主题下更改CSS变量对应的取值即可。
> 在Vue3官网还使用了`color-scheme: dark;`将系统的滚动条设置为了黑色模式，使样式更加统一。
>      html.dark {
>          color-scheme: dark;
>      }
> 
> 
> ## 优点：
> - 不用重新加载样式文件，在样式切换时不会有卡顿
> - 在需要切换主题的地方利用var()绑定变量即可，不存在优先级问题
> - 新增或修改主题方便灵活，仅需新增或修改CSS变量即可，在var()绑定样式变量的地方就会自动更换
> 
> 
> ## 缺点：
> - IE兼容性（忽略不计）
> - 首屏加载时会牺牲一些时间加载样式资源
> ```
>
> **实现方案如下**
>
> ```css
> /* 定义根作用域下的变量 */
> :root {
>   --theme-color: #333;
>   --theme-background: #eee;
> }
> /* 更改dark类名下变量的取值 */
> .dark{
>   --theme-color: #eee;
>   --theme-background: #333;
> }
> /* 更改pink类名下变量的取值 */
> .pink{
>   --theme-color: #fff;
>   --theme-background: pink;
> }
> 
> .box {
>   transition: all .2s;
>   width: 100px;
>   height: 100px;
>   border: 1px solid #000;
>   /* 使用变量 */
>   color: var(--theme-color);
>   background: var(--theme-background);
> }
> ```
>
> ![主题切换方案三](./image/Theme_switching_plan_3.gif)

#### 方案4：Vue3新特性（v-bind）

> 虽然这种方式存在局限性只能在Vue开发中使用，但是为Vue项目开发者做动态样式更改提供了又一个不错的方案。
>
> ### 简单用法
>
> ```vue
> <script setup>
>   // 这里可以是原始对象值，也可以是ref()或reactive()包裹的值，根据具体需求而定
>   const theme = { color: 'red' }
> </script>
> 
> <template>
> <p>hello</p>
> </template>
> 
> <style scoped>
>   p {
>     color: v-bind('theme.color');
>   }
> </style>
> ```
>
> `Vue3`中在`style`样式通过`v-bind()`绑定变量的原理其实就是给元素绑定CSS变量，在绑定的数据更新时调用[CSSStyleDeclaration.setProperty](https://developer.mozilla.org/zh-CN/docs/Web/API/CSSStyleDeclaration/setProperty)更新CSS变量值。
>
> ### 实现思考
>
> 前面方案3基于CSS变量绑定样式是在`:root`上定义变量，然后在各个地方都可以获取到根元素上定义的变量。现在的方案我们需要考虑的问题是，如果是基于JS层面如何在各个组件上优雅地使用统一的样式变量？
> 我们可以利用Vuex或Pinia对全局样式变量做统一管理，如果不想使用类似的插件也可以自行封装一个hook，大致如下：
>
> ```js
> /* theme.ts */
> // 定义暗黑主题变量
> export const theme_dark = {
>     fontSize: '16px',
>     fontColor: '#eee',
>     background: '#333',
> };
> 
> // 定义白天主题变量
> export const theme_day = {
>     fontSize: '20px',
>     fontColor: '#f90',
>     background: '#eee',
> };
> ```
>
> ```ts
> /* useTheme.ts */
> import { shallowRef } from 'vue';
> // 引入主题
> import { theme_day, theme_dark } from './theme';
> 
> // 定义在全局的样式变量
> const theme = shallowRef({});
> 
> export function useTheme() {
>   // 尝试从本地读取
>   const localTheme = localStorage.getItem('theme');
>   theme.value = localTheme ? JSON.parse(localTheme) : theme_day;
> 
>   const setDayTheme = () => {
>      theme.value = theme_day;
>   };
> 
>   const setDarkTheme = () => {
>      theme.value = theme_dark;
>   };
> 
>   return {
>      theme,
>      setDayTheme,
>      setDarkTheme,
>   };
> }
> ```
>
> **使用自己封装的主题hook**
>
> ```vue
> <script setup lang="ts">
>   import { useTheme } from './useTheme.ts';
>   import MyButton from './components/MyButton.vue';
> 
>   const { theme } = useTheme();
> </script>
> 
> <template>
> <div class="box">
>    <span>Hello</span>
> </div>
> <my-button />
> </template>
> 
> <style lang="scss">
>   .box {
>     width: 100px;
>     height: 100px;
>     background: v-bind('theme.background');
>     color: v-bind('theme.fontColor');
>     font-size: v-bind('theme.fontSize');
>   }
> </style>
> ```
>
> ````vue
> <!-- myButton.vue -->
> <script setup lang="ts">
>   import { useTheme } from '../useTheme.ts';
> 
>   const { theme, setDarkTheme, setDayTheme } = useTheme();
> 
>   const change1 = () => {
>     setDarkTheme();
>   };
> 
>   const change2 = () => {
>     setDayTheme();
>   };
> </script>
> 
> <template>
> <button class="my-btn" @click="change1">dark</button>
> <button class="my-btn" @click="change2">day</button>
> </template>
> 
> <style scoped lang="scss">
>   .my-btn {
>     color: v-bind('theme.fontColor');
>     background: v-bind('theme.background');
>   }
> </style>
> ````
>
> ![主题切换方案四](./image/Theme_switching_plan_4.gif)
>
> ```bash
> 其实从这里可以看到，跟Vue的响应式原理一样，只要数据发生改变，Vue就会把绑定了变量的地方通通更新。
> 
> 
> ### 优点：
> - 不用重新加载样式文件，在样式切换时不会有卡顿
> - 在需要切换主题的地方利用v-bind绑定变量即可，不存在优先级问题
> - 新增或修改主题方便灵活，仅需新增或修改JS变量即可，在v-bind()绑定样式变量的地方就会自动更换
> 
> 
> ### 缺点：
> - ~~IE兼容性（忽略不计）~~
> - 首屏加载时会牺牲一些时间加载样式资源
> - 这种方式只要是在组件上绑定了动态样式的地方都会有对应的编译成哈希化的CSS变量，而不像方案3统一地就在:root上设置（不确定在达到一定量级以后的性能），也可能正是如此，Vue官方也并未采用此方式做全站的主题切换
> ```

#### 方案5：SCSS + mixin + 类名切换

> 主要是运用SCSS的混合+CSS类名切换，其原理主要是首先要在页面的根元素上定义一个 `dataset`: `<html lang="en" data-theme="theme1">`，然后将使用到mixin混合的地方编译为固定的CSS以后，再通过类名切换去做样式的覆盖，实现方案如下：
> **定义SCSS变量**：
>
> ```css
> /* variable.scss */
> /* 字体定义规范 */
> $font_samll:12Px;
> $font_medium_s:14Px;
> $font_medium:16Px;
> $font_large:18Px;
> 
> /* 背景颜色规范(主要) */
> $background-color-theme: #d43c33;//背景主题颜色默认(网易红)
> $background-color-theme1: #42b983;//背景主题颜色1(QQ绿)
> $background-color-theme2: #333;//背景主题颜色2(夜间模式)
> 
> /* 背景颜色规范(次要) */ 
> $background-color-sub-theme: #f5f5f5;//背景主题颜色默认(网易红)
> $background-color-sub-theme1: #f5f5f5;//背景主题颜色1(QQ绿)
> $background-color-sub-theme2: #444;//背景主题颜色2(夜间模式)
> 
> /* 字体颜色规范(默认) */
> $font-color-theme : #666;//字体主题颜色默认(网易)
> $font-color-theme1 : #666;//字体主题颜色1(QQ)
> $font-color-theme2 : #ddd;//字体主题颜色2(夜间模式)
> 
> /* 字体颜色规范(激活) */
> $font-active-color-theme : #d43c33;//字体主题颜色默认(网易红)
> $font-active-color-theme1 : #42b983;//字体主题颜色1(QQ绿)
> $font-active-color-theme2 : #ffcc33;//字体主题颜色2(夜间模式)
> 
> /* 边框颜色 */
> $border-color-theme : #d43c33;//边框主题颜色默认(网易)
> $border-color-theme1 : #42b983;//边框主题颜色1(QQ)
> $border-color-theme2 : #ffcc33;//边框主题颜色2(夜间模式)
> 
> /* 字体图标颜色 */
> $icon-color-theme : #ffffff;//边框主题颜色默认(网易)
> $icon-color-theme1 : #ffffff;//边框主题颜色1(QQ)
> $icon-color-theme2 : #ffcc2f;//边框主题颜色2(夜间模式)
> $icon-theme : #d43c33;//边框主题颜色默认(网易)
> $icon-theme1 : #42b983;//边框主题颜色1(QQ)
> $icon-theme2 : #ffcc2f;//边框主题颜色2(夜间模式)
> ```
>
> **定义混合mixin**：
>
> ```scss
> /* mixin.scss */
> @import "./variable.scss";
> 
> @mixin bg_color(){
>   background: $background-color-theme;
>   [data-theme=theme1] & {
>      background: $background-color-theme1;
>   }
>   [data-theme=theme2] & {
>      background: $background-color-theme2;
>   }
> }
> @mixin bg_sub_color(){
>   background: $background-color-sub-theme;
>   [data-theme=theme1] & {
>      background: $background-color-sub-theme1;
>   }
>   [data-theme=theme2] & {
>      background: $background-color-sub-theme2;
>   }
> }
> 
> @mixin font_color(){
>   color: $font-color-theme;
>   [data-theme=theme1] & {
>      color: $font-color-theme1;
>   }
>   [data-theme=theme2] & {
>      color: $font-color-theme2;
>   }
> }
> @mixin font_active_color(){
>   color: $font-active-color-theme;
>   [data-theme=theme1] & {
>      color: $font-active-color-theme1;
>   }
>   [data-theme=theme2] & {
>      color: $font-active-color-theme2;
>   }
> }
> 
> @mixin icon_color(){
>    color: $icon-color-theme;
>    [data-theme=theme1] & {
>        color: $icon-color-theme1;
>    }
>    [data-theme=theme2] & {
>        color: $icon-color-theme2;
>    }
> }
> 
> @mixin border_color(){
>   border-color: $border-color-theme;
>   [data-theme=theme1] & {
>      border-color: $border-color-theme1;
>   }
>   [data-theme=theme2] & {
>      border-color: $border-color-theme2;
>   }
> }
> ```
>
> ```vue
> <!-- Header -->
> <template>
> <div class="header" @click="changeTheme">
>    <div class="header-left">
>        <slot name="left">左边</slot>
>    </div>
>    <slot name="center" class="">中间</slot>
>    <div class="header-right">
>        <slot name="right">右边</slot>
>    </div>
> </div>
> </template>
> 
> <script>
>   export default {
>      name: 'Header',
>      methods: {
>          changeTheme () {
>            document.documentElement.setAttribute('data-theme', 'theme1')
>          }
>      }
>   }
> </script>
> 
> <style scoped lang="scss">
>   @import "../assets/css/variable";
>   @import "../assets/css/mixin";
>   .header{
>     width: 100%;
>     height: 100px;
>     font-size: $font_medium;
>     @include bg_color();
>   }
> </style>
> ```
>
> ![主题切换方案五](./image/Theme_switching_plan_5.gif)
> 可以发现，使用mixin混合在SCSS编译后同样也是将所有包含的样式全部加载：
> ![ce812151cabd40eb882833c2767c1bc](./image/ce812151cabd40eb882833c2767c1bc.png)
>
> ```bash
> 这种方案最后得到的结果与方案2类似，只是在定义主题时由于是直接操作的SCSS变量，会更加灵活。
> 
> ## 优点：
> - 不用重新加载样式文件，在样式切换时不会有卡顿
> - 在需要切换主题的地方利用mixin混合绑定变量即可，不存在优先级问题
> - 新增或修改主题方便灵活，仅需新增或修改SCSS变量即可，经过编译后会将所有主题全部编译出来
> 
> 
> ## 缺点：
> - 首屏加载时会牺牲一些时间加载样式资源
> ```

#### 方案6：CSS变量+动态setProperty

> 此方案较于前几种会更加灵活，不过视情况而定，这个方案适用于由用户根据颜色面板自行设定各种颜色主题，这种是主题颜色不确定的情况，而前几种方案更适用于定义预设的几种主题。
> 方案参考：[vue-element-plus-admin](https%3A%2F%2Fgitee.com%2Fkailong110120130%2Fvue-element-plus-admin)
> 主要实现思路如下：
> 只需在全局中设置好预设的全局CSS变量样式，无需单独为每一个主题类名下重新设定CSS变量值，因为主题是由用户**动态**决定。
>
> ```css
> :root {
> --theme-color: #333;
> --theme-background: #eee;
> }
> ```
>
> 定义一个工具类方法，用于修改指定的CSS变量值，调用的是[CSSStyleDeclaration.setProperty](https%3A%2F%2Fdeveloper.mozilla.org%2Fzh-CN%2Fdocs%2FWeb%2FAPI%2FCSSStyleDeclaration%2FsetProperty)
>
> ```typescript
> export const setCssVar = (prop: string, val: any, dom = document.documentElement) => {
>   dom.style.setProperty(prop, val)
> }
> ```
>
> 在样式发生改变时调用此方法即可
>
> ```js
> setCssVar('--theme-color', color)
> ```
>
> ![主题切换方案六](./image/Theme_switching_plan_6.gif)
>
> ### vue-element-plus-admin主题切换源码：
>
> ![image-20220906163752395](./image/image-20220906163752395.png)
> 这里还用了`vueuse`的`useCssVar`不过效果和`Vue3`中使用`v-bind`绑定动态样式是差不多的，底层都是调用的[CSSStyleDeclaration.setProperty](https://link.juejin.cn?target=https%3A%2F%2Fdeveloper.mozilla.org%2Fzh-CN%2Fdocs%2FWeb%2FAPI%2FCSSStyleDeclaration%2FsetProperty)这个api
> ![image-20220906163956648](./image/image-20220906163956648.png)
>
> ```bash
> ## 优点：
> - 不用重新加载样式文件，在样式切换时不会有卡顿
> - 仔细琢磨可以发现其原理跟方案4利用Vue3的新特性v-bind是一致的，只不过此方案只在`:root`上动态更改CSS变量而Vue3中会将CSS变量绑定到任何依赖该变量的节点上。
> - 需要切换主题的地方只用在`:root`上动态更改CSS变量值即可，不存在优先级问题
> - 新增或修改主题方便灵活
> 
> 
> ## 缺点：
> - ~~IE兼容性（忽略不计）~~
> - 首屏加载时会牺牲一些时间加载样式资源（相对于前几种预设好的主题，这种方式的样式定义在首屏加载基本可以忽略不计）
> ```

#### 方案总结

> **说明**：两种主题方案都支持并不代表一定是最佳方案，视具体情况而定。
>
> | 方案/主题样式                           | 固定预设主题样式                                         | 主题样式不固定  |
> | --------------------------------------- | -------------------------------------------------------- | --------------- |
> | 方案1：link标签动态引入                 | √（文件过大，切换延时，不推荐）                          | ×               |
> | 方案2：提前引入所有主题样式，做类名切换 | √                                                        | ×               |
> | 方案3：CSS变量+类名切换                 | √（推荐）                                                | ×               |
> | 方案4：Vue3新特性（v-bind）             | √（性能不确定）                                          | √（性能不确定） |
> | 方案5：SCSS + mixin + 类名切换          | √（推荐，最终呈现效果与方案2类似，但定义和使用更加灵活） | ×               |
> | 方案6：CSS变量+动态setProperty          | √（更推荐方案3）                                         | √（推荐）       |

#### vue3 配置使用scss全局变量

> 只要在 vue.config.js 配置一下就可以了，配置的环境是 vue3，但是 vue2 也应该适用
>
> ```js
> /* vue.config.js */
> module.exports = {
>   css: {
>      loaderOptions: {
>          sass: {
>            // 具体路径根据你们项目来
>            additionalData: `@import "@/assets/theme.scss";`
>          },
>          scss: {
>            additionalData: `@import "@/assets/theme.scss";`
>          }
>      }
>   }
> }
> ```



### 暗黑模式

设置暗黑模式

````bash
#### 暗黑模式的实现
- `invert` — 反转元素和图片的颜色。在 100% 的情况下会完全反转，即黑色变为白色，白色变为黑色，#222 -> #ddd。
- `hue-rotate` — 帮助我们处理所有其他非黑色和白色的颜色。 将色相旋转 180 度，我们确保应用程序的颜色主题不会改变，而只是减弱其颜色。

注意，它还会反转应用程序中的所有图像和视频。如果不想给图片、视频应用暗黑模式，
````

```css
html[theme='dark-mode'] {
  filter: invert(1) hue-rotate(180deg);
}

img,
video {
  filter: invert(1) hue-rotate(180deg);
}
```



#### 检测暗模式

```bash
macOS、Windows 10 等现代操作系统允许用户选择他们希望在所有应用程序中看到的外观。

可以通过查看 `prefers-color-scheme` 媒体查询来检测该选项。它可以是以下值之一：
    - `light`：用户希望以浅色模式查看页面
    - `dark`：用户希望在暗黑模式下查看页面
    - `no-preference`：系统不知道用户的偏好
通过检查此媒体查询值，我们可以确定用户是否喜欢暗模式，获取系统是否处于暗模式下有两种方式。

```

使用 CSS 媒体查询检测 CSS 中的首选配色方案：

```css
@media (prefers-color-scheme: light) {
  body {
    filter: invert(0);
  }
}

/* Dark mode */
@media (prefers-color-scheme: dark) {
  body {
    filter: invert(100%) hue-rotate(180deg);
  }
}
```

使用 `matchMedia` 方法检测 JS 中的首选配色方案：

```js
const checkType = (type) =>
  window.matchMedia &&
  window.matchMedia(`(prefers-color-scheme: ${type})`).matches

const mode = {
  is: {
    dark: checkType('dark'),
    light: checkType('light')
  }
}

mode.is.dark // true
mode.is.light // false
```

如果用户在页面打开时更改首选项配色，我们可以使用 `addListener` 方法监听系统颜色的切换，来动态更改颜色。

```js
window.matchMedia('(prefers-color-scheme: dark)').addListener((e) => {
  const isDarkMode = e.matches
  console.log(`${isDarkMode ? '🌚' : '🌞'}.`)
})
```

强制设置暗模式：

```js
const forceDarkMode = () =>
  [...document.styleSheets[0].rules].forEach((rule) => {
    const mediaText = (rule.media && rule.media.mediaText) || []
    const hasColorScheme = mediaText.includes('prefers-color-scheme')
    const hasLightScheme = hasColorScheme && mediaText.includes('light')

    // 如果需要，请删除亮模式。
    if (hasLightScheme) {
      rule.media.deleteMedium('(prefers-color-scheme: light)')
    }

    // 添加暗模式
    rule.media && rule.media.appendMedium('(prefers-color-scheme: dark)')
  })
```



### RBAC 权限系统

```bash
RBAC（Role-Based Access Control）基于角色的访问控制，这是系统广泛的访问控制模型。
	- 将权限分配给就角色，再将角色分配给用户，来实现对系统资源的访问控制。
	
1. 角色层级 (Role Hierarchy): 代表用户再特定上下文中的身份或职能
   - 系统角色: admin、manager、user（可嵌套继承）
   
2. 权限类型 (Permission Type): 指对系统资源进行操作的许可，如读取、写入、修改等
   - 页面路由权限（控制菜单可见性）
   - 操作权限（按钮/API）
   - 数据权限（行级/列级控制）

3. 资源粒度 (Resource Granularity)
   - 模块级（如/user-manage）
   - 页面级（如/user-manage/list）
   - 组件级（如/user-manage/list:export按钮）



用户登录获取权限 -> 存储权限 -> 根据权限生成动态路由 -> 添加至路由实例 -> 路由守卫检查权限 -> 按钮级权限用指令控制


	实施常见问题
- 动态参数权限：在路由的beforeEnter钩子中发起额外权限校验请求
- 权限实时更新：建立WebSocket连接监听权限变更事件
- 多角色冲突：采用权限合并策略（取并集 + 优先级覆盖）
- 页面元素级控制：结合CSS作用域样式实现不可见元素隐藏
```

![img](./image/23a58fae7d16521b70a1f442ab50e704.png)

主外键关联的

![img](./image/f3859be2292c13de09e4f73d4296b60e.png)

非主外键（虚拟）

![img](./image/dc971e6622dd926a5aa74acb49baa9dd.png)



## 视频相关

### 获取视频时长

```vue
<script setup lang="ts">
/** 获取视频文件的时长 */
const getVideoDuration = (file: File) => {
  let timer: NodeJS.Timeout | null = null
  let count = 5

  return new Promise((resolve) => {
    const reader = new FileReader()
    reader.readAsDataURL(file)

    // 文件读取完成
    reader.onload = () => {
      const videoEle = document.createElement('video')
      videoEle.src = reader.result as string

      // 视频元数据加载成功
      videoEle.onloadedmetadata = () => {
        timer && clearInterval(timer)
        resolve(videoEle.duration)
      }
    }

    // 超时兜底处理
    timer = setInterval(() => {
      if (count <= 0) {
        timer && clearInterval(timer)
        resolve(0)
      } else count--
    }, 1000)
  })
}

/**
 * 优化版：获取视频文件的时长
 *  1. 使用 blob 替代 FileReader（使用FileReader读取文件速度极慢）
 *  2. 使用 Audio 类来加载视频数据
 */
const perfGetVideoDuration = (file: File) => {
  let timer: NodeJS.Timeout | null = null
  let count = 5

  return new Promise((resolve) => {
    const blobUrl = URL.createObjectURL(file)
    const audioEle = new Audio(blobUrl)

    // 视频元数据加载成功
    audioEle.onloadedmetadata = () => {
      timer && clearInterval(timer)
      URL.revokeObjectURL(blobUrl)
      resolve(audioEle.duration)
    }

    // 超时兜底处理
    timer = setInterval(() => {
      if (count <= 0) {
        timer && clearInterval(timer)
        resolve(0)
      } else count--
    }, 1000)
  })
}

const selectFile = async (type: 'old' | 'new', e) => {
  const file = (e as any).target.files[0]
  if (!file) return
  const duration =
    type === 'old'
      ? await getVideoDuration(file)
      : await perfGetVideoDuration(file)
  console.log('bbb', file, duration)
}
</script>

<template>
  <input type="file" accept="video/*" @change="(e) => selectFile('old', e)" />
  <input type="file" accept="video/*" @change="(e) => selectFile('new', e)" />
</template>
```



### 不同格式视频播放 + 水印

```bash
<video> 元素支持三种视频格式：MP4、WebM、Ogg。
	- MP4：MPEG4 文件使用 H264 视频编解码器和 AAC 音频编解码器
	- WebM：WebM 文件使用 VP8 视频编解码器和 Vorbis 音频编解码器
	- Ogg ：Ogg 文件使用 Theora 视频编解码器和 Vorbis音频编解码器
```

```html
<video id="video1" controls crossOrigin="Anonymous" width="520" height="320">
  <source :src="url" type="video/mp4">
  您的浏览器不支持 video 标签。
</video>
```

```js
captureClick() {
  const v = document.querySelector('#video1')
  const width = v.videoWidth
  const height = v.videoHeight

  const canvas = document.createElement('canvas')
  canvas.width = width
  canvas.height = height

  const ctx = canvas.getContext('2d')

  ctx.drawImage(v, 0, 0, width, height)

  ctx.rotate(-16 * Math.PI / 180)
  ctx.font = '100px 宋体'
  ctx.fillStyle = 'rgba(255, 255, 255, 1)'
  ctx.fillText('测试水印', 100, height - 200)

  const image = canvas.toDataURL('image/png')
  this.captureImg1 = image
}
```



### 视频录制

```ts
/**
 * @ Author: willysliang
 * @ CreateTime: 2025-05-15 22:51:28
 * @ Modifier: willysliang
 * @ ModifierTime: 2025-05-26 14:35:56
 * @ Description: 视频录制
 */

declare global {
  interface Window {
    webkitAudioContext?: typeof AudioContext
  }
}

/** 录制源接口 */
interface IRecordingSources {
  screen?: MediaStream
  camera?: MediaStream
}

/**
 * @class VideoRecorder 视频录制
 * @description
    1. 录制屏幕和摄像头内容，并合成视频
      - 如果有把摄像头视图渲染到页面上，录制的视频则忽略摄像头媒体流的合成，只把摄像头音频流合成到视频流中
    2. 在录制的视频中添加时间戳水印
    3. 录制过程中的音频可视化绘制为频谱图
    3. 把录制的视频保存到本地

 * @memberof #startRecording 开始录制视频
 * @memberof #stopRecording 停止录制视频
 * @memberof #saveAsFile 保存录制的视频文件
 *
 * 私有方法
 * @memberof #getSources 获取屏幕共享和摄像头媒体流
 * @memberof #compositeStream 创建合成视频流
 * @memberof #drawCompositeView 合并视图画面，可自定义画面布局样式
 * @memberof #drawAudioVisualization 可视化渲染音频-绘制频谱图
 * @memberof #stopTracks 关闭所有媒体轨道，并清理预览显示
 *
 * 辅助方法
 * @memberof #getMimeType 自动兼容不同浏览器的视频编码格式
 * @memberof #getBitrate 根据分辨率计算比特率
 *
 * @example
    const videoRef = ref<HTMLVideoElement>()
    const canvasRef = ref<HTMLCanvasElement>()
    const recorder = new VideoRecorder()
    const showPreview = ref<boolean>(true) // 是否展示镜头视图

    // 摄像头列表
    const cameraList = ref<MediaDeviceInfo[]>([])
    const currentCamera = ref<MediaDeviceInfo['deviceId']>('')
    getCameraList().then((list) => {
      cameraList.value = list
      currentCamera.value = list[0]?.deviceId
    })

    // 开始录制
    const handleStartRecord = async () => {
      await recorder.startRecording(
        currentCamera.value,
        canvasRef.value!,
        showPreview.value ? videoRef.value! : undefined,
      )
    }

    // 结束录制
    const handleStopRecord = async () => {
      recorder.stopRecording()
    }

    // 保存视频
    const handleSaveVideo = async () => {
      recorder.saveAsFile()
    }
 */
export class VideoRecorder {
  /** 媒体流的源 */
  private sources: IRecordingSources = {}
  /** 媒体录制器 */
  private mediaRecorder?: MediaRecorder
  /** 录制的数据块 */
  private recordedChunks: Blob[] = []

  /** 屏幕共享和摄像头流播放的DOM */
  private videoElements: HTMLVideoElement[] = []
  /** 预览视频元素 */
  private previewVideo?: HTMLVideoElement

  /** 视频合成画布 */
  private canvas!: HTMLCanvasElement
  private ctx!: CanvasRenderingContext2D
  private animationFrameId?: number

  /** 频谱图 */
  private audioContext?: AudioContext
  private audioRAFId?: number

  constructor() {
    this.canvas = document.createElement('canvas')
    this.ctx = this.canvas.getContext('2d')!
  }

  /**
   * @method 获取屏幕共享和摄像头媒体流
   */
  private async getSources(
    cameraDeviceId: MediaDeviceInfo['deviceId'],
  ): Promise<IRecordingSources> {
    try {
      const promises = [
        navigator.mediaDevices.getDisplayMedia({
          video: { frameRate: 24, deviceId: cameraDeviceId },
          audio: {
            echoCancellation: true, // 回声消除
            noiseSuppression: true, // 开启降噪 噪音抑制
            autoGainControl: false, // 自动增益控制(在原有录音基础上是否增加音量)
          },
        }),
        navigator.mediaDevices.getUserMedia({
          video: { width: 640, height: 480 },
          audio: true,
        }),
      ]
      const [screenStream, cameraStream] = await Promise.all(promises)
      const sources = { screen: screenStream, camera: cameraStream }

      // 强制检查是否存在有效轨道
      if (
        !screenStream.getVideoTracks().length ||
        !cameraStream.getVideoTracks().length
      ) {
        this.stopTracks(sources)
        throw new Error('必须提供有效的视频轨道')
      }

      return sources
    } catch (error) {
      const ERROR_MAP = {
        NotAllowedError: '请允许访问屏幕和摄像头权限 ➔',
        NotFoundError: '未找到视频设备，请检查摄像头连接 🔍',
        NotReadableError: '设备已被其他程序占用 🔒',
        OverconstrainedError: '无法满足分辨率要求',
        default: `媒体获取失败: ${error instanceof Error ? error.message : String(error)}`,
      }
      throw new Error(
        error instanceof DOMException
          ? ERROR_MAP[error.name] || ERROR_MAP.default
          : ERROR_MAP.default,
      )
    }
  }

  /**
   * @method 合并视图画面，绘制视频帧（含布局和水印）
   * @description 可自定义画面布局样式(如添加时间戳、绘制边框等)
   *  - 主画面为屏幕共享内容
   *  - 右下角为摄像头画面
   *  - 左下角为水印时间戳
   *  - 画面尺寸与屏幕流一致，并根据设备性能调整画质
   *  - 同步的音频录制
   */
  private async drawCompositeView() {
    if (!this.sources.screen || !this.sources.camera) return

    /**
     * 初始化视频元素
     */
    this.videoElements = await Promise.all(
      [this.sources.screen, this.sources.camera].map(async (stream) => {
        const video = document.createElement('video')
        video.srcObject = stream
        video.muted = true
        video.play()
        await new Promise((resolve) => (video.onloadedmetadata = resolve))
        return video
      }),
    )
    const [screenVideo, cameraVideo] = this.videoElements

    // 初始化画布尺寸
    const setupCanvas = () => {
      // 设置画布尺寸与屏幕流一致，并根据设备性能调整画质
      const isMobile = /Android|webOS|iPhone|iPad/i.test(navigator.userAgent)
      const quality = isMobile ? 0.7 : 1
      this.canvas.width = screenVideo.videoWidth * quality
      this.canvas.height = screenVideo.videoHeight * quality

      // 优化绘制性能
      this.ctx.imageSmoothingEnabled = true
      this.ctx.imageSmoothingQuality = 'high'
    }
    setupCanvas()

    /**
     * 动态时间戳水印绘制
     */
    const drawTimestampWatermark = () => {
      const watermarkStyle = {
        fontSize: 32,
        fontColor: 'rgba(255,255,255,0.8)',
        position: 'bottom-left',
      }
      const { fontColor, fontSize, position } = watermarkStyle
      this.ctx.font = `bold ${fontSize || 24}px Arial`
      this.ctx.fillStyle = fontColor || 'rgba(255, 0, 0, 0.7)'
      this.ctx.textBaseline = 'top'
      const timestamp = new Date().toLocaleTimeString()

      const padding = 20
      const x = position?.includes('right') ? this.canvas.width - 200 : padding
      const y = position?.includes('bottom') ? this.canvas.height - 50 : padding

      // 文字阴影效果
      this.ctx.shadowColor = 'rgba(0, 0, 0, 0.5)'
      this.ctx.shadowBlur = 4
      this.ctx.shadowOffsetX = 2
      this.ctx.shadowOffsetY = 2
      this.ctx.fillText(timestamp, x, y)
      this.ctx.restore()
    }

    /**
     * 画中画布局
     */
    const drawFrame = () => {
      const { width, height } = this.canvas
      this.ctx.clearRect(0, 0, width, height)

      // 绘制主屏幕
      if (screenVideo.readyState >= 2) {
        this.ctx.drawImage(screenVideo, 0, 0, width, height)
      }

      // 如果没有摄像头没有展示到页面，在右下角绘制摄像头画中画
      if (!this.previewVideo && cameraVideo.readyState >= 2) {
        const previewWidth = width / 4
        const previewHeight =
          (previewWidth * cameraVideo.videoHeight) / cameraVideo.videoWidth

        this.ctx.drawImage(
          cameraVideo,
          width - previewWidth - 10,
          height - previewHeight - 10,
          previewWidth,
          previewHeight,
        )
      }

      // 绘制时间戳水印
      drawTimestampWatermark()

      this.animationFrameId = requestAnimationFrame(drawFrame)
    }

    drawFrame()
  }

  /**
   * @method 可视化渲染音频-绘制频谱图
   * @description 音视频可视化-音频声波图（通过 canvas 对视频或音频绘制声波图）
   */
  private drawAudioVisualization(
    stream: MediaStream,
    canvasElement: HTMLCanvasElement,
  ) {
    this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
      latencyHint: 'interactive', // 超低延迟模式
      sampleRate: 48000, // 专业音频采样率
    })
    const source = this.audioContext.createMediaStreamSource(stream)

    // 创建分析器节点
    const analyser = this.audioContext.createAnalyser()
    analyser.fftSize = 256
    source.connect(analyser)

    const canvas = canvasElement
    const ctx = canvas.getContext('2d')!

    const dataArray = new Uint8Array(analyser.frequencyBinCount)
    const dataArrayLength = dataArray.length

    /**
     * 轮询绘制频谱
     */
    const draw = () => {
      // analyser.getByteTimeDomainData(dataArray) // 改用时域数据绘制波形
      analyser.getByteFrequencyData(dataArray) // 使用频域数据绘制频谱

      const WIDTH = canvas.width
      const HEIGHT = canvas.height - 2
      const meterWidth = 2 // 频谱条宽度
      const gap = 2 // 频谱条间距
      const capHeight = 100 // 频谱条高度
      const capStyle = 'rgb(6, 247, 8)' // #2196f3 频谱条颜色
      const meterNum = 20 / (gap + 2) // 频谱条数量
      const capYPositionArray: number[] = [] // 频谱条顶点位置数组

      ctx.clearRect(0, 0, WIDTH, HEIGHT) // 清空画布
      ctx.fillStyle = capStyle // 设置频谱条颜色

      const step = Math.round(dataArrayLength / meterNum) // 采样步长

      for (let i = 0; i < meterNum; i++) {
        const value = dataArray[i * step] // 获取当前能量值

        if (capYPositionArray.length < Math.round(meterNum)) {
          capYPositionArray.push(value) // 初始化顶点位置数组，并将第一个画面数据压入
        }
        if (value < capYPositionArray[i]) {
          ctx.fillRect(
            i * 4,
            HEIGHT - --capYPositionArray[i],
            meterWidth,
            capHeight,
          )
        } else {
          ctx.fillRect(i * 4, HEIGHT - value, meterWidth, capHeight)
          capYPositionArray[i] = value
        }
        ctx.fillRect(i * 4, HEIGHT - value + capHeight, meterWidth, capHeight)
      }

      this.audioRAFId = requestAnimationFrame(draw)
    }

    draw()
  }

  /**
   * @method 创建合成视频流
   * @param {boolean} needVideoComposite 是否需要合成
   *    - needVideoComposite=true，需要合成（把摄像头视图合成到视频流中）
   *    - needVideoComposite=false，直接返回所有媒体轨道（在页面有设置预览视频元素时，直接返回合成后的视频流）
   */
  private async compositeStream(): Promise<MediaStream> {
    // 视频合成
    await this.drawCompositeView()

    // 创建合成视频流
    const stream = this.canvas.captureStream(25) // 25fps

    // 合并所有音频轨道到视频中
    ;[this.sources.screen!, this.sources.camera!].forEach((source) => {
      source.getAudioTracks().forEach((track) => stream.addTrack(track))
    })
    return stream
  }

  /**
   * @method 关闭所有媒体轨道，并清理预览显示
   * @description 清除上次录制的副作用
   */
  private stopTracks(sources: IRecordingSources = this.sources) {
    Object.values(sources).forEach((stream) =>
      stream?.getTracks().forEach((t) => t.stop()),
    )
    sources = { screen: undefined, camera: undefined }

    // 停止媒体流
    this.mediaRecorder?.stream.getTracks().forEach((track) => track.stop())
    this.mediaRecorder = undefined

    // 清除视频元素
    this.videoElements.forEach((video) => {
      video.pause()
      video.srcObject = null
      video.remove()
    })
    this.videoElements = []

    // 清除预览显示
    if (this.previewVideo) {
      this.previewVideo.pause()
      this.previewVideo.srcObject = null
      this.previewVideo = undefined
    }

    // 关闭音频上下文
    if (this.audioContext) {
      this.audioContext.close()
      this.audioContext = undefined
    }
    // 停止音频绘制
    this.audioRAFId && cancelAnimationFrame(this.audioRAFId)

    // 停止动画绘制 & 清除画布
    this.animationFrameId && cancelAnimationFrame(this.animationFrameId)
    this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height)
  }

  // ================== 暴露给外部用的调用方法 ==================
  /**
   * @method 开始录制视频
   */
  public async startRecording(
    cameraDeviceId: MediaDeviceInfo['deviceId'],
    canvasElement: HTMLCanvasElement,
    previewElement?: HTMLVideoElement,
  ) {
    this.stopTracks() // 前置处理-开始前先关闭已有流

    this.previewVideo = previewElement
    this.sources = await this.getSources(cameraDeviceId) // 获取媒体流
    const stream = await this.compositeStream() // 获取合成后的视频流

    // 绘制频谱图
    this.drawAudioVisualization(stream, canvasElement)

    // 显示摄像头预览
    if (this.previewVideo && this.sources.camera) {
      this.previewVideo.srcObject = this.sources.camera
      // this.previewVideo.srcObject = stream
      await this.previewVideo.play()
    }

    // 准备录制
    this.mediaRecorder = new MediaRecorder(stream, {
      mimeType: this.getMimeType(),
      videoBitsPerSecond: this.getBitrate(),
      audioBitsPerSecond: 128_000, // 每秒音频比特率
    })

    this.recordedChunks = []
    this.mediaRecorder.ondataavailable = (e) => {
      e.data.size && this.recordedChunks.push(e.data)
    }

    this.mediaRecorder.start(100)
  }

  /**
   * @method 停止录制视频
   */
  public stopRecording() {
    if (!this.mediaRecorder) throw new Error('录制未开始')

    // 添加录制结束监听
    return new Promise<void>((resolve) => {
      this.mediaRecorder!.onstop = () => resolve()
      this.mediaRecorder?.stop()
      this.stopTracks()
    })
  }

  /**
   * @method 保存录制的视频文件
   */
  public saveAsFile(filename: string = 'recording') {
    if (this.recordedChunks.length === 0) return

    const mimeType = this.mediaRecorder?.mimeType || 'video/webm'
    const extension = mimeType.includes('mp4') ? 'mp4' : 'webm'
    const blob = new Blob(this.recordedChunks, { type: mimeType })

    const link = document.createElement('a')
    link.href = URL.createObjectURL(blob)
    link.download = `${filename}.${extension}`
    link.click()

    setTimeout(() => {
      URL.revokeObjectURL(link.href)
      link.remove()
    }, 100)
  }

  // ================== 辅助工具方法 ==================
  /**
   * @method 自动兼容不同浏览器的视频编码格式
   * @returns {string} 检查 MediaRecorder 格式支持并返回
   */
  private getMimeType(): string {
    const MIME_TYPES = [
      'video/mp4;codecs=avc1', // h264
      'video/webm;codecs=vp9', // vp9
      'video/webm;codecs=vp8', // vp8
    ] as const

    return MIME_TYPES.find(MediaRecorder.isTypeSupported) || 'video/webm'
  }

  /**
   * @method 根据分辨率计算比特率
   * @returns {number} 比特率
   */
  private getBitrate(): number {
    // const isHD = this.canvas.width >= 1280 || this.canvas.height >= 720
    // return isHD ? 5_000_000 : 2_500_000

    return this.canvas.width * this.canvas.height * 24 * 0.15 // 基于分辨率和帧率的动态比特率
  }
}

/**
 * @method 获取摄像头设备列表
 * @return {Promise<MediaDeviceInfo[]>} 摄像头设备列表
 */
export const getCameraList = async (): Promise<MediaDeviceInfo[]> => {
  const devices = await navigator.mediaDevices.enumerateDevices()
  return devices.filter((d) => d.kind === 'videoinput')
}
```



### 根据视频dom播放的实时帧检测黑屏

```ts
/**
 * @ Author: willysliang
 * @ CreateTime: 2025-04-03 19:41:23
 * @ Modifier: willysliang
 * @ ModifierTime: 2025-05-26 14:30:29
 * @ Description: 根据视频dom播放的实时帧检测黑屏(所以需要播放视频来处理)
 */

interface ICheckConfig {
  /** 黑色占比，-1 则关闭检查 */
  blackScreenParam: number
  /** 检查次数 */
  checkCount: number
  /** 检查时间周期毫秒 */
  checkInterval: number
  /** 纳入查色块范围 */
  color: number // 如color=10，则为 rgb(10, 10, 10) 到 rgb(0, 0, 0)
}

/**
 * @class CheckBlackVideo 检查是否是黑屏
 * @description 需要视频处于播放然后再获取实时的帧页面来处理
 * @example
    const handleCheckBlackVideo = () => {
      const videoDom = document.getElementById('video') as HTMLVideoElement
      if (!videoDom) return
      if (videoDom.paused) videoDom.play()
      const instance = new CheckBlackVideo(videoDom)
      instance.check().then((result) => {
        console.log('检测结果：', result ? '黑屏' : '非黑屏')
        console.log('检测帧率结果：', instance.checkResult)
      })
    }
 */
export class CheckBlackVideo {
  /** 视频dom */
  videoDom: HTMLVideoElement
  /** 检查配置项 */
  config: ICheckConfig
  checkResult: string[]

  constructor(videoDom: HTMLVideoElement) {
    this.config = {
      blackScreenParam: 0.68,
      checkCount: 2,
      checkInterval: 1000,
      color: 10,
    }
    this.videoDom = videoDom
    this.checkResult = []
  }

  /** 开始检测，返回是否为黑屏的布尔值 */
  check(): Promise<boolean> {
    return new Promise(async (resolve) => {
      if (this.config.blackScreenParam === -1) {
        resolve(false)
      }

      try {
        const isBlack = await this.useCanvasCheck()
        resolve(isBlack)
      } catch {
        // 报错则非黑屏
        resolve(false)
      }
    })
  }

  /** 使用 canvas 检查视频是否黑屏 */
  useCanvasCheck(): Promise<boolean> {
    return new Promise((resolve, reject) => {
      const canvas = document.createElement('canvas')
      const ctx = canvas.getContext('2d')!

      let count = 0

      const { color, blackScreenParam, checkCount, checkInterval } = this.config

      /** 遍历 canvas 输出的像素值 */
      const loopCheckFn = () => {
        count++

        canvas.width = this.videoDom.videoWidth
        canvas.height = this.videoDom.videoHeight

        // 将视频绘制到 canvas 上
        ctx.drawImage(this.videoDom, 0, 0)
        // 获取 canvas 的像素数据
        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height)
        ctx.putImageData(imageData, 0, 0)
        const data = imageData.data

        let blackPixels = 0

        // 一个像素占4位，rgba 顺序分布
        for (let i = 0; i < data.length; i += 4) {
          const r = data[i]
          const g = data[i + 1]
          const b = data[i + 2]
          if (r < color && g < color && b < color) {
            blackPixels++
          }
        }

        this.checkResult.push(
          `黑色像素比: ${(blackPixels * 4) / data.length}, 次数: ${count}`,
        )

        // 大于基准值，则认为是黑屏，少于则不是（黑屏的点在数据总数中超出基准值）
        if ((blackPixels * 4) / data.length > blackScreenParam) {
          // 只要有一次黑屏，则认为黑屏
          resolve(true)
        } else if (count < checkCount) {
          setTimeout(loopCheckFn, checkInterval)
        } else {
          // 次数结束则非黑屏
          resolve(false)
        }
      }

      // 初始化检查
      try {
        setTimeout(loopCheckFn, checkInterval)
      } catch (err) {
        reject(err)
      }
    })
  }
}
```



### 视频黑屏检测

```ts
/**
 * @ Author: willysliang
 * @ CreateTime: 2025-04-03 15:07:20
 * @ Modifier: willysliang
 * @ ModifierTime: 2025-04-03 21:26:13
 * @ Description: 视频黑屏检测器
 */

/** 视频黑屏检测配置项 */
type VideoConfig = {
  /** 亮度阈值 (0-255) */
  brightnessThreshold?: number
  /** 单通道像素阈值 (0-255) */
  pixelThreshold?: number
  /** 认定为黑屏的最小黑色像素比例 (0-1) */
  requiredBlackRatio?: number
  /** 采样间隔（秒） */
  sampleInterval?: number
  /** 最大采样帧数 */
  maxSamples?: number
  /** 采样帧数容错数 */
  sampleTolerance?: number
  /** 是否启用调试模式 */
  debug?: boolean
}

/**
 * 智能黑屏检测工具
 *
 * 🎯 主要功能：
 * 1. 自动分析视频内容是否为全黑画面
 * 2. 支持大文件快速检测
 * 3. 提供精准的像素级分析
 *
 * 💡 典型应用场景：
 * - 用户上传视频时的自动质量检查
 * - 监控视频片段的黑屏检测
 * - 视频处理流程中的异常检测
 *
 * @example
    // 基础用法 - 检测用户上传的视频
    const detector = new BlackScreenDetector()
    document
      .querySelector('input[type="file"]')
      .addEventListener('change', async (e) => {
        const file = e.target.files[0]
        const result = await detector.check(file)
        alert('检测结果：', result ? '黑屏' : '非黑屏')
        console.log('检测帧率结果：', result.checkResult)
      })
 */

export class BlackScreenDetector {
  /**
   * 默认配置项
   * @type {Required<VideoConfig>}
   * @static
   */
  static DEFAULTS: Required<VideoConfig> = {
    brightnessThreshold: 20, // 典型值范围：15-30（夜间场景可适当提高）
    pixelThreshold: 30, // 典型值范围：25-40（处理压缩视频需调高）
    requiredBlackRatio: 0.95, // 典型值范围：0.9-0.99
    sampleInterval: 0.2, // 单位：秒（兼顾精度与性能的平衡值）
    maxSamples: 50, // 防止超长视频处理时间过长
    sampleTolerance: 5, // 允许的采样帧数容错数
    debug: true, // 开启后可在控制台查看检测过程
  }

  /** 视频元素实例 */
  private video: HTMLVideoElement
  private canvas: HTMLCanvasElement
  /** Canvas 渲染上下文 */
  private ctx: CanvasRenderingContext2D
  /** 当前配置项 */
  private config: Required<VideoConfig>
  private abortController: AbortController | null = null

  /** 检测的结果 */
  public checkResult: unknown[] = []

  /**
   * 创建黑屏检测器实例
   * @param {VideoConfig} [options] 自定义配置项
   */
  constructor(options: VideoConfig = {}) {
    this.config = { ...BlackScreenDetector.DEFAULTS, ...options }

    // 初始化视频处理组件
    this.video = document.createElement('video')
    this.canvas = document.createElement('canvas')
    const ctx = this.canvas.getContext('2d')
    if (!ctx) throw new Error('Canvas 上下文初始化失败')
    this.ctx = ctx
  }

  /**
   * 执行黑屏检测（主入口方法）
   *
   * @param file 视频文件对象
   * @returns 检测结果（true=黑屏 / false=正常）
   *
   * 🚀 工作流程：
   * 1. 加载视频元数据 → 2. 智能缩放 → 3. 分段采样 → 4. 双验证检测
   *
   * ⚠️ 注意：
   * - 视频时长超过5分钟时自动启用快速采样模式
   * - 支持MP4/WebM/AVI等主流格式
   * - 检测过程中可调用 abort() 终止
   */
  async check(file: File | string): Promise<boolean> {
    this.abortController = new AbortController()
    this.checkResult = []

    try {
      // 初始化视频源
      if (typeof file === 'string') {
        this.video.src = file
      } else {
        this.video.src = URL.createObjectURL(file)
      }

      await this.loadVideoMetadata()

      // 分辨率优化处理（4K→480P）
      const scale = this.calculateOptimalScale()
      ;[this.canvas.width, this.canvas.height] = [
        Math.floor(this.video.videoWidth * scale),
        Math.floor(this.video.videoHeight * scale),
      ]

      // 生成智能采样点（兼顾首尾帧）
      const samplePoints = this.generateSamplePoints()
      const hasBlackFrames: number[] = [] // 累计检测到的黑屏帧
      for (const time of samplePoints) {
        if (this.abortController.signal.aborted) {
          throw new Error('用户终止检测')
        }

        await this.seekTo(time)
        const hasBlackFrame = this.analyzeFrame()
        if (hasBlackFrame) hasBlackFrames.push(time)
        if (hasBlackFrames.length > this.config.sampleTolerance) return true
      }

      return false
    } finally {
      this.cleanupResources()
    }
  }

  /**
   * 安全终止检测任务
   *
   * 🛑 使用场景：
   * - 用户取消上传
   * - 页面切换/关闭
   * - 响应超时强制终止
   */
  abort(): void {
    this.abortController?.abort()
  }

  // ----------------- 私有方法（内部逻辑）-----------------

  /**
   * 元数据加载（含超时控制）
   *
   * ⏱️ 性能指标：
   * - 超时时间：5秒
   * - 错误处理：网络错误/格式错误/权限问题
   * @returns {Promise<void>}
   * @throws {Error} 当视频加载失败或超时时抛出
   * @private
   */
  private async loadVideoMetadata(): Promise<void> {
    return new Promise((resolve, reject) => {
      const timer = setTimeout(() => reject(new Error('元数据加载超时')), 5000)

      const loadedHandler = () => {
        cleanup()
        resolve()
      }

      const errorHandler = (ev: ErrorEvent) => {
        cleanup()
        reject(new Error(`视频加载失败: ${ev.message}`))
      }

      const cleanup = () => {
        clearTimeout(timer)
        this.video.removeEventListener('loadedmetadata', loadedHandler)
        this.video.removeEventListener('error', errorHandler)
      }

      this.video.addEventListener('loadedmetadata', loadedHandler)
      this.video.addEventListener('error', errorHandler)
    })
  }

  /**
   * 计算最佳缩放比例（性能优化）
   *
   * 📐 算法逻辑：
   * - 限制最大边长为640px
   * - 保持原始宽高比
   * - 最小缩放比例10%（防失真）
   * @returns {number} 缩放比例 (0-1)
   * @private
   */
  private calculateOptimalScale(): number {
    const MAX_EDGE = 640
    return Math.min(
      MAX_EDGE / this.video.videoWidth,
      MAX_EDGE / this.video.videoHeight,
      1,
    )
  }

  /**
   * 生成采样时间点（科学分布算法）
   *
   * ⏳ 分布策略：
   * - 首帧必检（0秒）
   * - 尾帧必检（duration-0.1秒）
   * - 中间均匀分布
   * @returns {number[]} 采样时间点数组（单位：秒）
   * @private
   */
  private generateSamplePoints(): number[] {
    const duration = this.video.duration
    const idealSamples = Math.floor(duration / this.config.sampleInterval)
    const actualSamples = Math.min(idealSamples, this.config.maxSamples)

    const points = Array.from(
      { length: actualSamples },
      (_, i) => (i * duration) / actualSamples,
    )

    // 确保检测最后一帧
    if (!points.includes(duration - 0.1)) {
      points.push(Math.max(0, duration - 0.1))
    }
    return points
  }

  /**
   * 视频帧分析（双验证机制）
   *
   * 🔍 检测逻辑：
   * 1. 像素级检测：RGB三通道均≤阈值
   * 2. 亮度检测：YUV加权亮度≤阈值
   *
   * 🧮 公式：
   * 亮度值 = 0.299*R + 0.587*G + 0.114*B
   * @returns {boolean} 检测结果（true=黑屏 / false=正常）
   */
  private analyzeFrame(): boolean {
    // 绘制当前帧
    this.ctx.drawImage(this.video, 0, 0, this.canvas.width, this.canvas.height)
    const { data } = this.ctx.getImageData(
      0,
      0,
      this.canvas.width,
      this.canvas.height,
    )

    // 双指标统计
    let blackPixels = 0
    let totalBrightness = 0
    const pixelCount = this.canvas.width * this.canvas.height
    const { pixelThreshold, brightnessThreshold, requiredBlackRatio } =
      this.config

    for (let i = 0; i < data.length; i += 4) {
      const [r, g, b] = data.slice(i, i + 3)

      // 像素级检测 (RGB三通道均≤阈值)
      if (r <= pixelThreshold && g <= pixelThreshold && b <= pixelThreshold) {
        blackPixels++
      }

      // 亮度检测 (YUV加权公式)
      totalBrightness += 0.299 * r + 0.587 * g + 0.114 * b
    }

    // 双条件验证
    const brightnessCondition =
      totalBrightness / pixelCount <= brightnessThreshold
    const ratioCondition = blackPixels / pixelCount >= requiredBlackRatio

    // 调试信息输出
    if (this.config.debug) {
      const checkResult = {
        当前时间: this.video.currentTime.toFixed(1),
        黑色像素占比: `${((blackPixels / pixelCount) * 100).toFixed(1)}%`,
        平均亮度: (totalBrightness / pixelCount).toFixed(1),
        分辨率: `${this.canvas.width}x${this.canvas.height}`,
        像素阈值: pixelThreshold,
        亮度阈值: brightnessThreshold,
        黑屏比例: requiredBlackRatio,
        检测为黑屏: brightnessCondition || ratioCondition,
      }
      this.checkResult.push(checkResult)
      // console.table(checkResult)
    }

    return brightnessCondition || ratioCondition
  }

  /**
   * 资源清理（内存优化关键）
   *
   * 🧹 清理内容：
   * - 释放视频对象内存
   * - 重置中止控制器
   * - 清理画布数据
   */
  private cleanupResources(): void {
    URL.revokeObjectURL(this.video.src)
    this.video.removeAttribute('src')
    this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height)
    this.abortController = null
  }

  /**
   * 精准跳转到指定时间点
   *
   * ⏱️ 功能特性：
   * - 基于 Promise 的异步控制流程
   * - 自动处理视频 seeking 状态
   * - 内置 2 秒超时保护
   *
   * @param time 目标时间（单位：秒）
   * @returns Promise<void>
   *
   * @example
   * // 跳转到第5秒并检测
   * await seekTo(5);
   * const isBlack = analyzeFrame();
   */
  private async seekTo(time: number): Promise<void> {
    return new Promise((resolve, reject) => {
      // 参数有效性校验
      if (time < 0 || time > this.video.duration) {
        reject(
          new Error(`无效时间点: ${time}，视频总时长 ${this.video.duration}s`),
        )
        return
      }

      // 超时保护（2秒未完成视为失败）
      const timeoutId = setTimeout(() => {
        reject(new Error(`跳转超时（${time}s)`))
        cleanup()
      }, 2000)

      // 事件清理函数
      const cleanup = () => {
        clearTimeout(timeoutId)
        this.video.removeEventListener('seeked', onSeeked)
        this.video.removeEventListener('error', onError)
      }

      // 成功回调
      const onSeeked = () => {
        cleanup()

        // 额外校验当前时间（处理部分浏览器的精度问题）
        const delta = Math.abs(this.video.currentTime - time)
        if (delta > 0.1) {
          reject(
            new Error(
              `跳转偏差过大: 目标 ${time}s, 实际 ${this.video.currentTime}s`,
            ),
          )
        } else {
          resolve()
        }
      }

      // 错误处理
      const onError = (event: ErrorEvent) => {
        cleanup()
        reject(new Error(`跳转失败: ${event.message}`))
      }

      // 绑定事件监听
      this.video.addEventListener('seeked', onSeeked)
      this.video.addEventListener('error', onError)

      // 执行跳转
      try {
        this.video.currentTime = time
      } catch (err: any) {
        cleanup()
        reject(new Error(`设置时间失败: ${err.message}`))
      }
    })
  }
}
```



## 直播视频流

```bash
### 点播与直播
1. 点播：
	- 点播是指把提前做好的视频进行播放。
	- 对于前端来说，就是一个 mp4 链接地址放到 `<video>` 标签中，浏览器会帮助我们处理好视频解析播放等一系列事情，我们可以拖动进度条选择想看的任意一个时间。
	- 点播常见的是 mp4 格式，对前端的兼容性最好，但相对来说 mp4 的体积比较大，解析会复杂一些。

2. 直播：
	- 直播的特点：
			- 获取到的是流数据
			- 实时性
	- 流数据是指获取到的数据是一帧一帧的二进制数据进行拼接才获得一段视频。
	- 实时性：
			- 点播只需要将完整的视频直接存储到服务器上，然后返回链接，前端使用 video 或播放器播放即可。
			- 直播的实时性就决定数据源不在服务器上，而是某一个客户端。
	- 浏览器直播常用实现方案协议为 flv，它的头部文件非常小，结构简单，解析快速，在直播的实时性要求下非常具备优势。
```

### 流媒体

```bash
一、 流媒体
流媒体是指采用流式传输方式再 Internet 上播放的媒体格式，如音频/视频等多媒体文件。


二、 流式传输方式
流式输方式是将多媒体文件经过传输压缩后分成一个个压缩包，再由服务器向客户端连续、实时传送。用户不必像非流式传输一样等待整个文件全部下载完毕后才能播放，二十只需要经过几秒或几十秒的启动延时即可对压缩的音视频文件进行播放，剩余的部分将继续下载，直至播放完毕。


三、 流媒体传输协议
常用的流媒体传输协议主要有 HTTP渐进式下载 和 实时流媒体协议 两类。
1. HTTP 渐进式下载：
仅能传输完整的音视频文件，在给定时刻，用户只能观看已下载的那部分，而不是跳转到未下载部分。HTTP 边下载边播放，严格来说不是直播协议。它的原理是先下载文件的基本信息，音视频的时间戳，再下载音视频数据。
如播放 MP4，会先下载文件头，根据文件头指引下载文件尾，然后再下载文件的音视频数据。

2. 实时流媒体协议：
可用于实况直播，也可传输完整的音视频文件。
如 RTSP/RTP、RTMP、HLS、HTTP-FLV。



四、 测试地址
HLS直播源地址：
CCTV1高清：http://ivi.bupt.edu.cn/hls/cctv1hd.m3u8
CCTV3高清：http://ivi.bupt.edu.cn/hls/cctv3hd.m3u8
CCTV6高清：http://ivi.bupt.edu.cn/hls/cctv6hd.m3u8

RTMP直播源地址：
香港卫视：rtmp://live.hkstv.hk.lxdns.com/live/hks1
rtmp://live.hkstv.hk.lxdns.com/live/hks2
湖南卫视：rtmp://58.200.131.2:1935/livetv/hunantv
美国1：rtmp://ns8.indexforce.com/home/mystream
美国中文电视：rtmp://media3.sinovision.net:1935/live/livestream

FLV视频：
http://1011.hlsplay.aodianyun.com/demo/game.flv
```

### 直播原理

```bash
在直播时，主播端将直播流推向服务器，用户端发起请求从服务器拉视频流过来解码播放。

零. 直播流程
采集 => 处理 => 编码 => 封装 => 推流 => 分发 => 播放

发起直播的客户端，向上连着流媒体服务器，直播产生的视频流会被实时推送到服务端，这个过程叫做推流。
其他客户端同样也连接着这个流媒体服务器，不同的是它们是播放端，会实时拉取直播客户端的视频流，这个过程叫做拉流。
推流—> 服务器-> 拉流，这是目前流行的也是标准的直播解决方案。直播的整个流程全都是流数据传输，数据处理直面二进制，要比点播复杂了几个量级。


一. 采集端-视频主播端的操作：视频采集处理后推流到流媒体服务器
是视频的源头，视频的采集一般都是从真实的摄像头中得到的。如移动端设别、PC端设备的摄像头以及一些摄像头设备；
	1. 采集：首先从前端采集设备中获得原始的音频、视频数据；
	2. 处理：为了增强额外效果，对音频进行混音、降噪等处理，可为视频打上时间戳、添加 logo 水印或增加滤镜；
	3. 编码：随后对音频、视频进行编码，通过编码压缩满足其在互联网上实时传输的需求；
	4. 封装：编码后就可以把各种多媒体内容（视频、音频、字幕等）放在同一个容器中（即是封装处理），使得不同多媒体内容可同步播放，与此同时还提供了索引；
	5. 推流：最后通过流传输协议将封装好的内容推送到流媒体服务器上。


二. 流媒体服务器：负责把第一部分接收到的流进行处理并分发给用户
流媒体服务器需要接收从采集端推上来的视频流，然后将该视频流再推送到播放端；
流媒体服务器主要功能是对流媒体内容进行采集（接收推流）、缓存、调度和传输播放（以流式协议实现用户分发）
	- 微软的Windows Media Service（WMS）：它采用MMS协议接收、传输视频，采用Windows Media Player（WMP）作为前端播放器；
	- RealNetworks公司的Helix Server：采用RTSP/RTP协议接收、传输视频，采用Real Player作为播放前端播放器；
	- Adobe公司的Flash Media Server：采用RTMP（RTMPT/RTMPE/RTMPS）协议接收、传输视频，采用Flash Player作为前端播放器；


三. 播放端-用户：只需拥有支持对应流媒体传输协议的播放器即可。
播放端就是各种app，网页中的播放器，拉取流媒体服务器上的视频流，然后进行转码，最终播放出来；
这一部分就是前端需要实现如何在移动端内嵌 H5 页面中实现直播流的播放，所以需要关注服务端通过什么协议返回直播流，以及做到如何有效播放即可。
```

![image-20240816114549366](./image/image-20240816114549366.png)

![img](./image/1074523-20200324095029970-205010266.png)

### 流媒体传输协议

```bash
- RTMP: 底层基于 TCP，在浏览器端依赖 Flash。
- HTTP-FLV: 基于 HTTP 流式 IO 传输 FLV，依赖浏览器支持播放 FLV。
- WebSocket-FLV: 基于 WebSocket 传输 FLV，依赖浏览器支持播放 FLV。
- HLS: Http Live Streaming，苹果提出基于 HTTP 的流媒体传输协议。HTML5 可以直接打开播放。
- RTP: 基于 UDP，延迟 1 秒，浏览器不支持。


#### RTMP(Real Time Messaging Protocol)- 可用于推流端和拉流端
实时消息传输协议，既可以用来推送，又可以用来直播。
其核心里面是将大块的视频帧和音频帧切分，然后以小数据包的形式在互联网上传输，且支持加密，因此隐私性相对比较理想，但拆包组包的过程比较复杂，所以在海量并发时容易出现一些不可预期的稳定性问题。
RTMP协议中，视频必须是H264编码，音频必须是AAC或MP3编码，且多以flv格式封包。因为RTMP协议传输的基本是FLV格式的流文件，必须使用flash播放器才能播放。


#### RTSP(Real-Time Stream Protocol) - 用于推流端
既可以基于 UDP 传输也可以基于 TCP 传输，是纯粹的传输控制协议，它本身与它负载的媒体数据不相关，RTSP 协议需要自定义客户端向服务器发送 RTSP 命令。其视频数据由 RTP 传输，视频质量由 RTCP 控制，视频控制（如播放、暂停等）由 RTSP 提供。
RTSP实时效果非常好，适合视频聊天、视频监控等方向。


#### HLS(HTTP Live Steaming) - 用于拉流端
由Apple公司定义的基于HTTP的流媒体实时传输协议。目前video.js库支持该格式文件的播放。
传输内容包括两部分：1.M3U8描述文件；2.TS媒体文件。TS媒体文件中的视频必须是H264编码，音频必须是AAC或MP3编码。数据通过HTTP协议传输。
将视频分成 5~10 秒的视频小分片，然后用 M3U8 索引表进行管理。由于客户端下载到的视频都是 5-10 秒的完整数据，所以视频的流畅性很好，但也同样引入了很大的延迟（HLS的一般延迟在 10-30 秒左右）。
相对于 FLV，HLS在 IOS 和大部分 Android 手机浏览器上的支持非常好，所以常用于 QQ 和微信朋友圈的 URL 分享。



#### HTTP-FLV(Flash Video) - 用于拉流端
由 Adobe 公司主推，本协议实际为 http + flv，将音视频数据封装成 FLV 格式，然后通过 http 协议传输到客户端，这个协议大大方便了浏览器客户端播放直播视频流。
格式极其简单，只是在大块的视频帧和音视频头部加入一些标记头信息，由于这种极致的简洁，在延迟表现和大规模并发方面都很成熟。
唯一的不足就是在手机浏览器上的支持非常有限，但用作手机端 APP 直播协议却非常适合。
目前flv.js库支持该格式的文件播放。
```

![img](./image/1074523-20200324095018765-1924929212.png)

### 客户端视频插件

```bash
除了 H5 原生的 video 标签播放视频，常用并且支持实时流媒体播放的客户端插件（hls.js、video.js、vue-video-player）


#### hls.js
hls.js 是一个可以实现 HTTP 实时流媒体客户端的 js 库，主要依赖于 `<video>` 标签和 `Media Source Extensions` API。
它的工作原理是将 MPEG2 传输流和 AAC/MP3 流转换成 ISO BMFF（MP4）片段。由于 hls.js 是基于标准的 `<video>` 标签实现播放，所以它不需要额外的播放器。
优点：包比较小，很纯净，UI可以根据自己的业务自行扩展，功能可以根据需求进行封装，比较灵活，而且专业直播 HLS 协议流。
缺点：对于常规的通用性播放器没有封装好的UI，功能上也需要自己调 API 实现，协议单一，只支持 HLS。



#### video.js
video.js 是一个基于 h5 的网络视频播放器，支持 h5 视频、现代流媒体格式（MP4、WebM、HLS、DASH等）以及 YouTube、Vimeo，甚至连 flash 也支持(通过插件实现)，可在桌面端或移动端实现视频播放。
优点：支持多种格式的流媒体播放，浏览器不支持时可实现优雅降级；专门有一套针对直播流的 UI；插件多，兼容性好，几乎支持所有桌面及移动端的浏览器。
缺点：包比较大，实现 hls 直播时其实是内嵌了 hls.js 代码，由于封装好 UI 和功能，使其不够灵活，修改 UI 时需要通过插件实现。
```



#### flv.js

```bash
直播需要实时性，延迟越短越好。而决定传输速度的因素有很多，其中一个是视频数据本身的大小。
最早期常用的直播方案是 RTMP，兼容性也不错，但是它依赖于 Flash，而目前浏览器下 Flash 默认是被禁用的状态，已经是被时代淘汰的技术。
HLS 协议对应视频格式是 m3u8，由苹果推出，对手机支持好，但致命缺点是延迟高（10~30秒）。
RTP 协议浏览器不支持。
FLV 协议的头部文件非常小，结构简单，解析快速，在直播的实时性要求下非常具备优势。
所以选择方案只剩下 FLV。FLV 又分 `HTTP-FLV` 和 `WebSocket-FLV`。
	- 因为直播流是实时传输，连接创建后不会断，需要持续的推拉流。这种需要长连接的场景一般使用 WebSocket 相关方案。
	- 但随着 JS 原生能力扩展，fetch 不仅支持对我们更友好的 Promise，并且天生可以处理流数据，性能很好，而且使用起来简单，因此有 http 版的 flv 方案。
	- 所以最适合浏览器直播的是 flv，但它的缺点是前端 video 标签不能直接播放，需要经过处理才行（flv.js）



#### 错误状态
flv.js 的异常分为两个级别，可以看作是 一级异常 和 二级异常。
flv.js 的 事件 和 错误 都是用枚举来表示，如下：
  flvjs.Events：表示事件
  flvjs.ErrorTypes：表示一级异常
  flvjs.ErrorDetails：表示二级异常

一级异常有三类：
	NETWORK_ERROR：网络错误，表示连接问题
	MEDIA_ERROR：媒体错误，格式或解码问题
	OTHER_ERROR：其他错误
二级级异常常用的有三类：
	NETWORK_STATUS_CODE_INVALID：HTTP 状态码错误，说明 url 地址有误
	NETWORK_TIMEOUT：连接超时，网络或后台问题
	MEDIA_FORMAT_UNSUPPORTED：媒体格式不支持，一般是流数据不是 flv 的格式
```

```js
import flvjs from 'flv.js'

if (flvjs.isSupported()) {
  var videoEl = document.getElementById('videoEl')
  var flvPlayer = flvjs.createPlayer({
    type: 'flv', // 媒体类型，flv 或 mp4，默认 flv
    isLive: true, // 是否是直播流，默认 true
    hasAudio: true, // 是否有音频（如监控流只有视频流没有音频，那即便配置 hasAudio: true 也是不可能有声音的）
    hasVideo: true, // 是否有视频
    url: 'http://test.stream.com/fetch-media.flv', // 指定流地址，可以是 https(s) or ws(s)
  })

  flvPlayer.attachMediaElement(videoEl) // 挂载元素
  flvPlayer.load() // 加载流
  flvPlayer.play() // 播放流
}


// 监听错误事件
flvPlayer.on(flvjs.Events.ERROR, (err, errdet) => {
  // 参数 err 是一级异常，errdet 是二级异常
  if (err == flvjs.ErrorTypes.MEDIA_ERROR) {
    console.log('媒体错误')
    if(errdet == flvjs.ErrorDetails.MEDIA_FORMAT_UNSUPPORTED) {
      console.log('媒体格式不支持')
    }
  }
  if (err == flvjs.ErrorTypes.NETWORK_ERROR) {
    console.log('网络错误')
    if(errdet == flvjs.ErrorDetails.NETWORK_STATUS_CODE_INVALID) {
      console.log('http状态码异常')
    }
  }
  if(err == flvjs.ErrorTypes.OTHER_ERROR) {
    console.log('其他异常：', errdet)
  }
})

// 监听视频流加载完成
player.on(flvjs.Events.METADATA_ARRIVED, () => {
  console.log('视频加载完成')
})

// 直播的播放/暂停
const onClick = isplay => {
  // 参数 isplay 表示当前是否正在播放
  if (isplay) {
    // 在播放，断流
    player.unload()
    player.detachMediaElement()
  } else {
    // 已断流，重新拉流播放
    player.attachMediaElement(videoEl.current)
    player.load()
    player.play()
  }
}

// 全屏
const fullPage = () => {
  let dom = document.querySelector('.video')
  if (dom.requestFullscreen) {
    dom.requestFullscreen()
  } else if (dom.webkitRequestFullScreen) {
    dom.webkitRequestFullScreen()
  }
}
```

```css
/* 所有控件 */
video::-webkit-media-controls-enclosure {
  display: none;
}
/* 进度条 */
video::-webkit-media-controls-timeline {
  display: none;
}
video::-webkit-media-controls-current-time-display {
  display: none;
}
/* 音量按钮 */
video::-webkit-media-controls-mute-button {
  display: none;
}
video::-webkit-media-controls-toggle-closed-captions-button {
  display: none;
}
/* 音量的控制条 */
video::-webkit-media-controls-volume-slider {
  display: none;
}
/*  播放按钮 */
video::-webkit-media-controls-play-button {
  display: none;
}
```



### 播放 RTSP 流

```bash
既可以基于 UDP 传输也可以基于 TCP 传输，是纯粹的传输控制协议，它本身与它负载的媒体数据不相关，RTSP 协议需要自定义客户端向服务器发送 RTSP 命令。其视频数据由 RTP 传输，视频质量由 RTCP 控制，视频控制（如播放、暂停等）由 RTSP 提供。
RTSP实时效果非常好，适合视频聊天、视频监控等方向。

RTSP 流  =>  Web能接受的流（WebSocket 或 WebRTC）  =>  Web Video


#### 后端：
基于 NodeJS 推流包有：
	- node-rtsp-stream
	- node-media-server
	- rtsp-streaming-server
	- fluent-ffmpeg
但这些依赖包都需要一个前提条件：必须在系统中安装 FFMPEG，因为 RTSP 流转 WebSocket 是通过底层调用 FFMPEG 来实现。

#### 前端：
主流的有:
	- flv.js
	- @cycjimmy/jsmpeg-player
```

##### 创建本地 `RTSP`  推流

**第一步：安装软件**

| 工具       | 官网                          | 说明                                                         |
| ---------- | ----------------------------- | ------------------------------------------------------------ |
| FFMPEG     | https://ffmpeg.org/           | 推流工具，可以将本地视频（比如.mp4）转换成 RTSP 流           |
| EasyDarwin | https://www.easydarwin.org/   | 推流服务，启动一个本地 RTSP 流的服务，用于前端访问           |
| VLC        | https://www.videolan.org/vlc/ | 流播放器，可以测试本地 RTSP 流服务是否启动成功，是否可以播放 |

```bash
官网下载ffmpeg并配置把bin目录添加到环境变量
$ ffmpeg -version # 查看版本
$ mpeg -list_devices true -f dshow -i dummy # 查看可用以音视频设备
```

**第二步：启动 EasyDarwin，如下图所示即启动成功**

![image-20240823160551193](./image/image-20240823160551193.png)

**第三步：使用 FFMPEG 工具将本地视频文件转换为RTSP实时流**

```bash
ffmpeg -re -stream_loop -1 -i D:\videos\test.mp4 -rtsp_transport tcp -vcodec h264 -f rtsp rtsp://localhost/test
```

参数解析如下：

```bash
- `-re`：表示按照原始帧率读取输入文件。
- `-stream_loop -1`：表示无限循环读取输入文件，即不断重复播放(避免播放完推流就断了)。
- `-i D:\videos\test.mp4`：指定输入视频文件的路径为`D:\videos\test.mp4`(替换成本地文件视频即可)。
- `-rtsp_transport tcp`：指定使用TCP作为RTSP传输协议，保证传输的稳定性。
- `-vcodec h264`：指定视频编码格式为H.264。
- `-f rtsp`：表示输出格式为RTSP。
- `rtsp://localhost/test`：指定输出RTSP流的URL地址，这里是本地主机的地址，端口默认为554，路径为/test。

综上所述，这条命令行语句的意思是使用FFmpeg将`D:\videos\test.mp4`视频文件以H.264编码格式实时流传输到本地主机的`test`路径下，并使用TCP协议进行传输。
```

**使用本地摄像头推流到指定的RTMP服务器**

```bash
ffmpeg -f dshow -i video="Integrated Camera":audio="麦克风阵列 (Synaptics SmartAudio HD)" -vcodec libx264 -acodec copy -preset:v ultrafast -tune:v zerolatency -f flv "rtmp://192.168.20.107:1935/live/home"
```

```bash
- `-f dshow`：表示输入格式为DirectShow，它允许从Windows上的DirectShow设备捕获视频和音频，例如网络摄像头和麦克风。
- `-i video="Integrated Camera":audio="麦克风阵列 (Synaptics SmartAudio HD)"`：这指定了输入源。`video`参数后的`Integrated Camera`表示使用笔记本电脑自带的摄像头，`audio`参数后的`麦克风阵列 (Synaptics SmartAudio HD)`表示使用笔记本电脑自带的麦克风。
- `-vcodec libx264`：`-vcodec`表示视频编码器，`libx264`是一个广泛使用的H.264/AVC编码器，它提供了良好的视频压缩效率和质量。
- `-acodec copy`：`-acodec`表示音频编码器，`copy`表示音频流将被直接复制，不进行重新编码。这可以保持音频质量，并减少编码延迟。
- `-preset:v ultrafast`：`-preset`用于指定libx264编码器的预设，`ultrafast`是最快的预设，但会牺牲一些视频质量。如果你想要更高的视频质量，可以选择`speed`或`medium`。
- `-tune:v zerolatency`：`-tune`用于指定libx264编码器的调优参数，`zerolatency`表示零延迟，这对于实时流媒体应用非常重要，因为它可以减少编码和传输过程中的延迟。
- `-f flv`：指定输出格式为FLV（Flash Video），FLV格式是一种常见的流媒体格式，支持实时传输和播放。
- `"rtmp://192.168.20.107:1935/live/home"`：这是一个RTMP URL，用于指定内容将被推送到的目标RTMP服务器。`192.168.20.107`是服务器的IP地址，`1935`是RTMP服务器默认的端口号，`/live/home`是发布点（Stream Key），它指定了在服务器上内容将被发布的地方。

当运行这个命令时，FFmpeg会开始从摄像头和麦克风捕获视频和音频，将它们编码为FLV格式，并通过RTMP协议实时推送到指定的服务器地址。这样，任何拥有正确URL的人都可以收看你的实时直播节目。
```



**使用网络摄像头推流**

```bash
ffmpeg -threads 5 -i rtsp://admin:px123456@192.168.20.100:554/Streaming/Channels/101 -tune zerolatency -preset ultrafast -vcodec libx264 -threads 5 -b:v 400k -s 720x576 -r 25 -acodec libfaac -b:a 64k -f flv rtmp://192.168.20.107:1935/live/home
```



**第四步：在 VLC 播放器测试是否可以播放(媒体 -> 打开网络串流)**

![image-20240823161111046](./image/image-20240823161111046.png)

> 注意：EasyDarwin 默认会将推流服务启动在 554 端口，因此 VLC 添加网络串流的时候，记得输入端口号。



##### 后端推流：`node-rtsp-stream`

```js
const Stream = require('node-rtsp-stream');
const express =  require("express");
const expressWebSocket = require("express-ws");
const ffmpeg = require("fluent-ffmpeg");
ffmpeg.setFfmpegPath("ffmpeg");
const webSocketStream = require("websocket-stream/stream");

// config
const rtspServerPort = 9998;

const app = express();
app.use(express.static(__dirname));
expressWebSocket(app, null, {
  perMessageDeflate: true
});
app.ws("*", ws => {
  console.log("rtsp request handle");
  const stream = webSocketStream(ws, {
    binary: true,
    browserBufferTimeout: 1000000
  }, {
    browserBufferTimeout: 1000000
  });
  try {
    ffmpeg("rtsp://localhost:554/test")
      .addInputOption("-rtsp_transport", "tcp", "-buffer_size", "102400")  // 这里可以添加一些 RTSP 优化的参数
      .on("start", function () {
      console.log("Stream started.");
    })
      .on("codecData", function () {
      console.log("Stream codecData.")
      // 摄像机在线处理
    })
      .on("error", function (err) {
      console.log("An error occured: ", err.message);
    })
      .on("end", function () {
      console.log("Stream end!");
      // 摄像机断线的处理
    })
      .outputFormat("flv").videoCodec("libx264").noAudio().pipe(stream);
  } catch (error) {
    console.log(error);
  }
})
app.listen(rtspServerPort, () => {
  console.log("express listened on port : " + rtspServerPort)
});

// Name of the stream, used to identify it in the API
new Stream({
  name: 'socket',
  streamUrl: 'rtsp://localhost:554/test',
  wsPort: 9999,
  // ffmpeg 的一些配置参数，比如转换分辨率等，大家可以去 ffmpeg 官网自行查询
  ffmpegOptions: {
    '-stats': '',
    '-r': 20,
    '-s': '1280 720'
  }
});
```

##### 前端拉流视频展示：`flv.js`

```jsx
import React, { useEffect, useRef } from 'react';
import flvjs from 'flv.js';

export default function FlvPlayer() {
  const flvRef = useRef(null);
  useEffect(() => {
    // 根据你后端 RTSP 推流服务转的 WebSocket 地址修改
    const videoElement = document.getElementById('videoElement');
    if (flvjs.isSupported()) {
      const flvPlayer = flvjs.createPlayer({
        type: 'flv',
        isLive: true,
        url: 'ws://localhost:9998',
      });
      flvPlayer.attachMediaElement(videoElement);
      flvPlayer.load();
      flvRef.current = flvPlayer;
      // flvPlayer.play();
    }
  }, []);

  return (
    <div>
      <h1>Flv.js Player</h1>
      <div style={{ width: '100%', display: 'flex', justifyContent: 'center', alignItems: 'center' }}>
        <video id="videoElement" controls></video>
        <button onClick={() => {flvRef?.current?.play()}}>Play</button>
      </div>
    </div>
  );
}
```

![flvjs](./image/flvjs.webp)

##### 前端拉流视频展示：`jsmpeg`

```jsx
import React, { useEffect } from "react";
import JSMpeg from "@cycjimmy/jsmpeg-player";

export default function JsmpegPlayer() {
  useEffect(() => {
    // 根据你后端 RTSP 推流服务转的 WebSocket 地址修改
    new JSMpeg.VideoElement('#video', 'ws://localhost:9999');
  }, []);

  return (
    <div>
      <h1>Jsmpeg Player</h1>
      <div style={{ width: '100%', display: 'flex', justifyContent: 'center', alignItems: 'center' }}>
        <div id="video" style={{ width: 640, height: 360 }}></div>
      </div>
    </div>
  );
}
```

![jsmpeg](./image/jsmpeg.webp)



### ffmpeg-web视频推流

#### 一. node-media-server + ffmpeg 推流rtmp

##### 安装node-media-server依赖,新建app.js运行

```bash
$ npm install node-media-server -g
```

```js
const  NodeMediaServer  = require('node-media-server');
const config = {
  rtmp: {
    port: 1935,
    chunk_size: 60000,
    gop_cache: true,
    ping: 60,
    ping_timeout: 30
  },
  http: {
    port: 8000,
    allow_origin: '*'
  }
};
var nms = new NodeMediaServer(config);
nms.run();

// 执行 node app.js
```

##### 执行ffmpeg推流

> 官网下载ffmpeg并配置把bin目录添加到环境变量
>  ffmpeg -version 查看版本
>  mpeg -list_devices true -f dshow -i dummy 查看可用以音视频设备

##### 使用本地摄像头推流

```bash
ffmpeg -f dshow -i video="Integrated Camera":audio="麦克风阵列 (Synaptics SmartAudio HD)" -vcodec libx264 -acodec copy -preset:v ultrafast -tune:v zerolatency -f flv "rtmp://192.168.20.107:1935/live/home"
```

##### 使用网络摄像头推流

```bash
ffmpeg -threads 5 -i rtsp://admin:px123456@192.168.20.100:554/Streaming/Channels/101 -tune zerolatency -preset ultrafast -vcodec libx264 -threads 5 -b:v 400k -s 720x576 -r 25 -acodec libfaac -b:a 64k -f flv rtmp://192.168.20.107:1935/live/home
```

```bash
命令参数说明：
- rtsp://{账号}:{密码}@{ip}:{端口}/根据摄像头厂牌区分
 - rtmp://{本地ip}:1935/live/home
- 本地ip地址要设置为与网络摄像头同一网段
```

##### web端HTML页面4

> 因为各浏览器不再支持flash，需要使用flv.js插件

```html
<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
  </head>
  <body>
    <script src="https://cdn.bootcss.com/flv.js/1.4.0/flv.min.js"></script>
    <video id="videoElement" style="width: 80%;" controls="controls"></video>
    <script>
      if (flvjs.isSupported()) {//检查flvjs能否正常使用
        var videoElement = document.getElementById('videoElement');//使用id选择器找到第二步设置的dom元素
        var flvPlayer = flvjs.createPlayer({//创建一个新的flv播放器对象
          type: 'flv',//类型flv
          url: 'http://192.168.20.107:8000/live/home.flv'//flv文件地址
        },{
          enableWorker: true,
          enableStashBuffer: false,
          stashInitialSize: 128
        });
        flvPlayer.attachMediaElement(videoElement);//将flv视频装载进video元素内
        flvPlayer.load();//载入视频
        flvPlayer.play();//自动播放
      }
    </script>
  </body>
</html>
```



#### 二. `nginx + ffmpeg` 推流`hls`

> 注意：`hls`流延迟比较大，按官方的说法60秒内算正常

##### 下载安装`nginx`并配置

**修改配置文件：`/conf/nginx.conf` ，在server内添加：**

```yml
location /hls {
	root html;
	#add_header Cache-Control no-cache;
	add_header Access-Control-Allow-Origin *;
}
```

**修改配置文件：`/conf/mime.types` ，在types内添加：**

```yml
application/vnd.apple.mpegurl m3u8;
application/x-mpegURL m3u8;
video/mp2t ts;
```

##### `ffmpeg`推流：

> 要在html目录下创建hls目录

```bash
ffmpeg -i "rtsp://admin:px123456@192.168.20.100:554/Streaming/Channels/101" -vcodec libx265 -threads 5 -preset ultrafast -c copy -f hls -hls_time 5.0 -hls_list_size 1 15 D:/tool/Science/nginx-1.18.0/html/hls/test.m3u8
```

```bash
1. -hls_time n: 设置每片的长度，默认值为2。单位为秒
2. -hls_list_size n:设置播放列表保存的最多条目，设置为0会保存有所片信息，默认值为5
3. -hls_wrap n:设置多少片之后开始覆盖，如果设置为0则不会覆盖，默认值为0.这个选项能够避免在磁盘上存储过多的片，而且能够限制写入磁盘的最多的片的数量
4. -hls_start_number n:设置播放列表中sequence number的值为number，默认值为0
```

##### web端HTML页面

> 需要使用video.js插件

```html
<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title>video.js</title>
    <link href="https://unpkg.com/video.js@6.11.0/dist/video-js.min.css" rel="stylesheet">
    <script src="https://unpkg.com/video.js@6.11.0/dist/video.min.js"></script>
    <script src="https://unpkg.com/videojs-flash/dist/videojs-flash.js"></script>
    <script src="https://unpkg.com/videojs-contrib-hls/dist/videojs-contrib-hls.js"></script>
  </head>
  <body>
    <video id="my-player" class="video-js" controls>
      <source src="http://localhost/hls/test.m3u8" type="application/x-mpegURL">
      <p class="vjs-no-js">
        not support
      </p>
    </video>
    <script type="text/javascript">
      var player = videojs('my-player',{
        width:400,
        heigh:200
      });
    </script>
  </body>
```



#### 三. 通过webSocket发送MPEG，前端解析MPEG绘制canvas

> 延迟最小的方法，0.5秒左右，但是非常耗cpu。

##### 创建app.js，安装WebSocket等相应模块

```js
var fs = require('fs'), http = require('http'), WebSocket = require('ws');

// console.log(process.argv)
if (process.argv.length < 3) {
  // console.log('输入正确参数');
  process.argv[2]='supersecret';
  process.argv[3]='8081';
  process.argv[4]='8082';
  // 	process.exit();
}

var stream_secret = process.argv[2];//密码
var stream_port = process.argv[3] || 8081;//ffpeng推送端口
var websocket_port = process.argv[4] || 8082;//前端websocket端口 ，比如：8082
var record_stream = false;
var totalSize = 0;

function initWebSocket(websocket_port) {
  var clientMap = new Map();//缓存，实现多个视频流同时播放的问题

  var socketServer = new WebSocket.Server({
    port : websocket_port,
    perMessageDeflate : false
  });
  socketServer.on('connection', function(socket, upgradeReq) {
    var url = upgradeReq.socket.remoteAddress + upgradeReq.url;
    var key = url.substr(1).split('/')[1];//key就是通过url传递过来的标识比如:(ws://127.0.0.1:8082/live3)其中live3就是这个标识，其他的流可随机生成其他的字符串
    var clients = clientMap.get(key);
    if(!clients){
      clients = new Set();
      clientMap.set(key,clients);
    }
    clients.add(socket);
    totalSize++;
    process.stdout.write("[INFO]:a new connection, the current number of connections: " + totalSize + ".\r");
    socket.on('close', function(code, message) {
      var clientSet = clientMap.get(key);
      if(clientSet){
        clientSet.delete(socket);
        totalSize--;
        if(clientSet.size == 0){
          clientMap.delete(key);
        }
      }
      process.stdout.write("[INFO]:close a connection, the current number of connections:" + totalSize + ".\r");
    });
  });

  socketServer.broadcast = function(data, theme) {
    var clients = clientMap.get(theme);
    if (clients) {
      clients.forEach(function (client, set) {
        if(client.readyState === WebSocket.OPEN){
          client.send(data);
        }
      });
    }
  };
  return socketServer;
}

function initHttp(stream_port, stream_secret, record_stream, socketServer) {
  var streamServer = http.createServer(
    function(request, response) {
      var params = request.url.substr(1).split('/');
      if (params.length != 2) {
        process.stdout.write("\n[ERROR]:Incorrect parameters, enter password and push theme");
        response.end();
      }
      if (params[0] !== stream_secret) {
        process.stdout.write("\n[ERROR]:Password error: "+request.socket.remoteAddress+":"+request.socket.remotePort+"");
        response.end();
      }
      response.connection.setTimeout(0);
      request.on('data', function(data) {
        socketServer.broadcast(data, params[1]);
        if (request.socket.recording) {
          request.socket.recording.write(data);
        }
      });
      request.on('end', function() {
        process.stdout.write("\n[INFO]:close request");
        if (request.socket.recording) {
          request.socket.recording.close();
        }
      });
      if (record_stream) {
        var path = 'recordings/' + Date.now() + '.ts';
        request.socket.recording = fs.createWriteStream(path);
      }
    }).listen(stream_port);
  console.log('started rtsp WebSocket service in secret is [%s], service port is [%s], ws port is [%s].',stream_secret,stream_port,websocket_port);
}

initHttp(stream_port, stream_secret, record_stream, initWebSocket(websocket_port));
```

##### 执行ffmpeg(封装run.js)

把ffmpeg命令封装成js文件，以方便执行多条命令。

```js
require('shelljs/global');

var version = exec('node --version', {silent:true}).output;

exec(`ffmpeg -i "rtsp://admin:px123456@192.168.3.21:554/Streaming/Channels/101" -q 0 -f mpegts -codec:v mpeg1video -s 1680x945 http://127.0.0.1:8081/supersecret/live1`, function(status, output) {
  console.log('Exit status:', status);
  console.log('Program output:', output);
});
exec(`ffmpeg -i "rtsp://admin:px123456@192.168.3.21:554/Streaming/Channels/101" -q 0 -f mpegts -codec:v mpeg1video -s 1680x945 http://127.0.0.1:8081/supersecret/live2`, function(status, output) {
  console.log('Exit status:', status);
  console.log('Program output:', output);
});
exec(`ffmpeg -i "rtsp://admin:px123456@192.168.3.21:554/Streaming/Channels/101" -q 0 -f mpegts -codec:v mpeg1video -s 1680x945 http://127.0.0.1:8081/supersecret/live3`, function(status, output) {
  console.log('Exit status:', status);
  console.log('Program output:', output);
});
exec(`ffmpeg -i "rtsp://admin:px123456@192.168.3.21:554/Streaming/Channels/101" -q 0 -f mpegts -codec:v mpeg1video -s 1680x945 http://127.0.0.1:8081/supersecret/live4`, function(status, output) {
  console.log('Exit status:', status);
  console.log('Program output:', output);
});
```

##### 创建index.html

需要使用`jsmpeg.js`插件，页面要运行到服务器中

```html
<!DOCTYPE html>
<html>
  <body>
    <canvas id="video-canvas"></canvas>
    <canvas id="video-canvas1"></canvas>
    <canvas id="video-canvas2"></canvas>
    <canvas id="video-canvas3"></canvas>

    <script type="text/javascript" src="jsmpeg.min.js"></script>
    <script type="text/javascript">
      var canvas = document.getElementById('video-canvas');
      var url = 'ws://ip:8082/live1';
      var player = new JSMpeg.Player(url, { canvas: canvas });

      var canvas1 = document.getElementById('video-canvas1');
      var url1 = 'ws://ip:8082/live2';
      var player1 = new JSMpeg.Player(url1, {canvas: canvas1});

      var canvas2 = document.getElementById('video-canvas2');
      var url2 = 'ws://ip:8082/live3';
      var player2 = new JSMpeg.Player(url2, {canvas: canvas2});

      var canvas3 = document.getElementById('video-canvas3');
      var url3 = 'ws://ip:8082/live4';
      var player3 = new JSMpeg.Player(url3, {canvas: canvas3});
    </script>
  </body>
</html>
```



## 人脸识别

#### 人脸识别方案

```bash
人脸识别方案
1. WebRTC + Canvas（基础方案）
  原理：利用浏览器摄像头捕获视频流，通过Canvas截取帧图像进行人脸检测。
  优点：
    纯前端实现，无需后端依赖。
    适合简单的人脸检测（如活体检测、基础对齐）。
  缺点：
    无内置AI模型，需自行集成第三方库。
    性能依赖浏览器，复杂场景可能卡顿。
  适用场景：低功耗设备、离线应用、简单人脸检测。
  推荐库：
    face-api.js：基于 TensorFlow.js 内核，实现了三种卷积神经网络架构，用于完成人脸检测、识别和特征点检测任务，可以在浏览器中进行人脸识别。其内部实现了一个非常轻巧，快速，准确的 68 点面部标志探测器。支持多种 tf 模型，微小模型仅为 80kb。另外，它还支持 GPU 加速，相关操作可以使用 WebGL 运行
    tracking.js: 一个独立的 JavaScript 库，主要实现了颜色和人（人脸、五官等）的跟踪检测。可以通过检测到某特定颜色，或者检测一个人体/脸的出现与移动，来触发 JavaScript 事件，然后对人脸进行采集。Tracking.js 是使用 CPU 进行计算的，在图像的矩阵运算效率上，相对 GPU 要慢一些


2. TensorFlow.js + 预训练模型
  原理：直接在浏览器中运行深度学习模型（如MobileNet、SSD）
  优点：
    支持复杂模型（人脸检测、表情识别、年龄/性别预测）
    离线可用，保护用户隐私。
  缺点：
    模型较大，加载时间长（可优化为WebAssembly）
    高性能需求设备受限。
  推荐模型：
    Coco-SSD（通用目标检测）
    face-landmarks-detection（人脸关键点）
  适用场景：需要本地处理的隐私敏感应用（如AR滤镜、表情包生成）


3. 集成第三方API（高效省心）
原理：通过API调用云端服务（如百度AI、腾讯云、AWS Rekognition）
优点：
  无需训练模型，直接调用高精度API。
  支持复杂功能（活体检测、1:N识别）
缺点：
  依赖网络，存在隐私合规风险（需用户授权）
  可能有QPS限制或费用
推荐服务：
  百度AI：人脸识别API
  腾讯云：人脸核身
	AWS Rekognition：Amazon Rekognition
适用场景：快速上线、高精度需求（如门禁系统、金融身份验证）



4. WebAssembly + 高性能模型
原理：将C++/Rust等高性能模型编译为Wasm，在浏览器运行
优点：
  性能接近原生，适合复杂模型。
  支持WebGL加速（如OpenCV.js）
缺点：
  开发复杂度高，调试困难
推荐工具：
  OpenCV.js（计算机视觉库）
  ONNX Runtime Web（支持ONNX模型）
适用场景：对性能要求极高的场景（如实时视频分析）


5. 混合方案（前端+边缘计算）
原理：前端预处理（如裁剪/缩放），边缘节点（如Cloudflare Workers）辅助计算
优点：
  减轻浏览器负载，提升响应速度。
  隐私友好（敏感数据可在边缘处理）
缺点：
  需额外部署边缘服务
适用场景：需要平衡性能与隐私的场景（如大规模用户并发）
```

#### 应用场景

```bash\
应用场景
- 在线身份验证，银行和金融机构使用人脸识别来验证用户身份，防止欺诈行为
- 智能安防：在摄像头上部署人脸识别技术，可以自动识别和报警陌生人入侵
- 社交媒体：社交媒体平台使用人脸识别技术来自动标记照片中的朋友，提高用户体验
- 智能广告：通过分析用户的面部特征和情绪状态，广告商可以提供更加个性化的广告内容



1、识别精度问题
  提高图像质量：确保输入图像的质量足够高，避免模糊和噪点。
  优化模型：使用更先进的模型和算法，例如深度学习模型。
  增加数据集：通过增加训练数据集的规模和多样性，提高模型的泛化能力。

2、性能问题：人脸识别需要大量的计算资源
  使用Web Workers：将计算任务移到后台执行，避免阻塞主线程。
  使用GPU加速：利用GPU的强大计算能力加速模型的运行。
  减少计算量：在保证识别精度的前提下，尽量减少计算量。例如，可以通过调整模型参数和简化算法来提高运行效率。

3、人脸识别涉及到用户的隐私和安全问题
  数据加密：对用户数据进行加密存储和传输，防止数据泄露。
  权限控制：严格控制数据访问权限，确保只有授权用户才能访问敏感数据。
  合规性：遵守相关法律法规，确保数据处理符合隐私和安全要求。



1. 人脸识别在前端需要哪些技术支持？
人脸识别在前端实现需要以下技术支持：图像处理技术、人脸检测技术、特征提取技术、人脸匹配算法等。

2. 前端如何进行人脸检测和特征提取？
前端可以使用现有的人脸检测和特征提取算法库，如OpenCV.js等，通过调用相关API实现人脸检测和特征提取功能。

3. 如何实现人脸识别的实时性和准确性？
为了实现人脸识别的实时性和准确性，可以使用深度学习模型，如人脸识别中的卷积神经网络（CNN），通过训练模型来提高人脸识别的准确性，并使用GPU加速来提升实时性能。此外，还可以使用人脸关键点检测算法来提取更多的人脸特征，以提高识别的准确性。

4. 实名身份验证怎么实现？如何获取到身份证上的高清照片进行对比？
个人身份证上的高清图片是无法直接获取的，可以使用 百度AI 的实名身份认证服务，将待对比的人脸照片 + 身份证号码 + 姓名上传到百度AI服务，会返回图片的匹配度(0~100)。其底层调用的也是公安的实名认证接口。
```

#### 【人脸识别认证】

```bash
人脸识别认证场景描述及分析
人脸识别身份实名认证。用户使用人脸识别身份验证功能时，只需要将人脸对准摄像头，程序自动对人脸进行检测。如果检测到当前摄像头可视区域内仅存在唯一一个人脸，则采集当前人脸图片进行人脸对比、活体检测、身份证识别等多项组合能力，快速完成用户身份核验。


系统架构
1. 图像采集模块：负责从摄像头或其他图像输入设备中实时获取图像数据。
2. 预处理模块：对采集到的图像进行必要的预处理，如缩放、灰度化等。
3. 人脸检测模块：利用预训练的深度学习模型检测图像中的人脸位置。
4. 特征提取模块：从检测到的人脸中提取关键特征。
5. 识别与比对模块：将提取的特征与数据库中的已知特征进行比对，以识别出特定个体。


整体方案
  1. 调用摄像头（需获得用户授权允许），实时获取摄像头的视频流数据
  2. 使用 face-api.js 识别视频流中的人脸特征点，定位出人脸的位置
  		2.1 人脸检测detectAllFaces，并且调用想实现的功能，例如withFaceLandmarks是获取人脸的标志点
  		2.2 调整尺寸matchDimensions
  		2.3 调整面部检测结果的尺寸resizeResults
  		2.4 根据不同的功能调用绘制方法
  3. 符合人脸特征时，暂停视频流，根据视频流当前帧，绘制图像
  4. 将图像转成 base64 编码上传服务端
  5. 服务端调用 百度AI 的接口，与身份证上的图片信息进行对比，并进行活体检测
```

![face_detection](./image/face_detection.webp)

##### face-api.js使用流程

> **1、引入 face-api.js**
>
> ```bash
> npm install face-api.js
> ```
>
> **2、加载模型数据**
>
> 加载模型数据是异步操作。需要等模型数据加载完成后，才能开始人脸检测。
>
> ```js
> // 加载所有模型数据，models 是存放模型数据文件的目录
> await faceapi.loadModels('/models')
> 
> // 加载单个指定的模型数据
> await faceapi.loadTinyFaceDetectorModel('/models')
> await faceapi.loadSsdMobilenetv1Model('/models')
> await faceapi.loadMtcnnModel('/models')
> ```
>
> **3、检测人脸**
>
> 当人脸被检测到符合模型的配置参数后，就会被认为检测到人脸，然后返回一个detection对象，包括人脸匹配度、人脸坐标等信息。可用于后续自定义绘制人脸边界框，以及阈值的逻辑判断。
>
> - faceapi.detectAllFaces ：检测图像中的所有人脸
> - faceapi.detectSingleFace ：检测单个人脸，返回图像中具有最高置信度得分的人脸
>
> ```js
> // 数据源：HTMLImageElement | HTMLVideoElement | HTMLCanvasElement 类型
> // 不同的模型有不同的配置参数
> const detections1 = await faceapi.detectAllFaces(待检测的数据源, 模型的配置参数)
> const detections2 = await faceapi.detectSingleFace(待检测的数据源, 模型的配置参数)
> ```
>
> **4、常用人脸检测模型**
>
> （1）Tiny Face Detector 是一款性能非常高的实时人脸检测模型，与 SSD Mobilenet V1 人脸检测模型相比，它更快，更小，资源消耗更少，量化模型的大小仅为 190 KB（tiny_face_detector_model），但它在检测小脸时的表现稍差。加载时长 8 ms左右
>
> ```js
> // 模型的配置参数
> new faceapi.TinyFaceDetectorOptions({
>   // 输入的数据源大小，这个值越小，处理速度越快。常用值：128, 160, 224, 320, 416, 512, 608
>   inputSize: number,  // default: 416
>   // 用于过滤边界的分数阈值，大于等于这个值才被认为检测到了人脸，然后返回一个detection对象
>   scoreThreshold: number  // default: 0.5
> })
> ```
>
> （2）SSD Mobilenet V1 对于面部检测，该模型实现了基于 MobileNetV1 的 SSD（单次多盒检测器）。神经网络将计算图像中每个面部的位置，并将返回边界框以及每个面部的概率。该面部检测器旨在获得检测面部边界框而不是低推理时间的高精度。量化模型的大小约为 5.4 MB（ssd_mobilenetv1_model）。加载时长 2-3 s左右
>
> ```js
> // 模型的配置参数
> new faceapi.SsdMobilenetv1Options({
>   // 最小置信值，大于等于这个值才被认为检测到了人脸，然后返回一个detection对象
>   minConfidence: number,  // default: 0.5
>   // 最多返回人脸的个数
>   maxResults: number  // default: 100
> })
> ```
>
> （3）MTCNN MTCNN（多任务级联卷积神经网络）代表了 SSD Mobilenet v1 和 Tiny Yolo v2 的替代面部检测模型，它提供了更多的配置空间。通过调整输入参数，MTCNN 应该能够检测各种面部边界框大小。MTCNN 是一个 3 级级联 CNN，它同时返回 5 个面部标志点以及每个面的边界框和分数。此外，型号尺寸仅为 2 MB。加载时长 1-2s 左右
>
> ```js
> // 模型的配置参数
> new faceapi.MtcnnOptions({
>   // 人脸尺寸的最小值，小于这个尺寸的人脸不会被检测到
>   minFaceSize: number,  // default: 20
>   // 用于过滤边界的分数阈值，分别可以设置3个阶段盒子的阈值。scoreThresholds: number[],  // default: [0.6, 0.7, 0.7]
>   // 比例因子用于计算图像的比例步长
>   scaleFactor: number,  // default: 0.709
>   // 经过CNN的输入图像缩放版本的最大数量。数字越小，检测时间越短，但相对准确度会差一些。
>   maxNumScales: number,  // default: 10
>   // 手动设置缩放步长(可选) scaleSteps
>   scaleSteps: number[],
> })
> ```

##### 表情识别

```js
function faceShiBie() {
  const canvas = this.$refs.canvasRef
  const ctx = canvas.getContext('2d')
  const img = new Image()
  img.src = '/test/images/face.jpg'
  img.onload = async () => {
    // 使用detectAllFaces人脸检测
    // 然后使用withFaceLandmarks方法，对人脸进行特征点检测
    // 最后使用withFaceExpressions方法，对人脸表情进行检测
    const detections = await faceapi
      .detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks()
      .withFaceExpressions()
    // 设置canvas和img的尺寸相同
    const displaySize = faceapi.matchDimensions(canvas, img)
    // 将检测到的面部结果调整为显示大小
    const resizeDetections = faceapi.resizeResults(detections, displaySize)
    ctx.drawImage(img, 0, 0, img.width, img.height)
    // 面框分值
    faceapi.draw.drawDetections(canvas, resizeDetections)
    // 面部表情
    faceapi.draw.drawFaceExpressions(canvas, resizeDetections)
  }
}
```

##### 年龄性别识别

```js
function ageShiBie() {
  const canvas = this.$refs.canvasRef
  const ctx = canvas.getContext('2d')
  const img = new Image()
  img.src = '/test/images/face.jpg'
  img.onload = async () => {
    // 使用detectAllFaces人脸检测
    // 然后使用withFaceLandmarks方法获取人脸的标志点
    // 最后使用withAgeAndGender方法，对人脸进行年龄和性别预测
    const detections = await faceapi
      .detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks()
      .withAgeAndGender()
    // 设置canvas和img的尺寸相同
    const displaySize = faceapi.matchDimensions(canvas, img)
    // 将检测到的面部结果调整为显示大小
    const resizeDetections = faceapi.resizeResults(detections, displaySize)
    ctx.drawImage(img, 0, 0, img.width, img.height)
    // 面框分值
    faceapi.draw.drawDetections(canvas, resizeDetections)
    // 年龄和性别
    resizeDetections.forEach((detection) => {
      const { age, gender, genderProbability } = detection
      new faceapi.draw.DrawTextField(
        [
          `${Math.round(age)} Age`,
          `${gender} (${Math.round(genderProbability)})`,
        ],
        detection.detection.box.bottomLeft,
      ).draw(canvas)
    })
  }
}
```

##### 人脸提取

```js
function faceExtraction() {
  const faceDom = this.$refs.faceListRef
  const img = new Image()
  img.src = '/test/images/face.jpg'
  img.onload = async () => {
    // 使用faceapi库中的detectAllFaces方法检测图像中的人脸
    const detections = await faceapi.detectAllFaces(
      img,
      new faceapi.TinyFaceDetectorOptions(),
    )
    // 使用faceapi库中的extractFaces方法提取图像中的人脸
    const faceImages = await faceapi.extractFaces(img, detections)
    // 将提取的人脸图像添加到faceDom中
    faceImages.forEach((faceImage) => {
      faceDom.appendChild(faceImage)
    })
  }
}
```

##### 视频人脸打码

```js
function startMask() {
  const video = this.$refs.videoRef
  video.play()
  const canvas = this.$refs.canvasRef
  const ctx = canvas.getContext('2d')
  
  video.addEventListener('play', async () => {
    const displaySize = {
      width: 150, // 因为视频不是全屏的，所以需要手动设置一下canvas的宽高，没有使用video的宽
      height: video.height,
    }
    // 设置canvas的尺寸与显示尺寸相同
    faceapi.matchDimensions(canvas, displaySize)
    
    const img = new Image()
    img.src = '/test/mark.png'
    
    img.onload = () => {
      setInterval(async () => {
        // 使用faceapi库中的detectAllFaces方法检测视频中的所有人脸
        const detections = await faceapi.detectAllFaces(
          video,
          new faceapi.TinyFaceDetectorOptions(),
        )
        // 使用faceapi库中的resizeResults方法将检测到的人脸结果调整为指定大小
        const resizeDetections = faceapi.resizeResults(detections, displaySize)
        // 绘制视频
        ctx.drawImage(video, 0, 0, displaySize.width, displaySize.height)
        // 遍历检测到的物体
        resizeDetections.forEach((item) => {
          // 绘制物体
          ctx.drawImage(
            img,
            item.box.x,
            item.box.y,
            item.box.width,
            item.box.height,
          )
        })
      }, 100)
    }
  })
}
```

![视频人脸打码](./image/v2-7eab4724050820d84ef4726e02676a2c_b.webp)



